{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denliew/Chronicle-APIs-Colab/blob/main/Chronicle_APIs_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0jKbGj8ZZRB"
      },
      "source": [
        "#Start Here\n",
        "To start we need to clone the git repo of the google API python cliet as well as the CBN Tool and CLI tool, and then install them on this Google Colab instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJXfiPDxZIvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb3e6ae-6e04-4984-dea5-90aac37a32fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialization completed. Please proceed to the Upload keyfile section.\n"
          ]
        }
      ],
      "source": [
        "#@title Run me first\n",
        "#@markdown Run this cell to clone needed git repos and configure the environment. Should take about 1-3 minutes to complete.\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "!!rm -rf sample_data\n",
        "!!git clone --depth 1 https://github.com/googleapis/google-api-python-client --single-branch --branch=main\n",
        "!!git clone --depth 1 https://github.com/chronicle/cbn-tool --single-branch --branch=main\n",
        "!!git clone --depth 1 https://github.com/chronicle/cli --single-branch --branch=main\n",
        "!!pip install -r /content/cli/requirements.txt\n",
        "!!python3 -m pip install --editable /content/cli/\n",
        "!!mkdir ~/.chronicle_cli\n",
        "!!pip install -r /content/cbn-tool/requirements.txt\n",
        "!!pip install google-api-python-client\n",
        "clear_output(wait=False)\n",
        "print(f\"Initialization completed. Please proceed to the Upload keyfile section.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqcxM8_6bmM_"
      },
      "source": [
        "The next step is to upload the appropriate service key to the environment and initialize the web client.\n",
        "\n",
        "> â‡’ Click the play button below, then select your keyfile.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMb2pYab7W4R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "3fb32b65-410c-4d3c-a7d5-dd3ce9c9342b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please select and upload your keyfile\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2ffe0e5f-94b1-497a-b37f-2c10f9f02eb9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2ffe0e5f-94b1-497a-b37f-2c10f9f02eb9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dmrsk-bk-1709044560.json to dmrsk-bk-1709044560.json\n",
            "Webclient initialized\n"
          ]
        }
      ],
      "source": [
        "#@title Upload keyfile & Initialize web client\n",
        "# Imports required for the sample - Google Auth and API Client Library Imports.\n",
        "# Get these packages from https://pypi.org/project/google-api-python-client/ or run $ pip\n",
        "# install google-api-python-client from your terminal\n",
        "from google.oauth2 import service_account\n",
        "from google.auth.transport.requests import AuthorizedSession\n",
        "from googleapiclient import _auth\n",
        "import urllib\n",
        "import json\n",
        "import base64\n",
        "import http\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "# import subprocess\n",
        "from pprint import pprint\n",
        "from time import sleep\n",
        "from urllib.parse import urlencode\n",
        "from datetime import datetime\n",
        "from datetime import timezone\n",
        "\n",
        "SCOPES = [\n",
        "    'https://www.googleapis.com/auth/chronicle-backstory',  #regular backstory API\n",
        "    'https://www.googleapis.com/auth/malachite-ingestion',  #ingestion API\n",
        "    'https://www.googleapis.com/auth/cloud-platform'        #dataplane API (experimenting)\n",
        "    ]\n",
        "#@markdown Please make sure you select the appopriate region below.\n",
        "region = \"North America\" #@param  [\"North America\", \"Europe\", \"Asia (Singapore)\", \"United Kingdom (London)\", \"Australia (Sydney)\", \"Tel Aviv\", \"Frankfurt\", \"Zurich\", \"Saudi Arabia\", \"Mumbai\", \"Canada\", \"Japan (Tokyo)\", \"Qatar\", \"Italy\", \"Brazil\", \"France\", \"Jakarta\"]\n",
        "\n",
        "#@markdown <font color=red>Warning:</font> Due to the coming deprecation of the CBN tool newer regions are not supported. Only the US (North America) and Europe regions are known to work without a rewrite of the CBN scripts.\n",
        "\n",
        "if region == \"North America\":\n",
        "  region_prefix = \"\"\n",
        "  cbn_region = \"US\"\n",
        "  cli_region = \"US\"\n",
        "elif region == \"Europe\":\n",
        "  region_prefix = \"europe-\"\n",
        "  cbn_region = \"EUROPE\"\n",
        "  cli_region = \"EUROPE\"\n",
        "elif region == \"United Kingdom (London)\": #Brexit now supported\n",
        "  region_prefix = \"europe-west2-\"\n",
        "  cbn_region = \"EUROPE\" #This won't work since the CBN tool doesn't have the UK region in it\n",
        "  cli_region = \"EUROPE-WEST2\" #This may not work since the CBN tool doesn't have the UK region in it\n",
        "elif region == \"Asia (Singapore)\":\n",
        "  region_prefix = \"asia-southeast1-\"\n",
        "  cbn_region = \"ASIA\"\n",
        "  cli_region = \"ASIA-SOUTHEAST1\"\n",
        "elif region == \"Asia (Indonesia)\":\n",
        "  region_prefix =\"asia-southeast2-\"\n",
        "  cbn_region = \"ASIA\"\n",        
        "  cli_region = \"ASIA-SOUTHEAST2\"\n",
        "elif region == \"Australia (Sydney)\":\n",
        "  region_prefix = \"australia-southeast1-\"\n",
        "  cbn_region = \"AUSTRALIA\"\n",
        "  cli_region = \"AUSTRALIA-SOUTHEAST1\"\n",
        "elif region == \"Tel Aviv\":\n",
        "  region_prefix = \"me-west1-\"\n",
        "  cli_region = \"ME-WEST1\"\n",
        "elif region == \"Mumbai\":\n",
        "  region_prefix = \"asia-south1-\"\n",
        "  cli_region = \"ASIA-SOUTH1\"\n",
        "elif region == \"Frankfurt\":\n",
        "  region_prefix = \"europe-west3-\"\n",
        "  cli_region = \"EUROPE-WEST3\"\n",
        "elif region == \"Zurich\":\n",
        "  region_prefix = \"europe-west6-\"\n",
        "  cli_region = \"EUROPE-WEST6\"\n",
        "elif region == \"Saudi Arabia\":\n",
        "  region_prefix = \"me-central2-\"\n",
        "  cli_region = \"ME-CENTRAL2\"\n",
        "elif region == \"Canada\":\n",
        "  region_prefix = \"northamerica-northeast2-\"\n",
        "  cli_region = \"NORTHAMERICA_NORTHEAST2\"\n",
        "elif region == \"Japan (Tokyo)\":\n",
        "  region_prefix = \"asia-northeast1-\"\n",
        "  cli_region = \"ASIA-NORTHEAST1\",\n",
        "elif region == \"Brazil\":\n",
        "  region_prefix = \"southamerica-east1-\"\n",
        "  cli_region = \"SOUTHAMERICA-EAST1\"\n",
        "elif region == \"France\":\n",
        "  region_prefix = \"europe-west9-\"\n",
        "  cli_region = \"EUROPE-WEST9\"\n",
        "elif region == \"Italy\":\n",
        "  region_prefix = \"europe-west12-\"\n",
        "  cli_region = \"EUROPE-WEST12\"\n",
        "elif region == \"Qatar\":\n",
        "  region_prefix = \"me-central1-\"\n",
        "  cli_region = \"ME-CENTRAL1\"\n",
        "\n",
        "\n",
        "# The apikeys-demo.json file contains the customer's OAuth 2 credentials.\n",
        "# SERVICE_ACCOUNT_FILE is the full path to the apikeys-demo.json file\n",
        "# ToDo: Replace this with the full path to your OAuth2 credentials\n",
        "\n",
        "os.system(f\"rm supplied_key.json\")\n",
        "\n",
        "from google.colab import files\n",
        "print(\"Please select and upload your keyfile\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "os.system(f\"mv {list(uploaded.keys())[0]} supplied_key.json\")\n",
        "\n",
        "!cp supplied_key.json ~/.chronicle_cli/chronicle_credentials.json\n",
        "\n",
        "key_filename = \"supplied_key.json\"\n",
        "\n",
        "SERVICE_ACCOUNT_FILE = key_filename\n",
        "\n",
        "# Create a credential using Google Developer Service Account Credential and Chronicle API\n",
        "# Scope.\n",
        "credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
        "\n",
        "# Build an HTTP client to make authorized OAuth requests.\n",
        "http_client = _auth.authorized_http(credentials)\n",
        "session = AuthorizedSession(credentials)\n",
        "\n",
        "print(\"Webclient initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Quick Jump Index\n",
        "|                                                   |                                                     |                                               |\n",
        "|:-------------------------------------------------:|:---------------------------------------------------:|:---------------------------------------------:|\n",
        "|   [BigQuery Access API](#scrollTo=KCl0S9f9wWeu)   | [DataTap Configuration API](#scrollTo=MoDoZbCq8P7M) |    [Ingestion API](#scrollTo=6Ug4UflixBld)    |\n",
        "|         [CBN Tool](#scrollTo=ACbfcv9MdcYk)        |    [Detection Engine API](#scrollTo=gOLIlkpBCpNM)   |      [Parser API](#scrollTo=jV2L4JJXdVxn)     |\n",
        "|         [CLI tool](#scrollTo=Wx1pfTxOjv57)        |    [Feed Management API](#scrollTo=B1oCjyR52XG1)    | [Parser API v2 (dev)](#scrollTo=hJclWq5wb_1N) |\n",
        "|      [Collector API](#scrollTo=bdE3Nw4Yd6Xr)      |      [Feed Schema API](#scrollTo=m3wpTMoXG3Fh)      |       [RBAC API](#scrollTo=hbI-zFGq6hI5)      |\n",
        "| [Customer Management API](#scrollTo=ca5dXllqgGwQ) |       [Forwarder API](#scrollTo=gY3dJhKQRmKD)       |  [Reference List API](#scrollTo=NMvpcTZ3b-Ij) |\n",
        "|     [Data Export API](#scrollTo=q5xxRkQL2OM-)     |          [GCTI API](#scrollTo=RzEhT4Gsy7jN)         |      [Search API](#scrollTo=-q_rBGSYzWD8)     |"
      ],
      "metadata": {
        "id": "UTV-2AVDWYVO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV2L4JJXdVxn"
      },
      "source": [
        "#Parser API\n",
        "[Jump to top](#scrollTo=v0jKbGj8ZZRB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4xrtMrgyXoZ"
      },
      "outputs": [],
      "source": [
        "#@title Get current custom parsers\n",
        "uri = f'https://{region_prefix}backstory.googleapis.com/v1/tools/cbnParsers'\n",
        "\n",
        "# Send the request, parse the response, save logs to a file\n",
        "response = session.get(uri)\n",
        "\n",
        "if response.status_code == 200:\n",
        "  live_parsers = response.json()\n",
        "\n",
        "  index = 0\n",
        "  if \"cbnParsers\" in live_parsers:\n",
        "    for parser in live_parsers['cbnParsers']:\n",
        "      print(\"Type: {type}\\nAuthor:{author}\\nState:{state}\\nIndex: {index}\\n\".format(author= parser['author'], state= parser[\"state\"], type= parser[\"logType\"], index=index))\n",
        "      index += 1\n",
        "  else:\n",
        "    print(\"There don't appear to be any live custom parsers at the moment.\")\n",
        "else:\n",
        "  # something went wrong\n",
        "  print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fKmaJZUs7RJ"
      },
      "outputs": [],
      "source": [
        "#@title Get Sample Logs\n",
        "\n",
        "uri = f'https://{region_prefix}backstory.googleapis.com/v1/tools:retrieveSampleLogs'\n",
        "\n",
        "max_entries = 1000 #@param {type: \"number\"}\n",
        "log_type = \"IBM_SAM\" #@param {type:\"string\"}\n",
        "\n",
        "startDate = \"2021-11-01\" #@param {type: \"date\"}\n",
        "endDate = \"2023-07-19\" #@param {type: \"date\"}\n",
        "\n",
        "#@markdown Time should be in the format HH:MM:SS including leading zeros\n",
        "startTime = \"00:00:01\" #@param {type: \"string\"}\n",
        "endTime = \"23:59:59\" #@param {type: \"string\"}\n",
        "\n",
        "startTime = f\"{startDate}T{startTime}Z\"\n",
        "endTime = f\"{endDate}T{endTime}Z\"\n",
        "\n",
        "# define the logType, ingestion start and end, and the maximum number or records to return.\n",
        "data = {\n",
        "  'log_type': log_type,\n",
        "  'start_time': startTime,\n",
        "  'end_time': endTime,\n",
        "  'max_entries': max_entries\n",
        "}\n",
        "\n",
        "headers= {\n",
        "  \"Content-type\": \"application/x-www-form-urlencoded\"\n",
        "}\n",
        "\n",
        "# Send the request, parse the response, save logs to a file\n",
        "response = session.post(uri, params=data, headers=headers)\n",
        "\n",
        "# ToDo: replace this value with you own\n",
        "file_name = 'PAN_PRISMA_CA.logs' #@param {type: \"string\"}\n",
        "\n",
        "#check if file already exists, if it does delete it to prevent confusion\n",
        "if file_name in os.listdir():\n",
        "  os.remove(file_name)\n",
        "\n",
        "download_file = False #@param {\"type\": \"boolean\"}\n",
        "if response.status_code == 200:\n",
        "  sample_logs = response.json()\n",
        "  sample_logs_data = sample_logs.get('data', [])\n",
        "  if len(sample_logs_data) == 0:\n",
        "    print(\"No logs returned for selected time.\")\n",
        "  else:\n",
        "    for sample_log in sample_logs_data:\n",
        "      f = open(file_name, 'a')\n",
        "      f.write(base64.b64decode(sample_log).decode())\n",
        "      f.write('\\n')\n",
        "      f.close()\n",
        "      # print(base64.b64decode(sample_log).decode())\n",
        "    print(\"{} entries have been writen to filename: {} \".format(len(sample_logs_data), file_name))\n",
        "    if download_file:\n",
        "      files.download(file_name)\n",
        "else:\n",
        "  # something went wrong\n",
        "  print(response.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "imdtIZqs5QGw"
      },
      "outputs": [],
      "source": [
        "#@title Get parser history\n",
        "\n",
        "# logType identifying the parser\n",
        "log_type = 'DNS_SINKHOLE' #@param {type: \"string\"}\n",
        "\n",
        "uri = f'https://{region_prefix}backstory.googleapis.com/v1/tools/cbnParsers:listCbnParserHistory?log_type={log_type}'\n",
        "# send the request and process the response\n",
        "resp = session.get(uri)\n",
        "json_resp = resp.json()\n",
        "# show the parser history\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp['error'])\n",
        "else:\n",
        "  print(\"{:36s} {:15s} {:10s} {:25s}\".format(\"configId\",\"logType\",\"state\",\"stateLastChangedTime\"))\n",
        "  for item in json_resp['cbnParsers']:\n",
        "    print(\"{:36s} {:15s} {:10s} {:25s}\".format(item['configId'], item['logType'], item['state'], item['stateLastChangedTime']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PXtlV_-R6fPR"
      },
      "outputs": [],
      "source": [
        "#@title Test parser\n",
        "#@markdown Enter the filename of the CBN to test\n",
        "parser_conf_file = \"parser.conf\" #@param {type: \"string\"}\n",
        "#@markdown Enter the filename of the testdata\n",
        "test_data_file = \"sample.log\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Choose whether to write the output data to a file and then whether to download that file.\n",
        "write_to_file = False #@param {type: \"boolean\"}\n",
        "download_file = False #@param {type: \"boolean\"}\n",
        "\n",
        "file_name = \"parser_output.blah\" #@param {type: \"string\"}\n",
        "also_write_to_screen = False #@param {type: \"boolean\"}\n",
        "\n",
        "uri = f'https://{region_prefix}backstory.googleapis.com/v1/tools:validateCbnParser'\n",
        "\n",
        "conf_file = open(parser_conf_file, 'rb')\n",
        "conf_data = conf_file.read()\n",
        "conf_file.close()\n",
        "\n",
        "log_file = open(test_data_file, 'rb')\n",
        "log_data = log_file.read()\n",
        "log_file.close()\n",
        "\n",
        "data = {\n",
        "    'config' : base64.urlsafe_b64encode(conf_data).decode(),\n",
        "    'logs' : base64.urlsafe_b64encode(log_data).decode()\n",
        "}\n",
        "\n",
        "r_headers = {}\n",
        "r_headers.update({'Content-type' : 'application/x-www-form-urlencoded'})\n",
        "\n",
        "resp = session.post(uri,  data=data, headers=r_headers)\n",
        "\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  if write_to_file:\n",
        "    with open(file_name, \"w\") as output_file:\n",
        "      output_file.write(resp.text)\n",
        "      if also_write_to_screen:\n",
        "        pprint(resp.json())\n",
        "    if download_file:\n",
        "      files.download(file_name)\n",
        "  else:\n",
        "    pprint(resp.json())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4J2jL6EnhlQ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a1a9fee-c1a4-45a3-adcf-f9b37f864038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parser written to IBM_CLOUD_ACTIVITY_TRACKER.conf\n"
          ]
        }
      ],
      "source": [
        "#@title Get a single CBN parser\n",
        "# Unique configuration identifier assigned to the parser when it was submitted\n",
        "# ToDo: Replace this value with your own.\n",
        "\n",
        "#@markdown Config_id can either be an ID of a custom parser or the name of a default parser (for example: OKTA)\n",
        "# config ID list taken from ingest API get support log types endpoint\n",
        "config_id = \"IBM_CLOUD_ACTIVITY_TRACKER\" #@param ['A10_LOAD_BALANCER', 'ABNORMAL_SECURITY', 'ABSOLUTE', 'ACALVIO', 'ACCELLION', 'ACCOPS_HYSECURE_VPN', 'ACQUIA_CLOUD_PLATFORM', 'ACRONIS', 'ACTIVE_SYNC', 'ADAUDIT_PLUS', 'ADAXES', 'ADFS', 'ADMANAGER_PLUS', 'ADMIN_BY_REQUEST', 'ADOBE_COMMERCE', 'ADOBE_EXPERIENCE_MANAGER', 'ADSELFSERVICE_PLUS', 'ADTRAN_NETVANTA', 'ADVA_FSP', 'AGARI_PHISHING_DEFENSE', 'AIDE', 'AIRDEFENSE', 'AIRLOCK_DIGITAL', 'AIRWATCH', 'AIR_TABLE', 'AIX_SYSTEM', 'AI_HUNTER', 'AKAMAI_CLOUD_MONITOR', 'AKAMAI_DDOS', 'AKAMAI_DHCP', 'AKAMAI_DNS', 'AKAMAI_EAA', 'AKAMAI_ETP', 'AKAMAI_GUARDICORE', 'AKAMAI_SIEM_CONNECTOR', 'AKAMAI_WAF', 'AKEYLESS_VAULT', 'ALCATEL_SWITCH', 'ALERTLOGIC_NOTIFICATIONS', 'ALERT_GUARDIAN', 'ALGOSEC', 'ALICLOUD_ANTI_DDOS', 'ALICLOUD_WAF', 'ALIENVAULT_OTX', 'ALLOT_NETENFORCER', 'ALVEO_RDM', 'AMAVIS', 'AMD_DSS_FIREWALL', 'ANALYST1_IOC', 'ANOMALI_IOC', 'ANSIBLE_AWX', 'APACHE', 'APACHE_KAFKA_AUDIT', 'APACHE_SPAMASSASSIN', 'APC_ATS', 'APC_NETBOTZ', 'APC_PDU', 'APC_SMART_UPS', 'APC_STRUXUREWARE', 'APIIRO', 'APPGATE_SDP', 'APPIAN_CLOUD', 'APPOMNI', 'APPVIEWX', 'APTOS_EOM', 'AQUA_SECURITY', 'ARBOR_EDGE_DEFENSE', 'ARBOR_SIGHTLINE', 'ARCHER_IRM', 'ARCSIGHT_CEF', 'AREA1', 'ARGO_CD', 'ARGO_WORKFLOWS', 'ARISTA_AGNI', 'ARISTA_CVP', 'ARISTA_NDR', 'ARISTA_SWITCH', 'ARKIME_PCAP', 'ARMIS', 'ARMIS_ACTIVITIES', 'ARMIS_ALERTS', 'ARMIS_DEVICES', 'ARMIS_VULNERABILITIES', 'ARMORBLOX_ESC', 'ARMOR_ANYWHERE', 'ARRAYNETWORKS_VPN', 'ARRAY_NETWORKS_WAF', 'ARUBA_AIRWAVE', 'ARUBA_CENTRAL', 'ARUBA_EDGECONNECT_SDWAN', 'ARUBA_IPS', 'ARUBA_ORCHESTRATOR', 'ARUBA_SWITCH', 'ARUBA_WIRELESS', 'ARXAN_THREAT_ANALYTICS', 'ASANA', 'ASCERTIA', 'ASIMILY', 'ASOC_ALERT', 'ASSETNOTE', 'ASSET_STATIC_IP', 'ATLASSIAN_AUDIT', 'ATLASSIAN_BEACON', 'ATLASSIAN_BITBUCKET', 'ATLASSIAN_CONFLUENCE', 'ATLASSIAN_CONFLUENCE_JSON', 'ATLASSIAN_JIRA', 'ATLASSIAN_JIRA_JSON', 'ATTIVO', 'ATT_NETBOND', 'AUDITD', 'AUTHENTIC8_SILO', 'AUTHX', 'AUTHX_USER_CONTEXT', 'AUTH_ZERO', 'AUTOMATION_ANYWHERE', 'AUTOMOX_EPM', 'AVANAN_EMAIL', 'AVAST_HUB', 'AVATIER', 'AVAYA_AURA', 'AVAYA_BORDER', 'AVAYA_IVR', 'AVAYA_VSP', 'AVAYA_WIRELESS', 'AVIATRIX', 'AWAKE_NDR', 'AWS_AURORA', 'AWS_CLOUDFRONT', 'AWS_CLOUDTRAIL', 'AWS_CLOUDWATCH', 'AWS_CONFIG', 'AWS_CONTROL_TOWER', 'AWS_DYNAMO_DB', 'AWS_EC2_HOSTS', 'AWS_EC2_INSTANCES', 'AWS_EC2_VPCS', 'AWS_ELASTI_CACHE', 'AWS_ELB', 'AWS_EMR', 'AWS_FSX', 'AWS_IAM', 'AWS_INSPECTOR', 'AWS_INSPECTOR2', 'AWS_KMS', 'AWS_MACIE', 'AWS_NETWORK_FIREWALL', 'AWS_NGINX', 'AWS_RDS', 'AWS_REDSHIFT', 'AWS_ROUTE_53', 'AWS_S3_SERVER_ACCESS', 'AWS_SECURITY_HUB', 'AWS_SES', 'AWS_SESSION_MANAGER', 'AWS_SHIELD', 'AWS_VPC_FLOW', 'AWS_VPN', 'AWS_WAF', 'AXIS_ATMOS', 'AXIS_OS', 'AXONIUS', 'AZION', 'AZURE', 'AZURE_ACTIVITY', 'AZURE_AD', 'AZURE_AD_AUDIT', 'AZURE_AD_CONTEXT', 'AZURE_AD_PASSWORD_PROTECTION', 'AZURE_AD_PROVISIONING', 'AZURE_AD_SIGNIN', 'AZURE_API_MANAGEMENT', 'AZURE_APP_SERVICE', 'AZURE_ATP', 'AZURE_BASTION', 'AZURE_COSMOS_DB', 'AZURE_DEVOPS', 'AZURE_DNS', 'AZURE_FIREWALL', 'AZURE_FRONT_DOOR', 'AZURE_GATEWAY', 'AZURE_KEYVAULT_AUDIT', 'AZURE_MDM_INTUNE', 'AZURE_MDM_INTUNE_CONTEXT', 'AZURE_NSG_FLOW', 'AZURE_RESOURCE_LOGS', 'AZURE_SECURITY_CENTER', 'AZURE_SQL', 'AZURE_STORAGE_AUDIT', 'AZURE_VPN', 'AZURE_WAF', 'BABELFORCE', 'BACKBOX', 'BALABIT', 'BAMBOO_HR', 'BANNER_DD', 'BARRACUDA_CLOUDGEN_ACCESS', 'BARRACUDA_CLOUDGEN_FIREWALL', 'BARRACUDA_EMAIL', 'BARRACUDA_FIREWALL', 'BARRACUDA_IMPERSONATION', 'BARRACUDA_SHIELD', 'BARRACUDA_WAF', 'BARRACUDA_WEBFILTER', 'BETTERCLOUD', 'BEYONDTRUST_BEYONDINSIGHT', 'BEYONDTRUST_CPB', 'BEYONDTRUST_ENDPOINT', 'BEYONDTRUST_MC', 'BEYONDTRUST_PI', 'BEYONDTRUST_REMOTE_ACCESS', 'BEYOND_IDENTITY', 'BIGSWITCH_BCF', 'BIND_DNS', 'BITDEFENDER', 'BITVISE_SSHD', 'BITWARDEN_EVENTS', 'BLACKBERRY_WORKSPACES', 'BLOXONE', 'BLUECAT_AM', 'BLUECAT_DDI', 'BLUECAT_EDGE', 'BLUECOAT_WEBPROXY', 'BLUE_PRISM', 'BMC_AMI_DEFENDER', 'BMC_CLIENT_MANAGEMENT', 'BMC_CONTROL_M', 'BMC_HELIX_DISCOVERY', 'BOKS', 'BOMGAR', 'BOX', 'BRICATA_NDR', 'BRITIVE_AUDIT_API', 'BRIVO', 'BROADCOM_CA_PAM', 'BROADCOM_CEM', 'BROADCOM_SSL_VA', 'BROADCOM_SUPPORT_PORTAL', 'BROCADE_FOS', 'BROCADE_SANNAV', 'BROCADE_SERVERIRON', 'BROCADE_SWITCH', 'BRO_DHCP', 'BRO_HTTP', 'BRO_JSON', 'BRO_TSV', 'BT_IPCONTROL', 'BURPSUITE', 'CAMBIUM_NETWORKS', 'CAMEYO_BYO_CLOUD', 'CANARY_AUDIT_TRAIL', 'CASSANDRA', 'CATO_NETWORKS', 'CATO_SDWAN', 'CA_ACCESS_CONTROL', 'CA_ACF2', 'CA_LDAP', 'CA_SSO_WEB', 'CB_APP_CONTROL', 'CB_EDR', 'CENSORNET_CASB', 'CENSYS', 'CENTRIFY_SSO', 'CENTRIPETAL_IOC', 'CEQUENCE_BOT_DEFENSE', 'CERBERUS_FTP', 'CHECKPOINT_CLOUDGUARD', 'CHECKPOINT_EDR', 'CHECKPOINT_EMAIL', 'CHECKPOINT_FIREWALL', 'CHECKPOINT_GAIA', 'CHECKPOINT_HARMONY', 'CHECKPOINT_SMARTDEFENSE', 'CHRONICLE_SOAR_AUDIT', 'CILIUM', 'CIPHERTRUST_MANAGER', 'CIRCLECI', 'CISCO_ACE', 'CISCO_ACI', 'CISCO_ACS', 'CISCO_AIRONET', 'CISCO_AMP', 'CISCO_APIC', 'CISCO_ASA_FIREWALL', 'CISCO_CALL_MANAGER', 'CISCO_CLOUDLOCK_CASB', 'CISCO_CTS', 'CISCO_CYBER_VISION', 'CISCO_DHCP', 'CISCO_DNAC', 'CISCO_DNS', 'CISCO_EMAIL_SECURITY', 'CISCO_ESTREAMER', 'CISCO_FIREPOWER_FIREWALL', 'CISCO_FIRESIGHT', 'CISCO_FWSM', 'CISCO_IOS', 'CISCO_IRONPORT', 'CISCO_ISE', 'CISCO_MERAKI', 'CISCO_MERAKI_CAMERA', 'CISCO_NX_OS', 'CISCO_PIX_FIREWALL', 'CISCO_PRIME', 'CISCO_ROUTER', 'CISCO_SDWAN', 'CISCO_SECURE_MALWARE_ANALYTICS', 'CISCO_SECURE_WORKLOAD', 'CISCO_SMA', 'CISCO_SNMP', 'CISCO_STADIUMVISION', 'CISCO_STEALTHWATCH', 'CISCO_SWITCH', 'CISCO_TACACS', 'CISCO_UCM', 'CISCO_UCS', 'CISCO_UMBRELLA_AUDIT', 'CISCO_UNITY_CONNECTION', 'CISCO_VCS', 'CISCO_VPN', 'CISCO_WIPS', 'CISCO_WIRELESS', 'CISCO_WSA', 'CISCO_WSM', 'CISCO_XDR', 'CIS_ALBERT_ALERT', 'CITRIX_ANALYTICS', 'CITRIX_MONITOR', 'CITRIX_NETSCALER', 'CITRIX_NETSCALER_WEB_LOGS', 'CITRIX_SDWAN', 'CITRIX_SESSION_METADATA', 'CITRIX_STOREFRONT', 'CITRIX_VDI', 'CITRIX_WAF', 'CITRIX_WEB_GATEWAY', 'CITRIX_WORKSPACE', 'CITRIX_XENCENTER', 'CLAM_AV', 'CLAROTY_CTD', 'CLAROTY_EMC', 'CLAROTY_XDOME', 'CLEARPASS', 'CLEARSENSE', 'CLEARSWIFT', 'CLICK_STUDIOS_PASSWORDSTATE', 'CLOUDAWARE', 'CLOUDBEES', 'CLOUDBOLT', 'CLOUDFLARE', 'CLOUDFLARE_AUDIT', 'CLOUDFLARE_BOT_MANAGEMENT', 'CLOUDFLARE_WAF', 'CLOUDGENIX_SDWAN', 'CLOUDIAN_HYPERSTORE', 'CLOUDM', 'CLOUDPASSAGE_CSM', 'CLOUDPASSAGE_FIM', 'CLOUDPASSAGE_LIDS', 'CLOUDPASSAGE_SVM', 'CLOUD_IDENTITY_CONTEXT', 'CLOUD_PASSAGE', 'CMD', 'COALITION', 'COCKROACH_DB', 'CODE42', 'CODE42_INCYDR', 'CODE_WORLDWIDE', 'COFENSE_TRIAGE', 'COFENSE_VISION', 'COHESITY', 'COHESITY_HELIOS', 'COHESITY_SMARTFILES', 'COMMVAULT', 'COMMVAULT_COMMCELL', 'COMMVAULT_METALLIC', 'COMODO_AV', 'CONFLUENT_AUDIT', 'CONNECTWISE_AUTOMATE', 'CONNECTWISE_CONTROL', 'CORELIGHT', 'CORRATA', 'CORTEX_XDR', 'COVID_CTC_IOC', 'CRADLEPOINT_NETCLOUD', 'CRIBL_APPSCOPE', 'CRIBL_CLOUD', 'CRIBL_EDGE', 'CRIBL_SEARCH', 'CRIBL_STREAM', 'CROWDSTRIKE_IOC', 'CRYPTOSPIKE', 'CSG_CUSTOMENGINE', 'CSG_SINGLEVIEW', 'CSV_CUSTOM_CMDB', 'CSV_CUSTOM_IOC', 'CS_CEF_EDR', 'CS_DETECTS', 'CS_EDR', 'CS_IDP', 'CS_STREAM', 'CTERA_DRIVE', 'CULTURE_AI', 'CUSTOMER_ALERT', 'CUSTOM_APPLICATION_ACCESS', 'CUSTOM_DNS', 'CUSTOM_HOST_FORENSICS', 'CUSTOM_SECURITY_DATA_ANALYTICS', 'CYBERARK', 'CYBERARK_EPM', 'CYBERARK_PAM', 'CYBERARK_PRIVILEGE_CLOUD', 'CYBERARK_SSO', 'CYBERCNS', 'CYBEREASON_EDR', 'CYBERGATEKEEPER_NAC', 'CYBERHAVEN_DDR', 'CYBERHAVEN_EVENTS', 'CYBERINT', 'CYBERX', 'CYBER_2_IDS', 'CYCODE', 'CYDERES_INSIDER', 'CYDERES_IOC', 'CYLANCE', 'CYLANCE_PROTECT', 'CYLERA_IOT', 'CYMULATE', 'CYNET_360_AUTOXDR', 'CYOLO_ZTNA', 'D3_BANKING', 'D3_SECURITY', 'DARKTRACE', 'DATABRICKS', 'DATADOG', 'DATAIKU_DSS_LOGS', 'DATALOCKER_SAFECONSOLE', 'DATALUST', 'DATAMINR_ALERT', 'DATASUNRISE_DAM', 'DATAWATCH', 'DATTO_FILE_PROTECTION', 'DB2_DB', 'DEAL_CLOUD', 'DEEPFENCE', 'DEEP_INSTINCT_EDR', 'DELINEA_PAM', 'DELINEA_PRIVILEGE_MANAGER', 'DELINEA_SECRET_SERVER', 'DELINEA_SERVER_SUITE', 'DELL_COMPELLENT', 'DELL_CRM', 'DELL_CYBERSENSE', 'DELL_ECS', 'DELL_EMC_AVAMAR', 'DELL_EMC_CLOUDLINK', 'DELL_EMC_DATA_DOMAIN', 'DELL_EMC_NAS', 'DELL_EMC_POWERSTORE', 'DELL_EMC_UNITY', 'DELL_OPENMANAGE', 'DELL_SWITCH', 'DELL_WAF', 'DESIGN_PROFIT_CENTRAL_SERVER', 'DESYNOVA_CONTIDO', 'DEVICE_42', 'DEVOLUTIONS_RDM', 'DHS_IOC', 'DIGITALARTS_IFILTER', 'DIGITALGUARDIAN_DLP', 'DIGITALGUARDIAN_EDR', 'DIGITAL_SHADOWS_IOC', 'DIGITAL_SHADOWS_SEARCHLIGHT', 'DIGI_MODEMS', 'DIVVY_CLOUD', 'DMARCIAN', 'DMP_ENTRE', 'DNSFILTER', 'DOCKER', 'DOCUSIGN', 'DOMAINTOOLS_THREATINTEL', 'DOMO', 'DOPE_SWG', 'DRAGOS', 'DRAYTEK', 'DREMIO_DATA_LAKEHOUSE', 'DROPBOX', 'DRUPAL', 'DRUVA_BACKUP', 'DSP_AUDIT', 'DTEX_INTERCEPT', 'DUO_ACTIVITY', 'DUO_ADMIN', 'DUO_AUTH', 'DUO_CASB', 'DUO_CONTEXT', 'DUO_NETWORK_GATEWAY', 'DUO_TELEPHONY', 'DUO_TRUST_MONITOR', 'DUO_USER_CONTEXT', 'DYNATRACE', 'E2_GUARDIAN', 'E2_SOLUTIONS', 'EATON_UPS', 'ECAR', 'ECAR_BRO', 'EDGECORE_NETWORKS', 'EDGIO_CDN', 'EDGIO_RL', 'EDGIO_WAF', 'EFAX', 'EFFICIENTIP_DDI', 'EGNYTE', 'EGRESS_DEFEND', 'EGRESS_PREVENT', 'EIQ_EDR', 'ELASTIC_AUDITBEAT', 'ELASTIC_FILEBEAT', 'ELASTIC_METRICBEAT', 'ELASTIC_PACKETBEATS', 'ELASTIC_SEARCH', 'ELASTIC_WINLOGBEAT', 'EMERSON_FIREWALL', 'EMSISOFT_ANTIVIRUS', 'ENDGAME_EDR', 'ENDPOINT_PROTECTOR_DLP', 'ENSONO', 'ENTRUST_HSM', 'ENTRUST_NTP_SERVER', 'ENTRUST_SECRETS_VAULT', 'EPIC', 'ERLANG_SHELL', 'ERMES', 'ERMETIC', 'ESET_AV', 'ESET_EDR', 'ESET_IOC', 'ESHARE_PLATFORM', 'ESTAR', 'ETQ_RELIANCE', 'ET_PRO_IOC', 'EVIDOS_FIREWALL', 'EVISION_FIRCOSOFT', 'EXABEAM_FUSION_XDR', 'EXCHANGE_MAIL', 'EXTRAHOP', 'EXTRAHOP_DHCP', 'EXTRAHOP_DNS', 'EXTREMEWARE_NETWORKS', 'EXTREME_CONTROL', 'EXTREME_MANAGEMENT', 'EXTREME_SWITCH', 'EXTREME_WIRELESS', 'EZPROXY', 'F5_AFM', 'F5_ASM', 'F5_BIGIP_APM', 'F5_BIGIP_LTM', 'F5_BOT', 'F5_DCS', 'F5_DNS', 'F5_IP_INTELLIGENCE', 'F5_SHAPE', 'F5_SILVERLINE', 'F5_VPN', 'FAIL2BAN', 'FALCO_IDS', 'FARSIGHT_DNSDB', 'FASTLY_WAF', 'FEENICS_ACCESS_CONTROL', 'FIDELIS_ENDPOINT', 'FIDELIS_NETWORK', 'FILEMAGE_SFTP', 'FILEZILLA_FTP', 'FILE_SCANNING_FRAMEWORK', 'FIREBASE', 'FIREEYE_ALERT', 'FIREEYE_CMS', 'FIREEYE_EMPS', 'FIREEYE_ETP', 'FIREEYE_HELIX', 'FIREEYE_HX', 'FIREEYE_HX_AUDIT', 'FIREEYE_NX', 'FIREEYE_PX', 'FIREMON_FIREWALL', 'FISGLOBAL_QUANTUM', 'FIVETRAN', 'FLASHPOINT_IOC', 'FLEET_DM', 'FLUENTD', 'FORCEPOINT_CASB', 'FORCEPOINT_DLP', 'FORCEPOINT_EMAILSECURITY', 'FORCEPOINT_FIREWALL', 'FORCEPOINT_FIT', 'FORCEPOINT_MAIL_RELAY', 'FORCEPOINT_VSERIES', 'FORCEPOINT_WEBPROXY', 'FORESCOUT_NAC', 'FORGEROCK_IDENTITY_CLOUD', 'FORGEROCK_OPENIDM', 'FORSETI', 'FORTANIX_DSM', 'FORTINET_AP', 'FORTINET_DHCP', 'FORTINET_FIREWALL', 'FORTINET_FORTIANALYZER', 'FORTINET_FORTIAUTHENTICATOR', 'FORTINET_FORTICLIENT', 'FORTINET_FORTIEDR', 'FORTINET_FORTIMAIL', 'FORTINET_FORTINAC', 'FORTINET_FORTIWEB', 'FORTINET_SANDBOX', 'FORTINET_SWITCH', 'FORTINET_WEBPROXY', 'FORTRA_POWERTECH_SIEM_AGENT', 'FOUNDRY_FASTIRON', 'FOX_IT_STIX', 'FREEIPA', 'FREERADIUS', 'FRONTLINE_VM', 'FS_ISAC_IOC', 'FUTUREX_HSM', 'GCP_APIGEE', 'GCP_APIGEE_X', 'GCP_APP_ENGINE', 'GCP_ARTIFACT_REGISTRY', 'GCP_BIGQUERY_CONTEXT', 'GCP_CLOUDAUDIT', 'GCP_CLOUDIDENTITY_DEVICES', 'GCP_CLOUDIDENTITY_DEVICEUSERS', 'GCP_CLOUDIOT', 'GCP_CLOUDSQL', 'GCP_CLOUD_FUNCTIONS_CONTEXT', 'GCP_CLOUD_NAT', 'GCP_COMPUTE', 'GCP_COMPUTE_CONTEXT', 'GCP_DNS', 'GCP_FIREWALL', 'GCP_IAM_ANALYSIS', 'GCP_IAM_CONTEXT', 'GCP_IDS', 'GCP_KUBERNETES_CONTAINER_SECURITY', 'GCP_KUBERNETES_CONTEXT', 'GCP_LOADBALANCING', 'GCP_NETWORK_CONNECTIVITY_CONTEXT', 'GCP_NGFW_ENTERPRISE', 'GCP_RECAPTCHA_ENTERPRISE', 'GCP_RESOURCE_MANAGER_CONTEXT', 'GCP_RUN', 'GCP_SECURITYCENTER_POSTURE_VIOLATION', 'GCP_SECURITYCENTER_TOXIC_COMBINATION', 'GCP_SQL_CONTEXT', 'GCP_STORAGE_CONTEXT', 'GCP_SWP', 'GCP_THREAT_DETECTION', 'GCP_VPC_FLOW', 'GENETEC_AUDIT', 'GIGAMON', 'GIGYA_CIAM', 'GITGUARDIAN_ENTERPRISE', 'GITHUB', 'GITHUB_EVENTS', 'GITLAB', 'GLEAN', 'GLOBALSCAPE_SFTP', 'GLUSTER_FS', 'GMAIL_LOGS', 'GMV_CHECKER', 'GMV_CHECKER_CONTEXT', 'GOANYWHERE_MFT', 'GODADDY_DNS', 'GOLDILOCK', 'GOOGLE_ADS', 'GRAYHATWARFARE', 'GRAYLOG', 'GREATHORN', 'GREYNOISE', 'GTB_DLP', 'GUARDDUTY', 'GUARDICORE_CENTRA', 'GUARDIUM', 'GURUCUL', 'H3C_SWITCH', 'HADOOP', 'HALCYON', 'HALO', 'HAPROXY', 'HAPROXY_LOADBALANCER', 'HARBOR', 'HARFANGLAB_EDR', 'HASHICORP', 'HCL_BIGFIX', 'HCNET_ACCOUNT_ADAPTER', 'HIBOB', 'HIBP', 'HIRSCHMANN_SWITCH', 'HITACHI_CLOUD_PLATFORM', 'HITACHI_ID_PAM', 'HONEYD', 'HORNET_SECURITY', 'HPE_BLADESYSTEM_C7000', 'HPE_ILO', 'HPE_SAN', 'HP_ONEVIEW', 'HP_POLY', 'HP_PRINTER', 'HP_PROCURVE', 'HP_WOLF', 'HUAWEI_NAC', 'HUBSPOT_ACTIVITY', 'HUBSPOT_CRM', 'HUBSPOT_LOGIN', 'HYPR_MFA', 'IBM_3COM', 'IBM_AS400', 'IBM_CICS', 'IBM_CLEVERSAFE', 'IBM_DATAPOWER', 'IBM_DS8000', 'IBM_I', 'IBM_KNS', 'IBM_LTO', 'IBM_MAAS360', 'IBM_MAINFRAME_STORAGE', 'IBM_MQ_FILE_TRANSFER', 'IBM_QRADAR', 'IBM_SAFENET', 'IBM_SAM', 'IBM_SECURITY_VERIFY', 'IBM_SECURITY_VERIFY_SAAS', 'IBM_SIM', 'IBM_SOAR', 'IBM_SPECTRUM_PROTECT', 'IBM_SWITCH', 'IBM_TIVOLI', 'IBM_TRIRIGA', 'IBM_WEBSEAL', 'IBM_WEBSPHERE_APP_SERVER', 'IBM_WINCOLLECT', 'IBM_ZOS', 'IBM_ZSECURE_ALERT', 'IBOSS_WEBPROXY', 'IDECSI', 'IDRAC', 'IIS', 'ILLUMIO_CORE', 'IMAGENOW', 'IMANAGE_CLOUD', 'IMPERVA_ABP', 'IMPERVA_AUDIT_TRAIL', 'IMPERVA_CEF', 'IMPERVA_DB', 'IMPERVA_FLEXPROTECT', 'IMPERVA_SECURESPHERE', 'IMPERVA_SONAR', 'IMPERVA_WAF', 'IMPRIVATA_CONFIRM_ID', 'IMPRIVATA_IDG', 'IMPRIVATA_ONESIGN', 'INFINICO_NETWYVERN', 'INFINIDAT', 'INFOBLOX', 'INFOBLOX_DHCP', 'INFOBLOX_DNS', 'INFOBLOX_LOADBALANCER', 'INFOBLOX_NETMRI', 'INFOBLOX_RPZ', 'INFORMIX', 'INKY', 'INTERSYSTEMS_CACHE', 'INTRUDER_IO', 'INWEBO_MFA', 'IONIX', 'ION_SPECTRUM', 'IPSWITCH_MOVEIT_AUTOMATION', 'IPSWITCH_MOVEIT_TRANSFER', 'IPSWITCH_SFTP', 'IRONSCALES', 'ISC_DHCP', 'ISLAND_BROWSER', 'IVANTI_APP_CONTROL', 'IVANTI_CONNECT_SECURE', 'IVANTI_DEVICE_CONTROL', 'IVANTI_XTRACTION', 'JAMF', 'JAMF_COMPLIANCE_REPORTER', 'JAMF_NETWORK_TRAFFIC', 'JAMF_PRO', 'JAMF_PROTECT', 'JAMF_PRO_CONTEXT', 'JAMF_PRO_MDM', 'JAMF_TELEMETRY', 'JAMF_THREAT_EVENTS', 'JDE', 'JENKINS', 'JOURNALD', 'JUMPCLOUD_DAAS', 'JUMPCLOUD_DESKTOP', 'JUMPCLOUD_DIRECTORY_INSIGHTS', 'JUNIPER_FIREWALL', 'JUNIPER_IPS', 'JUNIPER_JUNOS', 'JUNIPER_MIST', 'JUNIPER_MX', 'JUNIPER_SDWAN', 'JUNIPER_VPN', 'JUPITER_ONE', 'KACE_SERVICE_DESK', 'KACE_SMA', 'KAMAILIO', 'KANDJI', 'KASEYA', 'KASPERSKY_AV', 'KASPERSKY_ENDPOINT', 'KEA_DHCP', 'KEEPALIVED', 'KEEPER', 'KEMP_LOADBALANCER', 'KERIOCONTROL', 'KEYCLOAK', 'KEYFACTOR', 'KEYSIGHT', 'KIBANA', 'KION', 'KISI', 'KITEWORKS', 'KNOWBE4_PHISHER', 'KOLIDE', 'KONG_GATEWAY', 'KUBERNETES_AUDIT', 'KUBERNETES_AUDIT_AZURE', 'KUBERNETES_AUTH_PROXY', 'KUBERNETES_NODE', 'KUSTOMER_CRM', 'KYRIBA', 'LACEWORK', 'LANSWEEPER', 'LASTPASS', 'LAUNCH_DARKLY', 'LB_ADC', 'LEANIX', 'LEANIX_CMDB', 'LENEL_ONGUARD', 'LEPIDE', 'LEXMARK_PRINTER', 'LIAISON_NUBRIDGES', 'LIBRAESVA_EMAIL', 'LIMACHARLIE_EDR', 'LINUX_DHCP', 'LINUX_SYSMON', 'LIRA', 'LOGICMONITOR', 'LOGONBOX', 'LOOKER_AUDIT', 'LOOKINGGLASS_IPS', 'LOOKING_GLASS_IOC', 'LOOKOUT_MOBILE_ENDPOINT_SECURITY', 'LSI_BMS', 'LUMEN_DDOS_HYPER', 'LUMETA', 'LUMOS', 'LXC_ORCHESTRATOR', 'MACOS', 'MACOS_ENDPOINT_SECURITY', 'MAILMARSHAL', 'MAILSCANNER', 'MALWAREBYTES_EDR', 'MAMBU', 'MANAGEENGINE_ENDPOINT', 'MANAGEENGINE_RAP', 'MANAGE_ENGINE_AD360', 'MANAGE_ENGINE_PAM360', 'MANAGE_ENGINE_PASSWORD_MANAGER', 'MANAGE_ENGINE_REPORTER_PLUS', 'MANDIANT_ASM_ENTITY', 'MANDIANT_ASM_ISSUE', 'MANDIANT_ASM_TECHNOLOGY', 'MANDIANT_CUSTOM_IOC', 'MANGOAPPS', 'MANHATTAN_WMS', 'MARIA_DB', 'MATERIAL_SECURITY', 'MATRIX_FRONTIER', 'MATTERMOST', 'MCAFEE_APP_CONTROL', 'MCAFEE_ATD', 'MCAFEE_DLP', 'MCAFEE_EDR', 'MCAFEE_EPO', 'MCAFEE_ESM', 'MCAFEE_IPS', 'MCAFEE_MVISION_CASB', 'MCAFEE_SKYHIGH_CASB', 'MCAFEE_SOLID_CORE', 'MCAFEE_UCE', 'MCAFEE_WEBPROXY', 'MCAFEE_WEB_PROTECTION', 'MEDIGATE_CMDB', 'MEDIGATE_IOT', 'MELISSA', 'MENANDMICE_DNS', 'MEND_IO', 'MENLO_SECURITY', 'META_MARKETING', 'MIASMA_SECRETSCANNER', 'MICROFOCUS_IMANAGER', 'MICROSEMI_NTP', 'MICROSOFT_ADS', 'MICROSOFT_ATA', 'MICROSOFT_CASB', 'MICROSOFT_CASB_CONTEXT', 'MICROSOFT_DEFENDER_CLOUD_ALERTS', 'MICROSOFT_DEFENDER_ENDPOINT', 'MICROSOFT_DEFENDER_IDENTITY', 'MICROSOFT_DYNAMICS_365', 'MICROSOFT_EASM', 'MICROSOFT_GRAPH_ACTIVITY_LOGS', 'MICROSOFT_GRAPH_ALERT', 'MICROSOFT_IAS', 'MICROSOFT_IDENTITY_PROTECTION', 'MICROSOFT_LAPS', 'MICROSOFT_NETLOGON', 'MICROSOFT_NPS', 'MICROSOFT_POWERBI_ACTIVITY_LOG', 'MICROSOFT_RISK_DETECTIONS', 'MICROSOFT_SCEP', 'MICROSOFT_SECURITY_ACTIONS', 'MICROSOFT_SECURITY_ALERTS', 'MICROSOFT_SENTINEL', 'MICROSOFT_SQL', 'MICROSOFT_SSTP', 'MICROSOFT_THREAT_INDICATORS', 'MIKROTIK_ROUTER', 'MIMECAST_ATTACHMENT_LOGS', 'MIMECAST_AUDIT_LOGS', 'MIMECAST_DLP_LOGS', 'MIMECAST_IMPERSONATION_LOGS', 'MIMECAST_MAIL', 'MIMECAST_URL_LOGS', 'MIMECAST_WEBPROXY', 'MINERVA_AV', 'MIRTH_NEXTGEN', 'MISP_IOC', 'MITEL_MCD', 'MOBILEIRON', 'MODE_ANALYTICS', 'MODSECURITY', 'MONDAY', 'MONGO_ATLAS_AUDIT', 'MONGO_DB', 'MOSYLE', 'MULESOFT', 'MULTICOM_SWITCH', 'MULTIPAY', 'MYSQL', 'NAGIOS', 'NASUNI_FILE_SERVICES', 'NCC_SCOUTSUITE', 'NCR_DIGITAL_INSIGHT_FSG', 'NCR_DIGITAL_INSIGHT_GL', 'NEO4J', 'NEOSEC', 'NESSUS', 'NETAPP_ONTAP', 'NETAPP_SAN', 'NETDISCO', 'NETDOCUMENTS', 'NETENRICH_ENTITY_BEHAVIOR', 'NETFILTER_IPTABLES', 'NETGEAR_SWITCH', 'NETIQ_ACCESS_MANAGER', 'NETIQ_EDIRECTORY', 'NETMOTION', 'NETSCOUT_OCI', 'NETSKOPE_ALERT', 'NETSKOPE_CASB', 'NETSKOPE_CLIENT', 'NETSKOPE_WEBPROXY', 'NETSURION_PROTECTWISE', 'NETWRIX', 'NET_SUITE', 'NEUSTAR_SITEPROTECT', 'NEW_RELIC', 'NEXTCLOUD_HUB', 'NEXTTHINK_FINDER', 'NEXUS_SONATYPE', 'NE_SILENT_LOG', 'NGINX', 'NIMBLE_OS', 'NINJAONE', 'NIST_NVD', 'NIX_SYSTEM', 'NNT_FIM', 'NOKIA_ROUTER', 'NONAME_API_SECURITY', 'NORD_LAYER', 'NORTEL_SWITCH', 'NOZOMI_GUARDIAN', 'NTOPNG', 'NUCLEUS_ASSET', 'NUCLEUS_VULNERABILITY', 'NUCLEUS_VULNERABILITY_DELTA', 'NUTANIX_FRAME', 'NUTANIX_PRISM', 'NXLOG_AGENT', 'NXLOG_FIM', 'NXLOG_MANAGER', 'NYANSA_EVENTS', 'OBSERVEIT', 'OBSIDIAN', 'OCI_AUDIT', 'OCI_FLOW', 'OCSF', 'OFFICE_365', 'OFFICE_365_MESSAGETRACE', 'OKERA_DAP', 'OKTA', 'OKTA_ACCESS_GATEWAY', 'OKTA_RADIUS', 'OKTA_USER_CONTEXT', 'ONAPSIS', 'ONBASE_CMS', 'ONEIDENTITY_ARS', 'ONEIDENTITY_CHANGE_AUDITOR', 'ONEIDENTITY_DEFENDER', 'ONEIDENTITY_TPAM', 'ONELOGIN_SSO', 'ONELOGIN_USER_CONTEXT', 'ONEPASSWORD', 'ONEPASSWORD_AUDIT_EVENTS', 'ONFIDO', 'OPENAM', 'OPENCANARY', 'OPENDJ', 'OPENGEAR', 'OPENLDAP', 'OPENPATH', 'OPENSSH', 'OPENTELEMETRY', 'OPENTEXT_FAX2MAIL', 'OPENVAS', 'OPEN_VPN', 'OPNSENSE', 'OPSWAT_KIOSK', 'OPSWAT_METADEFENDER', 'OPUS', 'ORACLE_CLOUD_AUDIT', 'ORACLE_DB', 'ORACLE_FUSION', 'ORACLE_HCM', 'ORACLE_NETSUITE', 'ORACLE_OUD', 'ORACLE_SSO_AUDIT', 'ORACLE_WEBLOGIC', 'ORCA', 'ORDR_IOT', 'OSCAR_CLAIMS', 'OSINT_IOC', 'OSIRIUM_PAM', 'OSQUERY_EDR', 'OSSEC', 'OUTPOST24', 'PACKETLIGHT_DWDM', 'PACKET_VIPER', 'PACOM_SYSTEMS', 'PAGERDUTY', 'PAGERDUTY_AUDIT', 'PALANTIR', 'PAN_CASB', 'PAN_CORTEX_XDR_EVENTS', 'PAN_DNS_SECURITY', 'PAN_EDR', 'PAN_FIREWALL', 'PAN_GLOBAL_PROTECT', 'PAN_IOC', 'PAN_IOT', 'PAN_PANORAMA', 'PAN_PRISMA_CA', 'PAN_PRISMA_CLOUD', 'PAN_XDR_MGMT_AUDIT', 'PAN_XSOAR', 'PAPER_CUT', 'PASSFORT', 'PASSIVE_DNS', 'PASSWORDSTATE', 'PAXTON_ACS', 'PCAP_SSL_CLIENT_HELLO', 'PEGA', 'PENTERA', 'PENTERA_ASV', 'PENTERA_LEEF', 'PEOPLESOFT', 'PEPLINK_FW', 'PEPLINK_LOADBALANCER', 'PEPLINK_ROUTER', 'PEPLINK_SWITCH', 'PERIMETERX_BOT_PROTECTION', 'PERIMETER_81', 'PFSENSE', 'PHISHEYE_ALERT', 'PHISHLABS', 'PING', 'PINGSAFE', 'PING_ACCESS', 'PING_DIRECTORY', 'PING_FEDERATE', 'PING_ONE', 'PING_SDK', 'PIVOTAL', 'PLASO', 'PLIXER_SCRUTINIZER', 'POMERIUM', 'PORTNOX_AUDIT', 'PORTNOX_CEF', 'POSTFIX_MAIL', 'POSTGRESQL', 'POWERSHELL', 'POWERSHELL_TRANSCRIPT', 'POWER_DNS', 'PREEMPT', 'PREEMPT_AUTH', 'PREVEIL_ENTERPRISE', 'PRISMA_SD_WAN', 'PROOFID', 'PROOFPOINT_CASB', 'PROOFPOINT_DLP', 'PROOFPOINT_MAIL', 'PROOFPOINT_MAIL_FILTER', 'PROOFPOINT_META', 'PROOFPOINT_ON_DEMAND', 'PROOFPOINT_SECURE_SHARE', 'PROOFPOINT_SECURITY_AWARENESS_TRAINING', 'PROOFPOINT_SENDMAIL_SENTRION', 'PROOFPOINT_SER', 'PROOFPOINT_TRAP', 'PROOFPOINT_WEB_BROWSER_ISOLATION', 'PROTEGRITY_DEFIANCE', 'PROWATCH', 'PROXMAX', 'PRTG_NETWORKMONITOR', 'PULSE_SECURE_VPN', 'PULSE_SECURE_VTM', 'PUPPET', 'PURE_STORAGE', 'QLIK_AUDIT', 'QNAP_NAS', 'QUALYS_ACTIVITY', 'QUALYS_ASSET_CONTEXT', 'QUALYS_CONTINUOUS_MONITORING', 'QUALYS_KNOWLEDGEBASE', 'QUALYS_SCAN', 'QUALYS_VIRTUAL_SCANNER', 'QUALYS_VM', 'QUEST_AD', 'QUEST_CA_AUDIT', 'QUEST_CHANGE_AUDITOR_EMC', 'QUEST_FILE_AUDIT', 'QUMULO_FS', 'RABBITMQ', 'RADIFLOW_IDS', 'RADIUS', 'RADWARE_ALTEON', 'RADWARE_DDOS', 'RADWARE_FIREWALL', 'RAD_ETX', 'RAPID7_INSIGHT', 'RAPID7_NEXPOSE', 'RAPID7_SECURITY_ONION', 'RARITAN_DOMINION', 'REALITEQ', 'RECORDED_FUTURE_IOC', 'RECORDIA', 'REDCANARY_CLOUD_PROTECTION_RAW', 'REDCANARY_EDR', 'REDHAT_DIRECTORY_SERVER', 'REDHAT_IM', 'REDHAT_JBOSS', 'REDHAT_KEYCLOAK', 'REDHAT_OPENSHIFT', 'REDHAT_SATELLITE', 'REDHAT_STACKROX', 'REDIS', 'REMEDIANT_SECUREONE', 'RH_ISAC_IOC', 'RIBBON_ANALYTICS_PLATFORM', 'RIBBON_SBC', 'RING_CENTRAL', 'RISKIQ_DIGITAL_FOOTPRINT', 'RSA_AUTH_MANAGER', 'RSA_NETWITNESS', 'RSA_SECURID', 'RUBRIK', 'RUBRIK_POLARIS', 'RUCKUS_WIRELESS', 'RUMBLE_NETWORK_DISCOVERY', 'SAFEBREACH', 'SAFECONNECT_NAC', 'SAILPOINT_IAM', 'SAIWALL_VPN', 'SALESFORCE', 'SALESFORCE_COMMERCE_CLOUD', 'SALESFORCE_CONTEXT', 'SANGFOR_NGAF', 'SAP_BTP', 'SAP_C4C', 'SAP_HANA', 'SAP_IDM', 'SAP_INSURANCE', 'SAP_NETWEAVER', 'SAP_SAST', 'SAP_SM20', 'SAP_SUCCESSFACTORS', 'SAP_WEBDISP', 'SAVIYNT_EIP', 'SCALITY_RING_AUDIT', 'SCCM', 'SECBERUS', 'SECUREAUTH_SSO', 'SECURELINK', 'SECURITYSCORECARD', 'SEMPERIS_ADFR', 'SEMPERIS_DSP', 'SENDGRID', 'SENDMAIL', 'SENDSAFELY', 'SENHASEGURA_PAM', 'SENTINELONE_ACTIVITY', 'SENTINELONE_ALERT', 'SENTINELONE_CF', 'SENTINEL_DV', 'SENTINEL_EDR', 'SENTRIGO', 'SEP', 'SEPPMAIL', 'SEQRITE_ENDPOINT', 'SERPICO', 'SERVICENOW_AUDIT', 'SERVICENOW_CMDB', 'SERVICENOW_ROLES', 'SERVICENOW_SECURITY', 'SEVCO_CMDB', 'SHAREPOINT', 'SHAREPOINT_ULS', 'SHIBBOLETH_IDP', 'SHODAN_IO', 'SHRUBBERY_TACACS', 'SIEBEL', 'SIEMENS_SIPASS', 'SIERRA_WIRELESS', 'SIGNAL_SCIENCES_WAF', 'SILVERFORT', 'SILVERPEAK_FIREWALL', 'SINGLE_STORE', 'SITE24X7', 'SITEMINDER_SSO', 'SKYBOX_FIREWALL_ASSURANCE', 'SKYSEA', 'SLACK_AUDIT', 'SMART_SIMPLE', 'SMBD', 'SNAPATTACK', 'SNARE_SOLUTIONS', 'SNIPE_IT', 'SNOOPY_LOGGER', 'SNORT_IDS', 'SNOWFLAKE', 'SNYK_SDLC', 'SOCOMEC_UPS', 'SOFTWARE_HOUSE_ACS', 'SOFTWARE_HOUSE_CCURE9000', 'SOLACE_AUDIT', 'SOLARIS_SYSTEM', 'SOLARWINDS_KSS', 'SOLARWINDS_SERV_U', 'SOLAR_SYSTEM', 'SONARQUBE', 'SONICWALL_SMA', 'SONIC_FIREWALL', 'SONRAI', 'SOPHOS_AV', 'SOPHOS_CAPSULE8', 'SOPHOS_CENTRAL', 'SOPHOS_DHCP', 'SOPHOS_EDR', 'SOPHOS_EMAIL', 'SOPHOS_FIREWALL', 'SOPHOS_URL', 'SOPHOS_UTM', 'SOTI_MOBICONTROL', 'SOURCEFIRE_IDS', 'SPAMHAUS', 'SPE', 'SPECTERX', 'SPIRION', 'SPLASHTOP', 'SPLUNK', 'SPLUNK_ATTACK_ANALYZER', 'SPLUNK_DNS', 'SPLUNK_PHANTOM', 'SPLUNK_TRUSTAR', 'SPUR_FEEDS', 'SPYCLOUD', 'SQUID_WEBPROXY', 'STAIRWELL_INCEPTION', 'STEALTHBITS_AUDIT', 'STEALTHBITS_DEFEND', 'STEALTHBITS_DLP', 'STEALTHBITS_PAM', 'STEELHEAD', 'STELLAR_CYBER', 'STIX', 'STORMSHIELD_FIREWALL', 'STREAMALERT', 'STRONGDM', 'STRONGSWAN_VPN', 'SUBLIMESECURITY', 'SUPERMICRO_IPMI', 'SUPERNA_EYEGLASS', 'SUREVIEW_SYSTEMS', 'SURICATA_EVE', 'SURICATA_IDS', 'SWIFT', 'SWIFT_AMH', 'SWIMLANE', 'SYMANTEC_CASB', 'SYMANTEC_DLP', 'SYMANTEC_EDR', 'SYMANTEC_EVENT_EXPORT', 'SYMANTEC_MAIL', 'SYMANTEC_VIP', 'SYMANTEC_WEB_ISOLATION', 'SYMANTEC_WSS', 'SYMPHONYAI', 'SYNOLOGY', 'SYSDIG', 'SYXSENSE', 'TABLEAU', 'TAILSCALE', 'TALON', 'TANIUM_ASSET', 'TANIUM_AUDIT', 'TANIUM_COMPLY', 'TANIUM_DEPLOY', 'TANIUM_DISCOVER', 'TANIUM_INSIGHT', 'TANIUM_INTEGRITY_MONITOR', 'TANIUM_PATCH', 'TANIUM_QUESTION', 'TANIUM_REVEAL', 'TANIUM_TANOS', 'TANIUM_TH', 'TANIUM_THREAT_RESPONSE', 'TCPWAVE_DDI', 'TEAMVIEWER', 'TECHNITIUM_DNS', 'TELEPORT_ACCESS_PLANE', 'TEMENOS_MANAGER_SYSTEMEVENT', 'TENABLE_ADS', 'TENABLE_IO', 'TENABLE_OT', 'TENABLE_SC', 'TENABLE_WAS', 'TERADICI_PCOIP', 'TERAMIND', 'TERRAFORM_ENTERPRISE', 'TESSIAN_PLATFORM', 'TETRAGON_EBPF_AUDIT_LOGS', 'TGDETECT', 'THALES_DIS', 'THALES_LUNA_HSM', 'THALES_MFA', 'THINKST_CANARY', 'THREATCONNECT_IOC', 'THREATLOCKER', 'THREATQ_IOC', 'THREATX_WAF', 'THYCOTIC', 'THYCOTIC_DEVOPS_SECRETVAULT', 'TIKTOK', 'TIPPING_POINT', 'TOMCAT', 'TRACEABLE_PLATFORM', 'TRAEFIK', 'TRELLIX_HX_ES', 'TRENDMICRO_APEX_CENTRAL', 'TRENDMICRO_APEX_ONE', 'TRENDMICRO_AV', 'TRENDMICRO_CLOUDAPPSECURITY', 'TRENDMICRO_CLOUDONE', 'TRENDMICRO_DDI', 'TRENDMICRO_DEEP_SECURITY', 'TRENDMICRO_EDGEIPS', 'TRENDMICRO_EDR', 'TRENDMICRO_EMAIL_SECURITY', 'TRENDMICRO_STELLAR', 'TRENDMICRO_VISION_ONE', 'TRENDMICRO_WEBPROXY', 'TRENDMICRO_WEBPROXY_DSM', 'TRIDIUM_NIAGARA_FRAMEWORK', 'TRIPP_LITE', 'TRIPWIRE_FIM', 'TRUEFORT', 'TRUENAS', 'TWILIO_AUDIT', 'TWILIO_AUTHY', 'TWINGATE', 'TYK_IO', 'UBIQUITI_ACCESSPOINT', 'UBIQUITI_FIREWALL', 'UBIQUITI_SWITCH', 'UDM', 'UIPATH', 'ULTRADNS', 'ULTRA_CYBERFENCE', 'UMBRELLA_DNS', 'UMBRELLA_FIREWALL', 'UMBRELLA_IP', 'UMBRELLA_WEBPROXY', 'UNBOUND_DNS', 'UNIFI_AP', 'UNIFI_SWITCH', 'UNIT21', 'UPGUARD', 'UPTYCS_EDR', 'VANDYKE_SFTP', 'VANGUARD', 'VARONIS', 'VECTOR_DEV', 'VECTRA_DETECT', 'VECTRA_PROTECT', 'VECTRA_STREAM', 'VEEAM', 'VELO_FIREWALL', 'VENAFI', 'VERCARA', 'VERIDIUM_ID', 'VERITAS_NETBACKUP', 'VERIZON_NDR', 'VERKADA', 'VERSA_FIREWALL', 'VIACONTROL', 'VIRSEC_EVENT', 'VIRSEC_THREAT', 'VIRTRU_EMAIL_ENCRYPTION', 'VIRUSTOTAL_THREAT_HUNTER', 'VITALQIP', 'VMRAY_FLOG_XML', 'VMWARE_ARIA_LOGS', 'VMWARE_AVINETWORKS_IWAF', 'VMWARE_AVI_VANTAGE', 'VMWARE_CD', 'VMWARE_ESX', 'VMWARE_HCX', 'VMWARE_HORIZON', 'VMWARE_NSX', 'VMWARE_NSX_AVI', 'VMWARE_SDDC', 'VMWARE_SDWN_EVENTS', 'VMWARE_TANZU', 'VMWARE_UNIFIED_ACCESS_GATEWAY', 'VMWARE_VCENTER', 'VMWARE_VREALIZE', 'VMWARE_VSHIELD', 'VMWARE_WORKSPACE_ONE', 'VOLTAGE', 'VONAGE', 'VORMETRIC', 'VSFTPD', 'VSFTPD_AUDIT', 'VYOS', 'WALLARM_NOTIFICATIONS', 'WALLIX_BASTION', 'WALLIX_EPM', 'WALLIX_PAM', 'WATCHGUARD', 'WATCHGUARD_EDR', 'WATERFALL_DSM', 'WAZUH', 'WEBEX_SAAS', 'WEBMARSHAL', 'WHITECLOUD_EDR', 'WINDCHILL', 'WINDOWS_AD', 'WINDOWS_APPLOCKER', 'WINDOWS_DEFENDER_ATP', 'WINDOWS_DEFENDER_AV', 'WINDOWS_DHCP', 'WINDOWS_DNS', 'WINDOWS_FIREWALL', 'WINDOWS_HYPERV', 'WINDOWS_NET_POLICY_SERVER', 'WINDOWS_SYSMON', 'WINDOWS_WFP', 'WINEVTLOG', 'WINEVTLOG_XML', 'WINSCP', 'WITHSECURE_CLOUD', 'WITHSECURE_ELEMENTS', 'WIZ_IO', 'WORDPRESS_CMS', 'WORDPRESS_SIMPLE_HISTORY', 'WORKATO', 'WORKDAY', 'WORKDAY_AUDIT', 'WORKDAY_USER_ACTIVITY', 'WORKSPACE_ACTIVITY', 'WORKSPACE_ALERTS', 'WORKSPACE_CHROMEOS', 'WORKSPACE_GROUPS', 'WORKSPACE_MOBILE', 'WORKSPACE_PRIVILEGES', 'WORKSPACE_USERS', 'WORKSPOT_CONTROL', 'WP_ENGINE', 'WS_FTP', 'WTI_CONSOLE_SERVERS', 'XITING_XAMS', 'YAMAHA_ROUTER', 'YSOFT_DSM', 'YUBICO_OTP', 'ZABBIX', 'ZENDESK_CRM', 'ZEROFOX_PLATFORM', 'ZIMPERIUM', 'ZIX_EMAIL_ENCRYPTION', 'ZOHO_AUDIT', 'ZOOM_OPERATION_LOGS', 'ZSCALER_CASB', 'ZSCALER_DECEPTION', 'ZSCALER_DIGITAL_EXPERIENCE', 'ZSCALER_DLP', 'ZSCALER_DNS', 'ZSCALER_FIREWALL', 'ZSCALER_INTERNET_ACCESS', 'ZSCALER_NSS_FEEDS', 'ZSCALER_TUNNEL', 'ZSCALER_VPN', 'ZSCALER_WEBPROXY', 'ZSCALER_ZCC', 'ZSCALER_ZDX', 'ZSCALER_ZPA', 'ZSCALER_ZPA_AUDIT', 'ZUORA_APP_LOGS'] {allow-input: true}\n",
        "\n",
        "#@markdown Choose show status to just see the status of the parser (live, validating, rejected, etc), otherwise the parser body will be saved (or downloaded) instead.\n",
        "show_status = False #@param {type: \"boolean\"}\n",
        "download_file = False #@param {type: \"boolean\"}\n",
        "\n",
        "# Construct the URL\n",
        "uri = f\"https://{region_prefix}backstory.googleapis.com/v1/tools/cbnParsers/{config_id.upper()}\"\n",
        "\n",
        "# send the request and process the response\n",
        "resp = session.get(uri)\n",
        "json_resp = resp.json()\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  if not show_status:\n",
        "    requested_parser = base64.b64decode(json_resp['config'])\n",
        "    f = open(config_id + \".conf\", \"wb\")\n",
        "    f.write(requested_parser)\n",
        "    f.close()\n",
        "    print(\"Parser written to {}.conf\".format(config_id))\n",
        "    if download_file:\n",
        "      files.download(\"{}.conf\".format(config_id))\n",
        "  else:\n",
        "    pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MuouB_2JYOYt"
      },
      "outputs": [],
      "source": [
        "#@title Submit a parser\n",
        "#@markdown This endpoint enables you to submit a customer-specific parser configuration for a specific parser. The validation process requires at least 10,000 raw logs for each LogType and that event timestamps are no older than 30 days, otherwise it will fail. Make sure there are at least 10,000 raw logs for the LogType with event timestamps no older than 30 days from the time you submit the parser configuration.\n",
        "log_type = 'ASSET_STATIC_IP' #@param {type: \"string\"}\n",
        "author_name = \"Eugene Dimarsky\" #@param {type: \"string\"}\n",
        "#@markdown Check the below box to upload a parser or leave unchecked to specify a filename in the `parser_filename` variable below that is already in the colab instance.\n",
        "upload_file = False #@param {type: \"boolean\"}\n",
        "parser_filename = \"parser.conf\" #@param {type:\"string\"}\n",
        "if upload_file:\n",
        "  print(\"Please select the parser file to upload\")\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  parser_filename = list(uploaded.keys())[0]\n",
        "\n",
        "with open(parser_filename, \"rb\") as parser_file:\n",
        "  parser = parser_file.read()\n",
        "\n",
        "skipValidationOnNoLogs = True #@param {type: \"boolean\"}\n",
        "\n",
        "uri = f\"https://{region_prefix}backstory.googleapis.com/v1/tools/cbnParsers\"\n",
        "\n",
        "# conf_file = '/_data/nginx.conf'\n",
        "\n",
        "\n",
        "# create the body with the parser configuration, logType identifier, and author\n",
        "request_body = {\n",
        "'config': base64.urlsafe_b64encode(parser).decode(\"ascii\"),\n",
        "'log_type': log_type,\n",
        "'author': author_name\n",
        "}\n",
        "\n",
        "if skipValidationOnNoLogs:\n",
        "  request_body['skipValidationOnNoLogs'] = True\n",
        "\n",
        "\n",
        "# encode the body and set the Content-Type\n",
        "body = urllib.parse.urlencode(request_body)\n",
        "r_headers = {}\n",
        "r_headers.update({'Content-type' : 'application/x-www-form-urlencoded'})\n",
        "\n",
        "# send the request and process the response\n",
        "resp = session.post(uri, data=body, headers=r_headers)\n",
        "json_resp = resp.json()\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp['error'])\n",
        "else:\n",
        "  pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hfzzVts6dMS4"
      },
      "outputs": [],
      "source": [
        "#@title Archive a parser\n",
        "#@markdown Sets the state of a specified parser configuration to ARCHIVED and returns information about the parser configuration before changing the state.\n",
        "config_id = \"0b598c6e-9e91-4fb9-a52d-481e17a7f13c\" #@param {type: \"string\"}\n",
        "\n",
        "uri = f\"https://{region_prefix}backstory.googleapis.com/v1/tools/cbnParsers/{config_id}:archive\"\n",
        "\n",
        "# send the request and process the response\n",
        "resp = session.post(uri)\n",
        "json_resp = resp.json()\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKwNZ5bHgKSs",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title List CBN Parser Errors\n",
        "\n",
        "#@markdown When customer-specific and default parsers encounter errors, they are captured and saved. This endpoint retrieves the errors generated by a specific logType over a defined time range. It returns a maximum of 1000 errors with each request.\n",
        "\n",
        "#@markdown Config_id can either be an ID of a custom parser or the name of a default parser (for example: OKTA)\n",
        "# config ID list taken from ingest API get support log types endpoint\n",
        "logtype = \"CLOUDFLARE\" #@param ['ABNORMAL_SECURITY', 'ABSOLUTE', 'ACALVIO', 'ACCELLION', 'ACQUIA_CLOUD_PLATFORM', 'ACTIVE_SYNC', 'ADAUDIT_PLUS', 'ADFS', 'ADMANAGER_PLUS', 'ADOBE_COMMERCE', 'ADSELFSERVICE_PLUS', 'ADTRAN_NETVANTA', 'AIRDEFENSE', 'AIRLOCK_DIGITAL', 'AIRWATCH', 'AIX_SYSTEM', 'AI_HUNTER', 'AKAMAI_CLOUD_MONITOR', 'AKAMAI_DDOS', 'AKAMAI_DHCP', 'AKAMAI_DNS', 'AKAMAI_EAA', 'AKAMAI_ETP', 'AKAMAI_SIEM_CONNECTOR', 'AKAMAI_WAF', 'AKEYLESS_VAULT', 'ALERTLOGIC_NOTIFICATIONS', 'ALGOSEC', 'ALLOT_NETENFORCER', 'ALVEO_RDM', 'ANOMALI_IOC', 'ANSIBLE_AWX', 'APACHE', 'APACHE_KAFKA_AUDIT', 'APACHE_SPAMASSASSIN', 'APC_NETBOTZ', 'APC_SMART_UPS', 'APC_STRUXUREWARE', 'APPGATE_SDP', 'APPIAN_CLOUD', 'APPOMNI', 'APTOS_EOM', 'AQUA_SECURITY', 'ARBOR_EDGE_DEFENSE', 'ARBOR_SIGHTLINE', 'ARCHER_IRM', 'ARCSIGHT_CEF', 'AREA1', 'ARGO_CD', 'ARISTA_SWITCH', 'ARKIME_PCAP', 'ARMIS', 'ARMORBLOX_ESC', 'ARMOR_ANYWHERE', 'ARRAYNETWORKS_VPN', 'ARRAY_NETWORKS_WAF', 'ARUBA_AIRWAVE', 'ARUBA_IPS', 'ARUBA_WIRELESS', 'ARXAN_THREAT_ANALYTICS', 'ASANA', 'ASOC_ALERT', 'ASSET_STATIC_IP', 'ATLASSIAN_CONFLUENCE', 'ATLASSIAN_JIRA', 'ATTIVO', 'ATT_NETBOND', 'AUDITD', 'AUTHENTIC8_SILO', 'AUTHX', 'AUTHX_USER_CONTEXT', 'AUTH_ZERO', 'AUTOMATION_ANYWHERE', 'AUTOMOX_EPM', 'AVANAN_EMAIL', 'AVATIER', 'AVAYA_AURA', 'AVAYA_IVR', 'AVAYA_WIRELESS', 'AVIATRIX', 'AWAKE_NDR', 'AWS_AURORA', 'AWS_CLOUDFRONT', 'AWS_CLOUDTRAIL', 'AWS_CLOUDWATCH', 'AWS_CONFIG', 'AWS_CONTROL_TOWER', 'AWS_ELB', 'AWS_KMS', 'AWS_MACIE', 'AWS_REDSHIFT', 'AWS_ROUTE_53', 'AWS_S3_SERVER_ACCESS', 'AWS_SECURITY_HUB', 'AWS_SES', 'AWS_SESSION_MANAGER', 'AWS_VPC_FLOW', 'AWS_WAF', 'AXIS_OS', 'AXONIUS', 'AZURE', 'AZURE_ACTIVITY', 'AZURE_AD', 'AZURE_AD_AUDIT', 'AZURE_AD_CONTEXT', 'AZURE_ATP', 'AZURE_COSMOS_DB', 'AZURE_DEVOPS', 'AZURE_FIREWALL', 'AZURE_MDM_INTUNE', 'AZURE_NSG_FLOW', 'AZURE_RESOURCE_LOGS', 'AZURE_SECURITY_CENTER', 'AZURE_SQL', 'AZURE_WAF', 'BALABIT', 'BARRACUDA_CLOUDGEN_ACCESS', 'BARRACUDA_EMAIL', 'BARRACUDA_FIREWALL', 'BARRACUDA_WAF', 'BETTERCLOUD', 'BEYONDTRUST_BEYONDINSIGHT', 'BEYONDTRUST_CPB', 'BEYONDTRUST_ENDPOINT', 'BEYONDTRUST_PI', 'BEYONDTRUST_REMOTE_ACCESS', 'BIGSWITCH_BCF', 'BIND_DNS', 'BITDEFENDER', 'BLUECAT_DDI', 'BLUECAT_EDGE', 'BLUECOAT_WEBPROXY', 'BLUE_PRISM', 'BMC_AMI_DEFENDER', 'BMC_CONTROL_M', 'BMC_HELIX_DISCOVERY', 'BOMGAR', 'BOX', 'BRICATA_NDR', 'BRIVO', 'BROADCOM_CEM', 'BROADCOM_SSL_VA', 'BROCADE_SERVERIRON', 'BROCADE_SWITCH', 'BRO_DHCP', 'BRO_HTTP', 'BRO_JSON', 'BRO_TSV', 'BT_IPCONTROL', 'CAMEYO_BYO_CLOUD', 'CASSANDRA', 'CATO_NETWORKS', 'CATO_SDWAN', 'CA_ACCESS_CONTROL', 'CA_ACF2', 'CA_LDAP', 'CA_SSO_WEB', 'CB_APP_CONTROL', 'CB_EDR', 'CENTRIFY_SSO', 'CENTRIPETAL_IOC', 'CEQUENCE_BOT_DEFENSE', 'CERBERUS_FTP', 'CHECKPOINT_CLOUDGUARD', 'CHECKPOINT_EDR', 'CHECKPOINT_EMAIL', 'CHECKPOINT_FIREWALL', 'CHECKPOINT_HARMONY', 'CIRCLECI', 'CISCO_ACE', 'CISCO_ACI', 'CISCO_ACS', 'CISCO_AMP', 'CISCO_APIC', 'CISCO_ASA_FIREWALL', 'CISCO_CLOUDLOCK_CASB', 'CISCO_CTS', 'CISCO_DHCP', 'CISCO_DNAC', 'CISCO_DNS', 'CISCO_EMAIL_SECURITY', 'CISCO_FIREPOWER_FIREWALL', 'CISCO_FIRESIGHT', 'CISCO_IOS', 'CISCO_ISE', 'CISCO_MERAKI', 'CISCO_NX_OS', 'CISCO_PRIME', 'CISCO_ROUTER', 'CISCO_SDWAN', 'CISCO_SECURE_MALWARE_ANALYTICS', 'CISCO_SECURE_WORKLOAD', 'CISCO_SMA', 'CISCO_STEALTHWATCH', 'CISCO_SWITCH', 'CISCO_TACACS', 'CISCO_UCM', 'CISCO_UCS', 'CISCO_VCS', 'CISCO_VPN', 'CISCO_WIPS', 'CISCO_WIRELESS', 'CISCO_WSA', 'CIS_ALBERT_ALERT', 'CITRIX_ANALYTICS', 'CITRIX_MONITOR', 'CITRIX_NETSCALER', 'CITRIX_NETSCALER_WEB_LOGS', 'CITRIX_SDWAN', 'CITRIX_SESSION_METADATA', 'CITRIX_STOREFRONT', 'CITRIX_WAF', 'CITRIX_WEB_GATEWAY', 'CITRIX_WORKSPACE', 'CITRIX_XENCENTER', 'CLAM_AV', 'CLEARPASS', 'CLEARSENSE', 'CLICK_STUDIOS_PASSWORDSTATE', 'CLOUDFLARE', 'CLOUDFLARE_AUDIT', 'CLOUDFLARE_BOT_MANAGEMENT', 'CLOUDFLARE_WAF', 'CLOUDGENIX_SDWAN', 'CLOUDIAN_HYPERSTORE', 'CLOUDM', 'CLOUDPASSAGE_CSM', 'CLOUDPASSAGE_FIM', 'CLOUDPASSAGE_LIDS', 'CLOUDPASSAGE_SVM', 'CLOUD_IDENTITY_CONTEXT', 'CLOUD_PASSAGE', 'CMD', 'CODE42', 'CODE42_INCYDR', 'CODE_WORLDWIDE', 'COFENSE_TRIAGE', 'COFENSE_VISION', 'COHESITY', 'COMMVAULT', 'COMODO_AV', 'CONFLUENT_AUDIT', 'CONNECTWISE_CONTROL', 'CORELIGHT', 'CORTEX_XDR', 'COVID_CTC_IOC', 'CRADLEPOINT_NETCLOUD', 'CROWDSTRIKE_IOC', 'CSV_CUSTOM_CMDB', 'CSV_CUSTOM_IOC', 'CS_CEF_EDR', 'CS_DETECTS', 'CS_EDR', 'CS_STREAM', 'CTERA_DRIVE', 'CUSTOMER_ALERT', 'CUSTOM_APPLICATION_ACCESS', 'CUSTOM_DNS', 'CUSTOM_HOST_FORENSICS', 'CUSTOM_SECURITY_DATA_ANALYTICS', 'CYBERARK', 'CYBERARK_PRIVILEGE_CLOUD', 'CYBEREASON_EDR', 'CYBERHAVEN_DDR', 'CYCODE', 'CYLANCE', 'CYLANCE_PROTECT', 'CYOLO_ZTNA', 'D3_BANKING', 'D3_SECURITY', 'DARKTRACE', 'DATADOG', 'DATALOCKER_SAFECONSOLE', 'DATAWATCH', 'DATTO_FILE_PROTECTION', 'DB2_DB', 'DEEPFENCE', 'DEEP_INSTINCT_EDR', 'DELINEA_PRIVILEGE_MANAGER', 'DELINEA_SECRET_SERVER', 'DELINEA_SERVER_SUITE', 'DELL_EMC_AVAMAR', 'DELL_EMC_CLOUDLINK', 'DELL_EMC_DATA_DOMAIN', 'DELL_EMC_NAS', 'DELL_EMC_UNITY', 'DELL_OPENMANAGE', 'DELL_SWITCH', 'DESIGN_PROFIT_CENTRAL_SERVER', 'DEVOLUTIONS_RDM', 'DHS_IOC', 'DIGITALARTS_IFILTER', 'DIGITALGUARDIAN_DLP', 'DIGITALGUARDIAN_EDR', 'DIGITAL_SHADOWS_IOC', 'DIGITAL_SHADOWS_SEARCHLIGHT', 'DMP_ENTRE', 'DOCKER', 'DOMO', 'DREMIO_DATA_LAKEHOUSE', 'DROPBOX', 'DRUPAL', 'DUO_ADMIN', 'DUO_AUTH', 'DUO_CASB', 'DUO_CONTEXT', 'DUO_NETWORK_GATEWAY', 'DUO_TELEPHONY', 'DUO_USER_CONTEXT', 'DYNATRACE', 'E2_SOLUTIONS', 'EATON_UPS', 'ECAR', 'ECAR_BRO', 'EDGIO_CDN', 'EFFICIENTIP_DDI', 'EIQ_EDR', 'ELASTIC_AUDITBEAT', 'ELASTIC_FILEBEAT', 'ELASTIC_METRICBEAT', 'ELASTIC_PACKETBEATS', 'ELASTIC_SEARCH', 'ELASTIC_WINLOGBEAT', 'EMERSON_FIREWALL', 'ENDGAME_EDR', 'ENDPOINT_PROTECTOR_DLP', 'ENTRUST_HSM', 'ENTRUST_NTP_SERVER', 'ENTRUST_SECRETS_VAULT', 'EPIC', 'ESET_AV', 'ESET_EDR', 'ESET_IOC', 'ESHARE_PLATFORM', 'ESTAR', 'ETQ_RELIANCE', 'ET_PRO_IOC', 'EXABEAM_FUSION_XDR', 'EXCHANGE_MAIL', 'EXTRAHOP', 'EXTRAHOP_DHCP', 'EXTRAHOP_DNS', 'EXTREME_MANAGEMENT', 'EXTREME_SWITCH', 'F5_ASM', 'F5_BIGIP_LTM', 'F5_BOT', 'F5_DNS', 'F5_SHAPE', 'F5_VPN', 'FALCO_IDS', 'FASTLY_WAF', 'FIDELIS_ENDPOINT', 'FIDELIS_NETWORK', 'FILEZILLA_FTP', 'FILE_SCANNING_FRAMEWORK', 'FIREEYE_ALERT', 'FIREEYE_EMPS', 'FIREEYE_ETP', 'FIREEYE_HX', 'FIREEYE_HX_AUDIT', 'FIREEYE_NX', 'FIREMON_FIREWALL', 'FLASHPOINT_IOC', 'FLUENTD', 'FORCEPOINT_CASB', 'FORCEPOINT_DLP', 'FORCEPOINT_FIREWALL', 'FORCEPOINT_WEBPROXY', 'FORESCOUT_NAC', 'FORSETI', 'FORTANIX_DSM', 'FORTINET_DHCP', 'FORTINET_FIREWALL', 'FORTINET_FORTIANALYZER', 'FORTINET_FORTIAUTHENTICATOR', 'FORTINET_FORTICLIENT', 'FORTINET_FORTIEDR', 'FORTINET_FORTINAC', 'FORTINET_SANDBOX', 'FORTINET_WEBPROXY', 'FOX_IT_STIX', 'FREEIPA', 'FREERADIUS', 'FRONTLINE_VM', 'FUTUREX_HSM', 'GCP_APIGEE', 'GCP_CLOUDIDENTITY_DEVICES', 'GCP_CLOUDIDENTITY_DEVICEUSERS', 'GCP_CLOUDIOT', 'GCP_CLOUDSQL', 'GCP_COMPUTE', 'GCP_IDS', 'GCP_LOADBALANCING', 'GCP_RECAPTCHA_ENTERPRISE', 'GCP_RUN', 'GCP_THREAT_DETECTION', 'GCP_VPC_FLOW', 'GIGAMON', 'GITHUB', 'GITLAB', 'GLOBALSCAPE_SFTP', 'GLUSTER_FS', 'GMAIL_LOGS', 'GMV_CHECKER', 'GMV_CHECKER_CONTEXT', 'GODADDY_DNS', 'GREATHORN', 'GTB_DLP', 'GUARDDUTY', 'GUARDICORE_CENTRA', 'GUARDIUM', 'H3C_SWITCH', 'HADOOP', 'HAPROXY', 'HAPROXY_LOADBALANCER', 'HASHICORP', 'HCL_BIGFIX', 'HCNET_ACCOUNT_ADAPTER', 'HIRSCHMANN_SWITCH', 'HITACHI_CLOUD_PLATFORM', 'HITACHI_ID_PAM', 'HONEYD', 'HPE_ILO', 'HPE_SAN', 'HP_PRINTER', 'HP_PROCURVE', 'HYPR_MFA', 'IBM_AS400', 'IBM_CICS', 'IBM_DATAPOWER', 'IBM_MAAS360', 'IBM_MQ_FILE_TRANSFER', 'IBM_QRADAR', 'IBM_SAFENET', 'IBM_SECURITY_VERIFY', 'IBM_SOAR', 'IBM_SPECTRUM_PROTECT', 'IBM_SWITCH', 'IBM_TIVOLI', 'IBM_WEBSEAL', 'IBM_WEBSPHERE_APP_SERVER', 'IBM_ZOS', 'IBM_ZSECURE_ALERT', 'IBOSS_WEBPROXY', 'IDRAC', 'IIS', 'ILLUMIO_CORE', 'IMANAGE_CLOUD', 'IMPERVA_DB', 'IMPERVA_FLEXPROTECT', 'IMPERVA_SECURESPHERE', 'IMPERVA_SONAR', 'IMPERVA_WAF', 'IMPRIVATA_CONFIRM_ID', 'IMPRIVATA_IDG', 'IMPRIVATA_ONESIGN', 'INFOBLOX', 'INFOBLOX_DHCP', 'INFOBLOX_DNS', 'INFOBLOX_LOADBALANCER', 'INFOBLOX_NETMRI', 'INFOBLOX_RPZ', 'INFORMIX', 'INTERSYSTEMS_CACHE', 'INWEBO_MFA', 'IPSWITCH_MOVEIT_AUTOMATION', 'IPSWITCH_MOVEIT_TRANSFER', 'IPSWITCH_SFTP', 'ISC_DHCP', 'JAMF', 'JAMF_COMPLIANCE_REPORTER', 'JAMF_PROTECT', 'JDE', 'JENKINS', 'JUMPCLOUD_DAAS', 'JUNIPER_FIREWALL', 'JUNIPER_IPS', 'JUNIPER_JUNOS', 'JUNIPER_MX', 'KAMAILIO', 'KANDJI', 'KASEYA', 'KASPERSKY_AV', 'KEA_DHCP', 'KEEPER', 'KEMP_LOADBALANCER', 'KIBANA', 'KISI', 'KNOWBE4_PHISHER', 'KOLIDE', 'KONG_GATEWAY', 'KUBERNETES_AUDIT', 'KUBERNETES_AUTH_PROXY', 'KUBERNETES_NODE', 'KYRIBA', 'LACEWORK', 'LASTPASS', 'LENEL_ONGUARD', 'LEXMARK_PRINTER', 'LIAISON_NUBRIDGES', 'LIBRAESVA_EMAIL', 'LIMACHARLIE_EDR', 'LINUX_DHCP', 'LINUX_SYSMON', 'LOGICMONITOR', 'LOOKINGGLASS_IPS', 'LOOKING_GLASS_IOC', 'LSI_BMS', 'LUMEN_DDOS_HYPER', 'LXC_ORCHESTRATOR', 'MACOS', 'MAILSCANNER', 'MALWAREBYTES_EDR', 'MANAGE_ENGINE_AD360', 'MANAGE_ENGINE_PASSWORD_MANAGER', 'MANAGE_ENGINE_REPORTER_PLUS', 'MANDIANT_IOC', 'MANGOAPPS', 'MARIA_DB', 'MATERIAL_SECURITY', 'MATRIX_FRONTIER', 'MCAFEE_ATD', 'MCAFEE_DLP', 'MCAFEE_EDR', 'MCAFEE_EPO', 'MCAFEE_ESM', 'MCAFEE_IPS', 'MCAFEE_MVISION_CASB', 'MCAFEE_SKYHIGH_CASB', 'MCAFEE_UCE', 'MCAFEE_WEBPROXY', 'MCAFEE_WEB_PROTECTION', 'MEDIGATE_CMDB', 'MEDIGATE_IOT', 'MENANDMICE_DNS', 'MENLO_SECURITY', 'MICROFOCUS_IMANAGER', 'MICROSEMI_NTP', 'MICROSOFT_ATA', 'MICROSOFT_CASB', 'MICROSOFT_DEFENDER_ENDPOINT', 'MICROSOFT_DEFENDER_IDENTITY', 'MICROSOFT_GRAPH_ALERT', 'MICROSOFT_NETLOGON', 'MICROSOFT_SCEP', 'MICROSOFT_SENTINEL', 'MICROSOFT_SQL', 'MICROSOFT_SSTP', 'MIMECAST_MAIL', 'MIMECAST_WEBPROXY', 'MINERVA_AV', 'MISP_IOC', 'MOBILEIRON', 'MONGO_DB', 'MULESOFT', 'MYSQL', 'NAGIOS', 'NASUNI_FILE_SERVICES', 'NCC_SCOUTSUITE', 'NCR_DIGITAL_INSIGHT_FSG', 'NCR_DIGITAL_INSIGHT_GL', 'NETAPP_ONTAP', 'NETAPP_SAN', 'NETDISCO', 'NETFILTER_IPTABLES', 'NETIQ_ACCESS_MANAGER', 'NETIQ_EDIRECTORY', 'NETMOTION', 'NETSKOPE_ALERT', 'NETSKOPE_CASB', 'NETSKOPE_WEBPROXY', 'NETSURION_PROTECTWISE', 'NEW_RELIC', 'NEXTCLOUD_HUB', 'NGINX', 'NIMBLE_OS', 'NIST_NVD', 'NIX_SYSTEM', 'NUCLEUS_ASSET', 'NUCLEUS_VULNERABILITY', 'NUCLEUS_VULNERABILITY_DELTA', 'NUTANIX_FRAME', 'NUTANIX_PRISM', 'NXLOG_MANAGER', 'OBSERVEIT', 'OBSIDIAN', 'OFFICE_365', 'OKERA_DAP', 'OKTA', 'OKTA_ACCESS_GATEWAY', 'OKTA_RADIUS', 'OKTA_USER_CONTEXT', 'ONBASE_CMS', 'ONEIDENTITY_ARS', 'ONEIDENTITY_CHANGE_AUDITOR', 'ONEIDENTITY_DEFENDER', 'ONEIDENTITY_TPAM', 'ONELOGIN_SSO', 'ONELOGIN_USER_CONTEXT', 'ONEPASSWORD', 'OPENAM', 'OPENDJ', 'OPENGEAR', 'OPENLDAP', 'OPENPATH', 'OPENSSH', 'OPENTEXT_FAX2MAIL', 'OPEN_VPN', 'ORACLE_CLOUD_AUDIT', 'ORACLE_DB', 'ORACLE_WEBLOGIC', 'ORCA', 'ORDR_IOT', 'OSCAR_CLAIMS', 'OSINT_IOC', 'OSIRIUM_PAM', 'OSQUERY_EDR', 'OSSEC', 'PACOM_SYSTEMS', 'PAGERDUTY', 'PAN_CASB', 'PAN_CORTEX_XDR_EVENTS', 'PAN_EDR', 'PAN_FIREWALL', 'PAN_GLOBAL_PROTECT', 'PAN_IOC', 'PAN_PRISMA_CLOUD', 'PAN_XSOAR', 'PASSIVE_DNS', 'PCAP_SSL_CLIENT_HELLO', 'PENTERA_ASV', 'PEOPLESOFT', 'PEPLINK_LOADBALANCER', 'PEPLINK_ROUTER', 'PEPLINK_SWITCH', 'PERIMETERX_BOT_PROTECTION', 'PFSENSE', 'PHISHEYE_ALERT', 'PING', 'PING_FEDERATE', 'PIVOTAL', 'PLASO', 'PLIXER_SCRUTINIZER', 'POSTFIX_MAIL', 'POWERSHELL', 'POWER_DNS', 'PREEMPT', 'PREEMPT_AUTH', 'PREVEIL_ENTERPRISE', 'PROOFID', 'PROOFPOINT_CASB', 'PROOFPOINT_MAIL', 'PROOFPOINT_MAIL_FILTER', 'PROOFPOINT_ON_DEMAND', 'PROOFPOINT_TRAP', 'PROOFPOINT_WEB_BROWSER_ISOLATION', 'PROTEGRITY_DEFIANCE', 'PROWATCH', 'PULSE_SECURE_VPN', 'PULSE_SECURE_VTM', 'PUPPET', 'PURE_STORAGE', 'QNAP_NAS', 'QUALYS_CONTINUOUS_MONITORING', 'QUALYS_VM', 'QUEST_AD', 'RADIUS', 'RADWARE_DDOS', 'RADWARE_FIREWALL', 'RAPID7_INSIGHT', 'RAPID7_NEXPOSE', 'RECORDED_FUTURE_IOC', 'REDCANARY_CLOUD_PROTECTION_RAW', 'REDCANARY_EDR', 'REDHAT_DIRECTORY_SERVER', 'REDHAT_IM', 'REDHAT_KEYCLOAK', 'REDHAT_OPENSHIFT', 'REDHAT_STACKROX', 'REMEDIANT_SECUREONE', 'RH_ISAC_IOC', 'RIBBON_ANALYTICS_PLATFORM', 'RIBBON_SBC', 'RING_CENTRAL', 'RISKIQ_DIGITAL_FOOTPRINT', 'RSA_AUTH_MANAGER', 'RSA_NETWITNESS', 'RSA_SECURID', 'RUBRIK', 'RUBRIK_POLARIS', 'RUCKUS_WIRELESS', 'RUMBLE_NETWORK_DISCOVERY', 'SAFECONNECT_NAC', 'SAILPOINT_IAM', 'SALESFORCE', 'SALESFORCE_CONTEXT', 'SAP_C4C', 'SAP_HANA', 'SAP_IDM', 'SAP_INSURANCE', 'SAP_SUCCESSFACTORS', 'SAVIYNT_EIP', 'SECBERUS', 'SECUREAUTH_SSO', 'SECURELINK', 'SECURITYSCORECARD', 'SEMPERIS_ADFR', 'SEMPERIS_DSP', 'SENDMAIL', 'SENTINELONE_ALERT', 'SENTINEL_DV', 'SENTINEL_EDR', 'SEP', 'SERVICENOW_AUDIT', 'SERVICENOW_CMDB', 'SERVICENOW_ROLES', 'SERVICENOW_SECURITY', 'SEVCO_CMDB', 'SHAREPOINT', 'SHIBBOLETH_IDP', 'SHODAN_IO', 'SHRUBBERY_TACACS', 'SIEMENS_SIPASS', 'SIGNAL_SCIENCES_WAF', 'SILVERFORT', 'SILVERPEAK_FIREWALL', 'SITEMINDER_SSO', 'SLACK_AUDIT', 'SNARE_SOLUTIONS', 'SNIPE_IT', 'SNOOPY_LOGGER', 'SNORT_IDS', 'SNOWFLAKE', 'SOFTWARE_HOUSE_ACS', 'SOLARIS_SYSTEM', 'SOLARWINDS_KSS', 'SOLARWINDS_SERV_U', 'SONARQUBE', 'SONIC_FIREWALL', 'SOPHOS_AV', 'SOPHOS_CAPSULE8', 'SOPHOS_CENTRAL', 'SOPHOS_DHCP', 'SOPHOS_EDR', 'SOPHOS_FIREWALL', 'SOPHOS_UTM', 'SOTI_MOBICONTROL', 'SOURCEFIRE_IDS', 'SPLUNK', 'SPLUNK_DNS', 'SPLUNK_PHANTOM', 'SPYCLOUD', 'SQUID_WEBPROXY', 'STAIRWELL_INCEPTION', 'STEALTHBITS_AUDIT', 'STEALTHBITS_DEFEND', 'STEELHEAD', 'STORMSHIELD_FIREWALL', 'STREAMALERT', 'STRONGSWAN_VPN', 'SUPERNA_EYEGLASS', 'SUREVIEW_SYSTEMS', 'SURICATA_EVE', 'SURICATA_IDS', 'SWIFT_AMH', 'SWIMLANE', 'SYMANTEC_CASB', 'SYMANTEC_DLP', 'SYMANTEC_EDR', 'SYMANTEC_EVENT_EXPORT', 'SYMANTEC_MAIL', 'SYMANTEC_VIP', 'SYMANTEC_WEB_ISOLATION', 'SYMANTEC_WSS', 'SYSDIG', 'TANIUM_ASSET', 'TANIUM_AUDIT', 'TANIUM_COMPLY', 'TANIUM_DEPLOY', 'TANIUM_DISCOVER', 'TANIUM_INSIGHT', 'TANIUM_INTEGRITY_MONITOR', 'TANIUM_PATCH', 'TANIUM_QUESTION', 'TANIUM_REVEAL', 'TANIUM_TH', 'TANIUM_THREAT_RESPONSE', 'TCPWAVE_DDI', 'TEAMVIEWER', 'TELEPORT_ACCESS_PLANE', 'TENABLE_IO', 'TENABLE_SC', 'TERRAFORM_ENTERPRISE', 'TESSIAN_PLATFORM', 'TGDETECT', 'THALES_DIS', 'THALES_LUNA_HSM', 'THALES_MFA', 'THINKST_CANARY', 'THREATCONNECT_IOC', 'THYCOTIC', 'THYCOTIC_DEVOPS_SECRETVAULT', 'TIPPING_POINT', 'TOMCAT', 'TRACEABLE_PLATFORM', 'TRENDMICRO_AV', 'TRENDMICRO_CLOUDAPPSECURITY', 'TRENDMICRO_DEEP_SECURITY', 'TRENDMICRO_EDR', 'TRENDMICRO_WEBPROXY', 'TRIPWIRE_FIM', 'TWILIO_AUDIT', 'UBIQUITI_SWITCH', 'UDM', 'ULTRADNS', 'ULTRA_CYBERFENCE', 'UMBRELLA_DNS', 'UMBRELLA_FIREWALL', 'UMBRELLA_IP', 'UMBRELLA_WEBPROXY', 'UNBOUND_DNS', 'UNIFI_AP', 'UNIFI_SWITCH', 'UNIT21', 'UPTYCS_EDR', 'VANDYKE_SFTP', 'VARONIS', 'VECTRA_DETECT', 'VECTRA_PROTECT', 'VECTRA_STREAM', 'VEEAM', 'VENAFI', 'VERIZON_NDR', 'VERSA_FIREWALL', 'VIRUSTOTAL_THREAT_HUNTER', 'VITALQIP', 'VMRAY_FLOG_XML', 'VMWARE_AVINETWORKS_IWAF', 'VMWARE_AVI_VANTAGE', 'VMWARE_ESX', 'VMWARE_HCX', 'VMWARE_HORIZON', 'VMWARE_NSX', 'VMWARE_SDWN_EVENTS', 'VMWARE_TANZU', 'VMWARE_VCENTER', 'VMWARE_VREALIZE', 'VMWARE_VSHIELD', 'VMWARE_WORKSPACE_ONE', 'VOLTAGE', 'VORMETRIC', 'VSFTPD_AUDIT', 'VYOS', 'WATCHGUARD', 'WAZUH', 'WHITECLOUD_EDR', 'WINDOWS_AD', 'WINDOWS_APPLOCKER', 'WINDOWS_DEFENDER_ATP', 'WINDOWS_DEFENDER_AV', 'WINDOWS_DHCP', 'WINDOWS_DNS', 'WINDOWS_FIREWALL', 'WINDOWS_NET_POLICY_SERVER', 'WINDOWS_SYSMON', 'WINEVTLOG', 'WINEVTLOG_XML', 'WIZ_IO', 'WORDPRESS_CMS', 'WORKDAY', 'WORKDAY_AUDIT', 'WORKSPACE_ACTIVITY', 'WORKSPACE_ALERTS', 'WORKSPACE_CHROMEOS', 'WORKSPACE_GROUPS', 'WORKSPACE_MOBILE', 'WORKSPACE_PRIVILEGES', 'WORKSPACE_USERS', 'WORKSPOT_CONTROL', 'WP_ENGINE', 'WTI_CONSOLE_SERVERS', 'YUBICO_OTP', 'ZENDESK_CRM', 'ZEROFOX_PLATFORM', 'ZIMPERIUM', 'ZIX_EMAIL_ENCRYPTION', 'ZOOM_OPERATION_LOGS', 'ZSCALER_CASB', 'ZSCALER_DECEPTION', 'ZSCALER_DIGITAL_EXPERIENCE', 'ZSCALER_DLP', 'ZSCALER_DNS', 'ZSCALER_FIREWALL', 'ZSCALER_VPN', 'ZSCALER_WEBPROXY'] {allow-input: true}\n",
        "\n",
        "#@markdown Time and date are in UTC\n",
        "start_date = \"2023-07-01\" #@param {type : \"date\"}\n",
        "end_date = \"2023-07-13\" #@param {type : \"date\"}\n",
        "\n",
        "#@markdown Time should be in the format HH:MM:SS including leading zeros\n",
        "startTime = \"00:00:00\" #@param {type: \"string\"}\n",
        "endTime = \"23:59:59\" #@param {type: \"string\"}\n",
        "\n",
        "startTime = f\"{start_date}T{startTime}Z\"\n",
        "endTime = f\"{end_date}T{endTime}Z\"\n",
        "\n",
        "decode_base64 = True #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown Check the below checkbox to download the result to your computer, otherwise the results will only be saved to the colab instnace.\n",
        "download_file = True #@param {type: \"boolean\"}\n",
        "# Construct the URL\n",
        "uri = f\"https://{region_prefix}backstory.googleapis.com/v1/tools/cbnParsers:listCbnParserErrors?log_type={logtype}&start_time={startTime}&end_time={endTime}\"\n",
        "# send the request and process the response\n",
        "# timeout set to ten minutes because some complaints of timeouts for long calls were received.\n",
        "resp = session.get(uri, timeout=600)\n",
        "json_resp = resp.json()\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  if f\"{logtype}-{startTime}-{endTime}.json\" in os.listdir():\n",
        "    os.remove(f\"{logtype}-{startTime}-{endTime}.json\")\n",
        "\n",
        "  if decode_base64:\n",
        "    for error_index in range(len(json_resp['errors'])):\n",
        "      for log_index in range(len(json_resp['errors'][error_index][\"logs\"])):\n",
        "        json_resp['errors'][error_index][\"logs\"][log_index] = base64.b64decode(json_resp['errors'][error_index][\"logs\"][log_index]).decode()\n",
        "  f = open( f\"{logtype}-{startTime}-{endTime}.json\", \"w\")\n",
        "  f.write(json.dumps(json_resp))\n",
        "  f.close()\n",
        "  print(f\"Errors written to filename: {logtype}-{startTime}-{endTime}.json \")\n",
        "  if download_file:\n",
        "    files.download(f\"{logtype}-{startTime}-{endTime}.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "g5XT8Nzgphbk"
      },
      "outputs": [],
      "source": [
        "#@title Get all CBN parsers\n",
        "#@markdown This will take many  minutes to run. Please prepare to twiddle your thumbs, or better yet just use the above cell to get the specific parser(s) you need one at a time.\n",
        "\n",
        "# config ID list taken from ingest API get support log types endpoint\n",
        "parser_list = [\"A10_LOAD_BALANCER\",\"ABNORMAL_SECURITY\",\"ABSOLUTE\",\"ACALVIO\",\"ACCELLION\",\"ADAUDIT_PLUS\",\"ADFS\",\"ADVA_FSP\",\"AI_HUNTER\",\"AIRLOCK_DIGITAL\",\"AIRWATCH\",\"AIX_SYSTEM\",\"AKAMAI_CLOUD_MONITOR\",\"AKAMAI_DNS\",\"AKAMAI_EAA\",\"AKAMAI_SIEM_CONNECTOR\",\"AKAMAI_WAF\",\"AKEYLESS_VAULT\",\"ALCATEL_SWITCH\",\"ALGOSEC\",\"AMD_DSS_FIREWALL\",\"ANOMALI_IOC\",\"ANSIBLE_AWX\",\"APACHE\",\"APPOMNI\",\"AQUA_SECURITY\",\"ARBOR_EDGE_DEFENSE\",\"ARBOR_SIGHTLINE\",\"ARCHER_IRM\",\"ARCSIGHT_CEF\",\"AREA1\",\"ARISTA_SWITCH\",\"ARMIS_ACTIVITIES\",\"ARMIS_ALERTS\",\"ARMIS_DEVICES\",\"ARMIS_VULNERABILITIES\",\"ARRAYNETWORKS_VPN\",\"ARUBA_AIRWAVE\",\"ARUBA_EDGECONNECT_SDWAN\",\"ARUBA_IPS\",\"ARUBA_SWITCH\",\"ARUBA_WIRELESS\",\"ASOC_ALERT\",\"ASSET_STATIC_IP\",\"ATLASSIAN_BITBUCKET\",\"ATLASSIAN_CONFLUENCE\",\"ATLASSIAN_JIRA\",\"ATTIVO\",\"AUDITD\",\"AUTH_ZERO\",\"AUTOMATION_ANYWHERE\",\"AVANAN_EMAIL\",\"AVATIER\",\"AVAYA_AURA\",\"AWAKE_NDR\",\"AWS_API_GATEWAY\",\"AWS_AURORA\",\"AWS_CLOUDFRONT\",\"AWS_CLOUDTRAIL\",\"AWS_CLOUDWATCH\",\"AWS_CONFIG\",\"AWS_CONTROL_TOWER\",\"AWS_EC2_HOSTS\",\"AWS_EC2_INSTANCES\",\"AWS_EC2_VPCS\",\"AWS_ELB\",\"AWS_EMR\",\"AWS_IAM\",\"AWS_KMS\",\"AWS_MACIE\",\"AWS_NETWORK_FIREWALL\",\"AWS_RDS\",\"AWS_ROUTE_53\",\"AWS_S3_SERVER_ACCESS\",\"AWS_SECURITY_HUB\",\"AWS_SESSION_MANAGER\",\"AWS_VPC_FLOW\",\"AWS_VPN\",\"AWS_WAF\",\"AZION\",\"AZURE_ACTIVITY\",\"AZURE_AD\",\"AZURE_AD_AUDIT\",\"AZURE_AD_CONTEXT\",\"AZURE_AD_SIGNIN\",\"AZURE_APP_SERVICE\",\"AZURE_COSMOS_DB\",\"AZURE_DEVOPS\",\"AZURE_FIREWALL\",\"AZURE_GATEWAY\",\"AZURE_KEYVAULT_AUDIT\",\"AZURE_MDM_INTUNE\",\"AZURE_NSG_FLOW\",\"AZURE_RESOURCE_LOGS\",\"AZURE_SQL\",\"AZURE_STORAGE_AUDIT\",\"AZURE_VPN\",\"AZURE_WAF\",\"BARRACUDA_EMAIL\",\"BARRACUDA_FIREWALL\",\"BARRACUDA_WAF\",\"BARRACUDA_WEBFILTER\",\"BEYONDTRUST_ENDPOINT\",\"BEYONDTRUST_PI\",\"BEYONDTRUST_REMOTE_ACCESS\",\"BIGSWITCH_BCF\",\"BIND_DNS\",\"BITDEFENDER\",\"BITWARDEN_EVENTS\",\"BLOXONE\",\"BLUECAT_DDI\",\"BLUECAT_EDGE\",\"BLUECOAT_WEBPROXY\",\"BMC_AMI_DEFENDER\",\"BMC_HELIX_DISCOVERY\",\"BOMGAR\",\"BOX\",\"BRO_JSON\",\"BRO_TSV\",\"BROADCOM_SSL_VA\",\"BROCADE_SERVERIRON\",\"BROCADE_SWITCH\",\"CA_ACCESS_CONTROL\",\"CA_ACF2\",\"CA_LDAP\",\"CA_SSO_WEB\",\"CAMBIUM_NETWORKS\",\"CASSANDRA\",\"CATO_NETWORKS\",\"CB_APP_CONTROL\",\"CB_EDR\",\"CENSYS\",\"CENTRIFY_SSO\",\"CENTRIPETAL_IOC\",\"CEQUENCE_BOT_DEFENSE\",\"CHECKPOINT_AUDIT\",\"CHECKPOINT_EDR\",\"CHECKPOINT_FIREWALL\",\"CHECKPOINT_HARMONY\",\"CHECKPOINT_SMARTDEFENSE\",\"CHRONICLE_SOAR_AUDIT\",\"CIMCOR\",\"SYSLOG\",\"CIRCLECI\",\"CIS_ALBERT_ALERT\",\"CISCO_ACE\",\"CISCO_ACI\",\"CISCO_ACS\",\"CISCO_AMP\",\"CISCO_ASA_FIREWALL\",\"CISCO_CLOUDLOCK_CASB\",\"CISCO_CTS\",\"CISCO_DHCP\",\"CISCO_DNAC\",\"CISCO_EMAIL_SECURITY\",\"CISCO_ESTREAMER\",\"CISCO_FIREPOWER_FIREWALL\",\"CISCO_FIRESIGHT\",\"CISCO_FWSM\",\"CISCO_IOS\",\"CISCO_IRONPORT\",\"CISCO_ISE\",\"CISCO_MERAKI\",\"CISCO_NX_OS\",\"CISCO_PIX_FIREWALL\",\"CISCO_PRIME\",\"CISCO_ROUTER\",\"CISCO_SECURE_WORKLOAD\",\"CISCO_STADIUMVISION\",\"CISCO_STEALTHWATCH\",\"CISCO_SWITCH\",\"CISCO_TACACS\",\"CISCO_UCM\",\"CISCO_UCS\",\"CISCO_UMBRELLA_AUDIT\",\"CISCO_VCS\",\"CISCO_VPN\",\"CISCO_WIPS\",\"CISCO_WIRELESS\",\"CISCO_WSA\",\"CISCO_WSM\",\"CITRIX_ANALYTICS\",\"CITRIX_MONITOR\",\"CITRIX_NETSCALER\",\"CITRIX_STOREFRONT\",\"CLAM_AV\",\"CLAROTY_EMC\",\"CLEARPASS\",\"CLEARSWIFT\",\"CLOUD_IDENTITY_CONTEXT\",\"CLOUD_PASSAGE\",\"CLOUDFLARE\",\"CLOUDFLARE_AUDIT\",\"CLOUDFLARE_WAF\",\"CLOUDGENIX_SDWAN\",\"CLOUDIAN_HYPERSTORE\",\"CLOUDM\",\"COFENSE_TRIAGE\",\"COHESITY\",\"COMFORTE_SECURDPS\",\"COMMVAULT\",\"COMMVAULT_COMMCELL\",\"COMODO_AV\",\"CORELIGHT\",\"CORTEX_XDR\",\"COVID_CTC_IOC\",\"CRIBL_STREAM\",\"CROWDSTRIKE_IOC\",\"CS_DETECTS\",\"CS_EDR\",\"CS_STREAM\",\"CSV_CUSTOM_IOC\",\"CUSTOM_APPLICATION_ACCESS\",\"CUSTOM_DNS\",\"CUSTOM_SECURITY_DATA_ANALYTICS\",\"CYBER_2_IDS\",\"CYBERARK\",\"CYBERARK_EPM\",\"CYBERARK_PAM\",\"CYBERARK_PRIVILEGE_CLOUD\",\"CYBERARK_PTA\",\"CYBEREASON_EDR\",\"CYBERGATEKEEPER_NAC\",\"CYBERX\",\"CYLANCE_PROTECT\",\"CYNET_360_AUTOXDR\",\"D3_BANKING\",\"DARKTRACE\",\"DATADOG\",\"DATAMINR_ALERT\",\"DATTO_FILE_PROTECTION\",\"DB2_DB\",\"DEEP_INSTINCT_EDR\",\"DELINEA_PAM\",\"DELL_ECS\",\"DELL_EMC_DATA_DOMAIN\",\"DELL_EMC_NAS\",\"DELL_OPENMANAGE\",\"DELL_SWITCH\",\"DESYNOVA_CONTIDO\",\"DHS_IOC\",\"DIGI_MODEMS\",\"DIGITAL_SHADOWS_IOC\",\"DIGITAL_SHADOWS_SEARCHLIGHT\",\"DIGITALARTS_IFILTER\",\"DIGITALGUARDIAN_DLP\",\"DIGITALGUARDIAN_EDR\",\"DMP_ENTRE\",\"DNSFILTER\",\"DOMAINTOOLS_THREATINTEL\",\"DOPE_SWG\",\"DUO_ADMIN\",\"DUO_AUTH\",\"DUO_CONTEXT\",\"DUO_TELEPHONY\",\"DUO_USER_CONTEXT\",\"EFFICIENTIP_DDI\",\"ELASTIC_AUDITBEAT\",\"ELASTIC_PACKETBEATS\",\"ELASTIC_SEARCH\",\"ELASTIC_WINLOGBEAT\",\"ENDPOINT_PROTECTOR_DLP\",\"EPIC\",\"ERGON_INFORMATIK_AIRLOCK_IAM\",\"ESET_AV\",\"ESET_EDR\",\"ESET_IOC\",\"ET_PRO_IOC\",\"EVISION_FIRCOSOFT\",\"EXCHANGE_MAIL\",\"EXTRAHOP\",\"EXTRAHOP_DNS\",\"EXTREME_SWITCH\",\"EXTREME_WIRELESS\",\"F5_AFM\",\"F5_ASM\",\"F5_BIGIP_APM\",\"F5_BIGIP_LTM\",\"F5_DNS\",\"F5_SHAPE\",\"F5_SILVERLINE\",\"F5_VPN\",\"FALCO_IDS\",\"FASTLY_WAF\",\"FIDELIS_NETWORK\",\"FILE_SCANNING_FRAMEWORK\",\"FILEZILLA_FTP\",\"FIREEYE_ALERT\",\"FIREEYE_ETP\",\"FIREEYE_HX\",\"FIREEYE_HX_AUDIT\",\"FIREEYE_NX\",\"FIREEYE_NX_AUDIT\",\"FIREEYE_PX\",\"FIVETRAN\",\"FLUENTD\",\"FORCEPOINT_CASB\",\"FORCEPOINT_DLP\",\"FORCEPOINT_EMAILSECURITY\",\"FORCEPOINT_FIREWALL\",\"FORCEPOINT_MAIL_RELAY\",\"FORCEPOINT_WEBPROXY\",\"FORESCOUT_NAC\",\"FORGEROCK_IDENTITY_CLOUD\",\"FORGEROCK_OPENIDM\",\"FORSETI\",\"FORTINET_DHCP\",\"FORTINET_FIREWALL\",\"FORTINET_FORTIANALYZER\",\"FORTINET_FORTIAUTHENTICATOR\",\"FORTINET_FORTICLIENT\",\"FORTINET_FORTIEDR\",\"FORTINET_FORTIMAIL\",\"FORTINET_FORTIMANAGER\",\"FORTINET_FORTINAC\",\"FORTINET_FORTIWEB\",\"FORTRA_POWERTECH_SIEM_AGENT\",\"GCP_APIGEE\",\"GCP_APIGEE_X\",\"GCP_APP_ENGINE\",\"GCP_CLOUD_FUNCTIONS_CONTEXT\",\"GCP_CLOUDIDENTITY_DEVICES\",\"GCP_CLOUDIDENTITY_DEVICEUSERS\",\"GCP_CLOUDIOT\",\"GCP_CLOUDSQL\",\"GCP_COMPUTE\",\"GCP_IDS\",\"GCP_KUBERNETES_CONTEXT\",\"GCP_LOADBALANCING\",\"GCP_NETWORK_CONNECTIVITY_CONTEXT\",\"GCP_NGFW_ENTERPRISE\",\"GCP_RECAPTCHA_ENTERPRISE\",\"GCP_RESOURCE_MANAGER_CONTEXT\",\"GCP_RUN\",\"GCP_SECURITYCENTER_POSTURE_VIOLATION\",\"GCP_SECURITYCENTER_TOXIC_COMBINATION\",\"GCP_SQL_CONTEXT\",\"GCP_SWP\",\"GCP_VPC_FLOW\",\"GITHUB\",\"GITLAB\",\"GMAIL_LOGS\",\"GMV_CHECKER\",\"GUARDDUTY\",\"GUARDICORE_CENTRA\",\"GUARDIUM\",\"HADOOP\",\"HAPROXY\",\"HASHICORP\",\"HCL_BIGFIX\",\"HCNET_ACCOUNT_ADAPTER\",\"HID_DIGITALPERSONA\",\"HITACHI_CLOUD_PLATFORM\",\"HONEYD\",\"HP_PROCURVE\",\"HPE_BLADESYSTEM_C7000\",\"HPE_ILO\",\"HYPR_MFA\",\"IBM_AS400\",\"IBM_CICS\",\"IBM_DATAPOWER\",\"IBM_DS8000\",\"IBM_I\",\"IBM_LTO\",\"IBM_MAINFRAME_STORAGE\",\"IBM_OPENPAGES\",\"IBM_QRADAR\",\"IBM_SAFENET\",\"IBM_SAM\",\"IBM_SECURITY_VERIFY\",\"IBM_SECURITY_VERIFY_SAAS\",\"IBM_SIM\",\"IBM_TIVOLI\",\"IBM_WEBSEAL\",\"IBM_WEBSPHERE_APP_SERVER\",\"IBM_ZOS\",\"IBOSS_WEBPROXY\",\"IIS\",\"ILLUMIO_CORE\",\"IMPERVA_ABP\",\"IMPERVA_AUDIT_TRAIL\",\"IMPERVA_CEF\",\"IMPERVA_DB\",\"IMPERVA_FLEXPROTECT\",\"IMPERVA_SECURESPHERE\",\"IMPERVA_WAF\",\"INFOBLOX\",\"INFOBLOX_DHCP\",\"INFOBLOX_DNS\",\"INFOBLOX_RPZ\",\"INFORMIX\",\"INGRIAN_NETWORKS_DATASECURE_APPLIANCE\",\"INTERSYSTEMS_CACHE\",\"ION_SPECTRUM\",\"IONIX\",\"IPSWITCH_MOVEIT_TRANSFER\",\"IPSWITCH_SFTP\",\"IRONSTREAM_ZOS\",\"ISC_DHCP\",\"ISLAND_BROWSER\",\"JAMF\",\"JAMF_PRO\",\"JAMF_PROTECT\",\"JAMF_TELEMETRY\",\"JENKINS\",\"JFROG_ARTIFACTORY\",\"JUMPCLOUD_DIRECTORY_INSIGHTS\",\"JUNIPER_FIREWALL\",\"JUNIPER_IPS\",\"JUNIPER_JUNOS\",\"JUNIPER_MIST\",\"JUNIPER_MX\",\"JUNIPER_SDWAN\",\"KASPERSKY_AV\",\"KEA_DHCP\",\"KEEPER\",\"KEMP_LOADBALANCER\",\"KERIOCONTROL\",\"KEYCLOAK\",\"KISI\",\"KITEWORKS\",\"KOLIDE\",\"KONG_GATEWAY\",\"KUBERNETES_AUDIT\",\"KUBERNETES_AUDIT_AZURE\",\"KUBERNETES_AUTH_PROXY\",\"KUBERNETES_NODE\",\"KYRIBA\",\"LACEWORK\",\"LASTPASS\",\"LENEL_ONGUARD\",\"LIMACHARLIE_EDR\",\"LINUX_DHCP\",\"LINUX_SYSMON\",\"LOGONBOX\",\"LOOKOUT_MOBILE_ENDPOINT_SECURITY\",\"LUCID\",\"MACOS\",\"MACOS_ENDPOINT_SECURITY\",\"MAILMARSHAL\",\"MALWAREBYTES_EDR\",\"MANAGE_ENGINE_AD360\",\"MANAGE_ENGINE_REPORTER_PLUS\",\"MANDIANT_CUSTOM_IOC\",\"MARIA_DB\",\"MATTERMOST\",\"MCAFEE_DLP\",\"MCAFEE_EPO\",\"MCAFEE_ESM\",\"MCAFEE_IPS\",\"MCAFEE_MVISION_CASB\",\"MCAFEE_SKYHIGH_CASB\",\"MCAFEE_UCE\",\"MCAFEE_WEB_PROTECTION\",\"MCAFEE_WEBPROXY\",\"MEDIGATE_IOT\",\"MENANDMICE_DNS\",\"MENLO_SECURITY\",\"MICROFOCUS_IMANAGER\",\"MICROSOFT_ATA\",\"MICROSOFT_CASB\",\"MICROSOFT_DEFENDER_CLOUD_ALERTS\",\"MICROSOFT_DEFENDER_ENDPOINT\",\"MICROSOFT_DEFENDER_IDENTITY\",\"MICROSOFT_DEFENDER_MAIL\",\"MICROSOFT_GRAPH_ACTIVITY_LOGS\",\"MICROSOFT_GRAPH_ALERT\",\"MICROSOFT_IAS\",\"MICROSOFT_LAPS\",\"MICROSOFT_NPS\",\"MICROSOFT_SCEP\",\"MICROSOFT_SENTINEL\",\"MICROSOFT_SQL\",\"MIKROTIK_ROUTER\",\"MIMECAST_MAIL\",\"MIMECAST_URL_LOGS\",\"MISP_IOC\",\"MOBILEIRON\",\"MONGO_DB\",\"MYSQL\",\"N\",\"N\",\"N\",\"N\",\"N\",\"N\",\"N\",\"N\",\"N\",\"N\",\"N\",\"N\",\"NAGIOS\",\"NASUNI_FILE_SERVICES\",\"NEO4J\",\"NEOSEC\",\"NET_SUITE\",\"NETAPP_ONTAP\",\"NETAPP_SAN\",\"NETAPP_STORAGEGRID\",\"NETDOCUMENTS\",\"NETFILTER_IPTABLES\",\"NETIQ_EDIRECTORY\",\"NETSCOUT_OCI\",\"NETSKOPE_ALERT\",\"NETSKOPE_CASB\",\"NETSKOPE_WEBPROXY\",\"NETWRIX\",\"NGINX\",\"NIMBLE_OS\",\"NIX_SYSTEM\",\"NOKIA_ROUTER\",\"NONAME_API_SECURITY\",\"NTOPNG\",\"NUCLEUS_ASSET\",\"NUCLEUS_VULNERABILITY\",\"NUTANIX_PRISM\",\"NXLOG_MANAGER\",\"NYANSA_EVENTS\",\"OBSERVEIT\",\"OCI_AUDIT\",\"OCI_FLOW\",\"OCSF\",\"OFFICE_365\",\"OFFICE_365_MESSAGETRACE\",\"OKERA_DAP\",\"OKTA\",\"OKTA_ACCESS_GATEWAY\",\"OKTA_USER_CONTEXT\",\"ONAPSIS\",\"ONELOGIN_SSO\",\"ONEPASSWORD\",\"ONFIDO\",\"OPEN_VPN\",\"OPENAM\",\"OPENCANARY\",\"OPENDJ\",\"OPENGEAR\",\"OPENLDAP\",\"OPENPATH\",\"OPENSSH\",\"OPNSENSE\",\"ORACLE_CLOUD_AUDIT\",\"ORACLE_DB\",\"ORACLE_OUD\",\"ORDR_IOT\",\"OSQUERY_EDR\",\"OSSEC\",\"PAN_CASB\",\"PAN_CORTEX_XDR_EVENTS\",\"PAN_EDR\",\"PAN_FIREWALL\",\"PAN_IOC\",\"PAN_PANORAMA\",\"PAN_PRISMA_CA\",\"PAN_PRISMA_CLOUD\",\"PASSIVE_DNS\",\"PASSWORDSTATE\",\"PEPLINK_FW\",\"PERIMETERX_BOT_PROTECTION\",\"PFSENSE\",\"PHISHLABS\",\"PING\",\"PING_FEDERATE\",\"PIVOTAL\",\"PORTNOX_CEF\",\"POSTFIX_MAIL\",\"POSTGRESQL\",\"POWERSHELL\",\"PREEMPT\",\"PREEMPT_AUTH\",\"PROOFPOINT_MAIL\",\"PROOFPOINT_MAIL_FILTER\",\"PROOFPOINT_ON_DEMAND\",\"PROOFPOINT_SENDMAIL_SENTRION\",\"PROOFPOINT_SER\",\"PROOFPOINT_TRAP\",\"PROOFPOINT_WEB_BROWSER_ISOLATION\",\"PULSE_SECURE_VPN\",\"PULSE_SECURE_VTM\",\"QUALYS_ASSET_CONTEXT\",\"QUALYS_CONTINUOUS_MONITORING\",\"QUALYS_SCAN\",\"QUALYS_VIRTUAL_SCANNER\",\"QUALYS_VM\",\"QUEST_AD\",\"QUEST_CHANGE_AUDITOR_EMC\",\"QUEST_FILE_AUDIT\",\"QUMULO_FS\",\"RADWARE_ALTEON\",\"RADWARE_FIREWALL\",\"RAPID7_INSIGHT\",\"RAPID7_NEXPOSE\",\"RECORDED_FUTURE_IOC\",\"RECORDIA\",\"REDCANARY_EDR\",\"REDHAT_DIRECTORY_SERVER\",\"REDHAT_OPENSHIFT\",\"REMEDIANT_SECUREONE\",\"RH_ISAC_IOC\",\"RIBBON_ANALYTICS_PLATFORM\",\"RIPPLING_ACTIVITYLOGS\",\"RSA_AUTH_MANAGER\",\"RSA_NETWITNESS\",\"RSA_SECURID\",\"RUBRIK\",\"RUBRIK_POLARIS\",\"RUCKUS_WIRELESS\",\"SAILPOINT_IAM\",\"SAIWALL_VPN\",\"SALESFORCE\",\"SANGFOR_NGAF\",\"SAP_BTP\",\"SAP_NETWEAVER\",\"SAP_SAST\",\"SAP_SM20\",\"SAP_SUCCESSFACTORS\",\"SAP_WEBDISP\",\"SAVIYNT_EIP\",\"SECUREAUTH_SSO\",\"SECURELINK\",\"SEMPERIS_DSP\",\"SENDMAIL\",\"SENTINEL_DV\",\"SENTINEL_EDR\",\"SENTINELONE_ALERT\",\"SENTINELONE_CF\",\"SEP\",\"SEPPMAIL\",\"SEQRITE_ENDPOINT\",\"SERVICENOW_CMDB\",\"SERVICENOW_SECURITY\",\"SHIBBOLETH_IDP\",\"SHRUBBERY_TACACS\",\"SIERRA_WIRELESS\",\"SIGNAL_SCIENCES_WAF\",\"SILVERFORT\",\"SITEMINDER_SSO\",\"SKYBOX_FIREWALL_ASSURANCE\",\"SLACK_AUDIT\",\"SMBD\",\"SNARE_SOLUTIONS\",\"SNOOPY_LOGGER\",\"SNORT_IDS\",\"SNOWFLAKE\",\"SNYK_SDLC\",\"SOLARIS_SYSTEM\",\"SOLARWINDS_KSS\",\"SONIC_FIREWALL\",\"SONICWALL_SMA\",\"SONRAI\",\"SOPHOS_AV\",\"SOPHOS_CAPSULE8\",\"SOPHOS_CENTRAL\",\"SOPHOS_DHCP\",\"SOPHOS_EDR\",\"SOPHOS_FIREWALL\",\"SOPHOS_UTM\",\"SOTI_MOBICONTROL\",\"SOURCEFIRE_IDS\",\"SPLUNK\",\"SPLUNK_ATTACK_ANALYZER\",\"SPUR_FEEDS\",\"SPYCLOUD\",\"SQUID_WEBPROXY\",\"STEALTHBITS_AUDIT\",\"STEALTHBITS_DEFEND\",\"STEALTHBITS_PAM\",\"STEELHEAD\",\"STIX\",\"STORMSHIELD_FIREWALL\",\"STRONGSWAN_VPN\",\"SURICATA_EVE\",\"SURICATA_IDS\",\"SWIFT_AMH\",\"SYMANTEC_CASB\",\"SYMANTEC_DLP\",\"SYMANTEC_EDR\",\"SYMANTEC_EVENT_EXPORT\",\"SYMANTEC_VIP\",\"SYMANTEC_VIP_AUTHHUB\",\"SYMANTEC_WEB_ISOLATION\",\"SYMANTEC_WSS\",\"SYNOLOGY\",\"SYSDIG\",\"TABLEAU\",\"TALON\",\"TANIUM_ASSET\",\"TANIUM_AUDIT\",\"TANIUM_COMPLY\",\"TANIUM_DISCOVER\",\"TANIUM_INSIGHT\",\"TANIUM_INTEGRITY_MONITOR\",\"TANIUM_PATCH\",\"TANIUM_REVEAL\",\"TANIUM_TH\",\"TANIUM_THREAT_RESPONSE\",\"TCPWAVE_DDI\",\"TEAMVIEWER\",\"TELEPORT_ACCESS_PLANE\",\"TENABLE_ADS\",\"TENABLE_AUDIT\",\"TENABLE_IO\",\"TENABLE_OT\",\"TENABLE_SC\",\"TERRAFORM_ENTERPRISE\",\"TETRAGON_EBPF_AUDIT_LOGS\",\"THALES_DIS\",\"THALES_LUNA_HSM\",\"THALES_MFA\",\"THINKST_CANARY\",\"THREATCONNECT_IOC\",\"THREATLOCKER\",\"THYCOTIC\",\"TIPPING_POINT\",\"TOMCAT\",\"TRELLIX_HX_ES\",\"TRENDMICRO_APEX_CENTRAL\",\"TRENDMICRO_APEX_ONE\",\"TRENDMICRO_AV\",\"TRENDMICRO_CLOUDONE\",\"TRENDMICRO_DEEP_SECURITY\",\"TRENDMICRO_VISION_ONE\",\"TRENDMICRO_WEBPROXY\",\"TRIPWIRE_FIM\",\"TWINGATE\",\"UBIKA_WAAP\",\"UBIKA_WAF\",\"UBIQUITI_SWITCH\",\"UMBRELLA_DNS\",\"UMBRELLA_FIREWALL\",\"UMBRELLA_IP\",\"UMBRELLA_WEBPROXY\",\"UNBOUND_DNS\",\"UNIFI_AP\",\"UPTYCS_EDR\",\"UPX_ANTIDDOS\",\"VANDYKE_SFTP\",\"VARONIS\",\"VECTRA_DETECT\",\"VECTRA_STREAM\",\"VEEAM\",\"VELO_FIREWALL\",\"VERBA_REC\",\"VERIDIUM_ID\",\"VERITAS_NETBACKUP\",\"VERSA_FIREWALL\",\"VIRTRU_EMAIL_ENCRYPTION\",\"VITALQIP\",\"VMWARE_ESX\",\"VMWARE_HORIZON\",\"VMWARE_NSX\",\"VMWARE_TANZU\",\"VMWARE_VCENTER\",\"VMWARE_VREALIZE\",\"VMWARE_WORKSPACE_ONE\",\"VOLTAGE\",\"VORMETRIC\",\"VSFTPD\",\"VYOS\",\"WALLIX_BASTION\",\"WATCHGUARD\",\"WATCHGUARD_EDR\",\"WAZUH\",\"WEBMARSHAL\",\"WINDCHILL\",\"WINDOWS_AD\",\"WINDOWS_APPLOCKER\",\"WINDOWS_DEFENDER_ATP\",\"WINDOWS_DEFENDER_AV\",\"WINDOWS_DHCP\",\"WINDOWS_DNS\",\"WINDOWS_FIREWALL\",\"WINDOWS_HYPERV\",\"WINDOWS_NET_POLICY_SERVER\",\"WINDOWS_SYSMON\",\"WINEVTLOG\",\"WINEVTLOG_XML\",\"WINSCP\",\"WIZ_IO\",\"WORDPRESS_CMS\",\"WORKDAY\",\"WORKDAY_AUDIT\",\"WORKSPACE_ACTIVITY\",\"WORKSPACE_ALERTS\",\"WORKSPACE_CHROMEOS\",\"WORKSPACE_GROUPS\",\"WORKSPACE_MOBILE\",\"WORKSPACE_PRIVILEGES\",\"WORKSPACE_USERS\",\"XITING_XAMS\",\"YAMAHA_ROUTER\",\"YUBICO_OTP\",\"ZIMPERIUM\",\"ZIX_EMAIL_ENCRYPTION\",\"ZOOM_OPERATION_LOGS\",\"ZSCALER_CASB\",\"ZSCALER_DECEPTION\",\"ZSCALER_DLP\",\"ZSCALER_DNS\",\"ZSCALER_FIREWALL\",\"ZSCALER_INTERNET_ACCESS\",\"ZSCALER_TUNNEL\",\"ZSCALER_VPN\",\"ZSCALER_WEBPROXY\",\"ZSCALER_ZPA\",\"ZSCALER_ZPA_AUDIT\"]\n",
        "\n",
        "download_file = True #@param {type:\"boolean\"}\n",
        "\n",
        "os.mkdir(\"cbn_files\")\n",
        "\n",
        "for logtype in parser_list:\n",
        "  uri  = 'https://{}backstory.googleapis.com/v1/tools/cbnParsers/{}'.format(region_prefix, logtype)\n",
        "  resp = http_client.request(uri, \"GET\")\n",
        "  if resp[0].status == http.HTTPStatus.OK:\n",
        "    result = json.loads(resp[1])\n",
        "    cbn = base64.b64decode(result['config'])\n",
        "\n",
        "    f = open(\"cbn_files/\" + logtype + \".conf\", \"wb\")\n",
        "    f.write(cbn)\n",
        "    f.close()\n",
        "    #print(type(cbn))\n",
        "\n",
        "    print(logtype + ': cbn exported')\n",
        "    sleep(1)\n",
        "  else:\n",
        "    print('{}: no cbn found - '.format(logtype) + str(resp[0].status) )\n",
        "    sleep(1)\n",
        "\n",
        "!zip -r cbn_files.zip cbn_files\n",
        "\n",
        "\n",
        "if download_file:\n",
        "  files.download(\"cbn_files.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yznnuK7h1lwz"
      },
      "outputs": [],
      "source": [
        "#@title Get all custom parsers\n",
        "#@markdown This *should* pull all the current custom parsrers in the instnace a key has been provided for.\n",
        "\n",
        "#@markdown Once complete a zip file containing the conf files will be downloaded by your browser.\n",
        "\n",
        "#@markdown If you'd like to browse the CBNs in the colab UI switch to the files view and look at the `custom_parsers` directory.\n",
        "\n",
        "download_file = True #@param {type: \"boolean\"}\n",
        "from pprint import pprint\n",
        "\n",
        "CHRONICLE_API_V1_URL = 'https://{}backstory.googleapis.com/v1'.format(region_prefix)\n",
        "GET_CBN_PARSERS = '{}/tools/cbnParsers'.format(CHRONICLE_API_V1_URL)\n",
        "\n",
        "print(\"Fetching parsers for Chronicle instance...\")\n",
        "# Send the request, parse the response, save logs to a file\n",
        "response = http_client.request(GET_CBN_PARSERS , 'GET')\n",
        "\n",
        "current_log_types = []\n",
        "os.mkdir(\"custom_parsers\")\n",
        "\n",
        "if response[0].status == 200:\n",
        "  live_parsers = json.loads(response[1])\n",
        "  # pprint(live_parsers)\n",
        "\n",
        "  index = 0\n",
        "  print(f\"Found {len(live_parsers['cbnParsers'])} parsers.\")\n",
        "  if \"cbnParsers\" in live_parsers:\n",
        "    for parser in live_parsers['cbnParsers']:\n",
        "      # print(\"Type: {type}\\nAuthor:{author}\\nState:{state}\\nIndex: {index}\\n\".format(author= parser['author'], state= parser[\"state\"], type= parser[\"logType\"], index=index))\n",
        "      current_log_types.append(parser[\"logType\"])\n",
        "      index += 1\n",
        "    for log_type in current_log_types:\n",
        "      print(f\"Pausing for one second for API rate limit reasons, then fetching the parser for logtype: {log_type}\")\n",
        "      sleep(1)\n",
        "      uri = f'https://{region_prefix}backstory.googleapis.com/v1/tools/cbnParsers:listCbnParserHistory?log_type={log_type}'\n",
        "      # send the request and process the response\n",
        "      resp = http_client.request(uri, \"GET\")\n",
        "      json_resp = json.loads(resp[1])\n",
        "      for item in json_resp['cbnParsers']:\n",
        "        if item['state'] == \"LIVE\":\n",
        "          with open(f\"custom_parsers/{item['logType']}.conf\", 'wb') as conf_file:\n",
        "            conf_file.write(base64.b64decode(item['config']))\n",
        "    print(\"Finished fetching parers.\")\n",
        "    if download_file:\n",
        "      !zip -r custom_parsers.zip custom_parsers\n",
        "      files.download(\"custom_parsers.zip\")\n",
        "  else:\n",
        "    print(\"There don't appear to be any live parsers at the moment.\")\n",
        "else:\n",
        "  # something went wrong\n",
        "  err = response[1]\n",
        "  print(err)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color=red>Work in progess</font> Parser API V2 (BYOP)\n",
        "This functionality requires two things\n",
        "\n",
        "1. A Chronicle instance with BYOP setup  \n",
        "1. A service account key from the GCP project tied to the Chronicle instance with the appropriate IAM roles granted\n",
        "  1. Of the default roles `Chronicle API Admin` is the one to choose.\n",
        "\n",
        "[Jump to top](#scrollTo=v0jKbGj8ZZRB)"
      ],
      "metadata": {
        "id": "hJclWq5wb_1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize BYOP info\n",
        "#@markdown The below information is required to work with this API. Subsequent commands will not work without this.\n",
        "PROJECT_ID = \"chronicle-byop\" #@param {type:\"string\"}\n",
        "CUSTOMER_ID = \"34871035-2752-4075-aed6-2e7f261be67d\" #@param {type:\"string\"}\n",
        "#@markdown <font color=\"red\">Don't forget to click the play button on this cell after filling out the required fields!</font>\n",
        "BASE_URI = f\"https://{cli_region.lower()}-chronicle.googleapis.com/v1alpha/projects/{PROJECT_ID}/locations/{cli_region.lower()}/instances/{CUSTOMER_ID}/\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "oudg6OIadinW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title List Parsers\n",
        "#@markdown Optional, leave as `-` to list all logtypes\n",
        "logtype = \"-\" #@param [\"-\"] {allow-input: true}\n",
        "decode_base64 = True #@param {type: \"boolean\"}\n",
        "custom_only = False #@param {type: \"boolean\"}\n",
        "#@markdown Filename required for all active parsers (not custom only). Too much data to display\n",
        "filename = \"parsers.json\" #@param {type: \"string\"}\n",
        "download_file = True #@param {type: \"boolean\"}\n",
        "URL = f\"https://{cli_region.lower()}-chronicle.googleapis.com/v1alpha/projects/{PROJECT_ID}/locations/{cli_region.lower()}/instances/{CUSTOMER_ID}/logTypes/{logtype.upper()}/parsers\"\n",
        "if custom_only:\n",
        "  URL += \"?filter=TYPE+%3D+CUSTOM\"\n",
        "resp = session.get(URL)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "  sys.exit()\n",
        "\n",
        "json_resp = resp.json()\n",
        "if decode_base64 and \"parsers\" in json_resp.keys():\n",
        "  for parser_index in range(len(json_resp[\"parsers\"])):\n",
        "    json_resp[\"parsers\"][parser_index][\"cbn\"] = base64.b64decode(json_resp[\"parsers\"][parser_index][\"cbn\"]).decode()\n",
        "\n",
        "if (not custom_only and filename) or len(resp.text) > 100000:\n",
        "  if not filename:\n",
        "    print(f\"Please specify a filename. The response is too large to print on screen.\")\n",
        "    sys.exit(1)\n",
        "  with open(filename, \"w\") as file_to_write:\n",
        "    json.dump(json_resp, file_to_write, indent=4)\n",
        "  if download_file:\n",
        "    files.download(filename)\n",
        "  print(f\"Wrote data to {filename}\")\n",
        "elif not custom_only and len(resp.text) > 100000:\n",
        "  print(f\"Filename must be specified for listing all parsers. Data is too large to display on screen. Response body is {len(resp.raw)} bytes\")\n",
        "else:\n",
        "  print(json.dumps(json_resp,indent=2))"
      ],
      "metadata": {
        "id": "c4gMTDW0daL4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title List Extensions\n",
        "#@markdown Optional, leave as `-` to list all logtypes\n",
        "logtype = \"-\" #@param [\"-\"] {allow-input: true}\n",
        "decode_base64 = True #@param {type: \"boolean\"}\n",
        "#@markdown Filename required for all parsers (not custom only). Too much data to display\n",
        "filename = \"\" #@param {type: \"string\"}\n",
        "download_file = False #@param {type: \"boolean\"}\n",
        "URL = f\"{BASE_URI}logTypes/{logtype.upper()}/parserExtensions\"\n",
        "resp = session.get(URL)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "  sys.exit()\n",
        "\n",
        "json_resp = resp.json()\n",
        "if decode_base64:\n",
        "  for parserExtension_index in range(len(json_resp[\"parserExtensions\"])):\n",
        "    if \"log\" in json_resp[\"parserExtensions\"][parserExtension_index].keys():\n",
        "      json_resp[\"parserExtensions\"][parserExtension_index][\"log\"] = base64.b64decode(json_resp[\"parserExtensions\"][parserExtension_index][\"log\"]).decode()\n",
        "    if \"fieldExtractors\" in json_resp[\"parserExtensions\"][parserExtension_index].keys() and \\\n",
        "    \"transformedCbnSnippet\" in json_resp[\"parserExtensions\"][parserExtension_index][\"fieldExtractors\"].keys():\n",
        "      json_resp[\"parserExtensions\"][parserExtension_index][\"fieldExtractors\"][\"transformedCbnSnippet\"] = base64.b64decode(json_resp[\"parserExtensions\"][parserExtension_index][\"fieldExtractors\"][\"transformedCbnSnippet\"]).decode()\n",
        "\n",
        "if filename or len(resp.text) > 100000:\n",
        "  if not filename:\n",
        "    print(f\"Please specify a filename. The response is too large to print on screen.\")\n",
        "    sys.exit(1)\n",
        "  with open(filename, \"w\") as file_to_write:\n",
        "    json.dump(json_resp, file_to_write, indent=4)\n",
        "  if download_file:\n",
        "    files.download(filename)\n",
        "  print(f\"Wrote data to {filename}\")\n",
        "else:\n",
        "  print(json.dumps(json_resp,indent=2))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Lqxor4gT6IeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfLjZLR-DTjB",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run parser\n",
        "#@markdown Enter the filename of the CBN to test\n",
        "parser_conf_file = \"VMWARE_TANZU.conf\" #@param {type: \"string\"}\n",
        "#@markdown Enter the filename of the testdata\n",
        "test_data_file = \"sample.log\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Enter a valid logtype. This does not have the be the logtype tested, just any valid logtype.\n",
        "LOG_TYPE = \"OKTA\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Choose whether to write the output data to a file and then whether to download that file.\n",
        "write_to_file = True #@param {type: \"boolean\"}\n",
        "download_file = False #@param {type: \"boolean\"}\n",
        "\n",
        "file_name = \"parser_output.blah\" #@param {type: \"string\"}\n",
        "also_write_to_screen = True #@param {type: \"boolean\"}\n",
        "\n",
        "uri = f\"{BASE_URI}logTypes/{logtype.upper()}:runParser\"\n",
        "\n",
        "conf_file = open(parser_conf_file, 'rb')\n",
        "conf_data = conf_file.read()\n",
        "conf_file.close()\n",
        "\n",
        "log_file = open(test_data_file, 'rb')\n",
        "log_data = log_file.readlines()\n",
        "log_file.close()\n",
        "\n",
        "\n",
        "\n",
        "data = {\n",
        "  \"parser\": {\n",
        "    \"cbn\": base64.urlsafe_b64encode(conf_data).decode()\n",
        "  },\n",
        "  \"log\": [base64.urlsafe_b64encode(x).decode() for x in log_data],\n",
        "  \"statedump_allowed\": True\n",
        "}\n",
        "\n",
        "resp = session.post(uri,  json=data)\n",
        "\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  if write_to_file:\n",
        "    with open(file_name, \"w\") as output_file:\n",
        "      output_file.write(resp.text)\n",
        "      if also_write_to_screen:\n",
        "        pprint(resp.json())\n",
        "    if download_file:\n",
        "      files.download(file_name)\n",
        "  else:\n",
        "    pprint(resp.json())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZsp3qFDU12C",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title (Not ready) Submit a parser\n",
        "#@markdown This endpoint enables you to submit a customer-specific parser configuration for a specific parser. The validation process requires at least 10,000 raw logs for each LogType and that event timestamps are no older than 30 days, otherwise it will fail. Make sure there are at least 10,000 raw logs for the LogType with event timestamps no older than 30 days from the time you submit the parser configuration.\n",
        "log_type = 'PAN_EDR' #@param {type: \"string\"}\n",
        "author_name = \"Eugene Dimarsky\" #@param {type: \"string\"}\n",
        "#@markdown Check the below box to upload a parser or leave unchecked to specify a filename in the `parser_filename` variable below that is already in the colab instance.\n",
        "upload_file = True #@param {type: \"boolean\"}\n",
        "parser_filename = \"ZSCALER_WEBPROXY.conf\" #@param {type:\"string\"}\n",
        "#@markdown Optional and experimental, add a changelog string to your parser\n",
        "changelog_entry = \"\" #@param {type: \"string\"}\n",
        "if upload_file:\n",
        "  print(\"Please select the parser file to upload\")\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  parser_filename = list(uploaded.keys())[0]\n",
        "\n",
        "with open(parser_filename, \"rb\") as parser_file:\n",
        "  parser = parser_file.read()\n",
        "\n",
        "skipValidationOnNoLogs = True #@param {type: \"boolean\"}\n",
        "\n",
        "uri = f\"{BASE_URI}logTypes/{logtype.upper()}/parsers\"\n",
        "\n",
        "# create the body with the parser configuration, logType identifier, and author\n",
        "request_body = {\n",
        "'cbn': base64.urlsafe_b64encode(parser).decode(\"ascii\"),\n",
        "'type' : \"CUSTOM\",\n",
        "'changelogs' : {\n",
        "    'entries' : [] if not changelog_entry else [changelog_entry]\n",
        "},\n",
        "'creator' : {\n",
        "    'author' : author_name\n",
        "},\n",
        "'validatedOnEmptyLogs' : skipValidationOnNoLogs\n",
        "}\n",
        "\n",
        "\n",
        "# encode the body and set the Content-Type\n",
        "body = urllib.parse.urlencode(request_body)\n",
        "r_headers = {}\n",
        "r_headers.update({'Content-type' : 'application/x-www-form-urlencoded'})\n",
        "\n",
        "# send the request and process the response\n",
        "resp = session.post(uri, data=body, headers=r_headers)\n",
        "json_resp = resp.json()\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp['error'])\n",
        "else:\n",
        "  pprint(json_resp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbI-zFGq6hI5"
      },
      "source": [
        "#RBAC API\n",
        "Documentation [link](https://cloud.google.com/chronicle/docs/reference/rbac-api)\n",
        "\n",
        "[Jump to top](#scrollTo=v0jKbGj8ZZRB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vR1kUXRH6j_6"
      },
      "outputs": [],
      "source": [
        "#@title List Roles\n",
        "#@markdown Retrieves all roles.\n",
        "ENDPOINT_BASE = 'https://{}backstory.googleapis.com/v1'.format(region_prefix)\n",
        "LIST_ROLES_URL = '{}/roles'.format(ENDPOINT_BASE)\n",
        "# send the request and process the response\n",
        "resp = session.get(LIST_ROLES_URL)\n",
        "json_resp = resp.json()\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dlE0Q9mnDM8s"
      },
      "outputs": [],
      "source": [
        "#@title Update Role\n",
        "#@markdown Updates a role to specify whether it is the default role.\n",
        "\n",
        "name = \"Administrator\" #@param {type: \"string\"}\n",
        "isDefault = True #@param {type: \"boolean\"}\n",
        "\n",
        "ENDPOINT_BASE = 'https://{}backstory.googleapis.com/v1'.format(region_prefix)\n",
        "UPDATE_ROLE_URL = '{}/roles/{}'.format(ENDPOINT_BASE, name)\n",
        "\n",
        "req_body = {\n",
        "        \"isDefault\": isDefault\n",
        "}\n",
        "\n",
        "# send the request and process the response\n",
        "resp = session.patch(UPDATE_ROLE_URL, json=req_body)\n",
        "json_resp = resp.json()\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hRFPUjF2mAlW"
      },
      "outputs": [],
      "source": [
        "#@title Create Subject\n",
        "#@markdown Creates a subject and assigns the given role.\n",
        "\n",
        "#@markdown The name of the IdP group to grant the below role(s)\n",
        "name = \"i_like_cheese\" #@param {type: \"string\"}\n",
        "subject_type = \"SUBJECT_TYPE_IDP_GROUP\" #@param [\"SUBJECT_TYPE_ANALYST\", \"SUBJECT_TYPE_IDP_GROUP\"]\n",
        "#@markdown Please enter a comma separated list of desired roles\n",
        "roles = \"ViewerWithNoDetectAccess, Viewer\" #@param {type: \"string\"}\n",
        "\n",
        "uri = f'https://{region_prefix}backstory.googleapis.com/v1/subjects'\n",
        "\n",
        "req_body = {\n",
        "  \"name\": name,\n",
        "  \"type\": subject_type,\n",
        "  \"roles\": [{\"name\": role.strip()} for role in roles.split(\",\")]\n",
        "}\n",
        "\n",
        "# send the request and process the response\n",
        "resp = http_client.request(uri, \"POST\", body=json.dumps(req_body))\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fvFFhTOOsW_a"
      },
      "outputs": [],
      "source": [
        "#@title Get Subject\n",
        "#@markdown Retrieves a subject.\n",
        "\n",
        "subject_id = \"i_like_cheese\" #@param {type: \"string\"}\n",
        "\n",
        "uri = f\"https://{region_prefix}backstory.googleapis.com/v1/subjects/{subject_id}\"\n",
        "# send the request and process the response\n",
        "resp = http_client.request(uri, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0ySrX_UeBmB9"
      },
      "outputs": [],
      "source": [
        "#@title List Subjects\n",
        "#@markdown Retrieves all subjects.\n",
        "\n",
        "#@markdown Specify the maximum number of subjects to return (range is 1 through 1,000). The default is 100.\n",
        "page_size = 101 #@param {type:\"slider\", min:1, max:1000, step:1}\n",
        "#@markdown Page token received from a previous call. Use to retrieve the next page.\n",
        "page_token = \"\" #@param {type: \"string\"}\n",
        "url_params = {'page_size': page_size}\n",
        "if page_token:\n",
        "  url_params[\"page_token\"] = page_token\n",
        "encoded_url_params = urlencode(url_params)\n",
        "\n",
        "ENDPOINT_BASE = f'https://{region_prefix}backstory.googleapis.com/v1'\n",
        "LIST_SUBJECTS_URL = f'{ENDPOINT_BASE}/subjects?{encoded_url_params}'\n",
        "# send the request and process the response\n",
        "resp = http_client.request(LIST_SUBJECTS_URL, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pPgKniG9p4b3"
      },
      "outputs": [],
      "source": [
        "#@title Update Subject\n",
        "#@markdown Updates the role of the specified subject.\n",
        "\n",
        "subject_id = \"i_like_cheese\" #@param {type: \"string\"}\n",
        "name = \"\" #@param {type: \"string\"}\n",
        "subject_type = \"SUBJECT_TYPE_IDP_GROUP\" #@param [\"SUBJECT_TYPE_ANALYST\", \"SUBJECT_TYPE_IDP_GROUP\"]\n",
        "#@markdown Please enter a comma separated list of desired roles\n",
        "roles = \"Administrator\" #@param {type: \"string\"}\n",
        "\n",
        "req_payload = {\n",
        "  \"subject\": {\n",
        "    \"name\": name,\n",
        "    \"type\": subject_type,\n",
        "    \"roles\": []\n",
        "  }\n",
        "}\n",
        "\n",
        "roles = roles.split(\",\")\n",
        "for role in roles:\n",
        "  req_payload['subject']['roles'].append({\"name\": role.strip()})\n",
        "\n",
        "uri = f\"https://{region_prefix}backstory.googleapis.com/v1/subjects/{subject_id}\"\n",
        "# send the request and process the response\n",
        "resp = http_client.request(uri, \"PATCH\", body=json.dumps(req_body))\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Up6T7VXFvjLc"
      },
      "outputs": [],
      "source": [
        "#@title Delete Subject\n",
        "#@markdown Deletes a subject.\n",
        "\n",
        "subject_id = \"i_like_cheese\" #@param {type: \"string\"}\n",
        "\n",
        "uri = f\"https://{region_prefix}backstory.googleapis.com/v1/subjects/{subject_id}\"\n",
        "# send the request and process the response\n",
        "resp = http_client.request(uri, \"DELETE\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ug4UflixBld"
      },
      "source": [
        "#Ingestion API\n",
        "Documentation [link](https://cloud.google.com/chronicle/docs/reference/ingestion-api)\n",
        "\n",
        "[Jump to top](#scrollTo=v0jKbGj8ZZRB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YYNUCuTKUQNy"
      },
      "outputs": [],
      "source": [
        "#@title udmevents\n",
        "#@markdown Use this method to forward UDM events to Chronicle in batches.\n",
        "\n",
        "customer_id = \"bd54dc26-3d54-44fb-88dc-8fd323df46f0\" #@param {type: \"string\"}\n",
        "#@markdown Choose whether to upload a file of UDM data or to specify a file already in the colab filesystem.\n",
        "upload_log_file = True #@param {type: \"boolean\"}\n",
        "log_file = \"udm.json\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown **The logfile should be a JSON style array of UDM events.**\n",
        "\n",
        "if upload_log_file:\n",
        "  print(\"Please select the file with UDM data (in JSON format)\")\n",
        "  uploaded = files.upload()\n",
        "  log_file = list(uploaded.keys())[0]\n",
        "with open(log_file, \"r\") as log_data:\n",
        "  log_entries = json.loads(log_data.read())\n",
        "\n",
        "# delete logfile after upload to prevent naming issues as covered in the notes at the bottom\n",
        "if upload_log_file:\n",
        "  os.system(f\"rm {log_file}\")\n",
        "\n",
        "\n",
        "payload = {\n",
        "    \"customer_id\" : customer_id,\n",
        "    \"events\" : log_entries\n",
        "}\n",
        "\n",
        "uri = f\"https://{region_prefix}malachiteingestion-pa.googleapis.com/v2/udmevents:batchCreate\"\n",
        "\n",
        "resp = http_client.request(uri, \"POST\", body=json.dumps(payload))\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  print(f\"Logs uploaded succesfully. Returned body is:\\n{pprint(json_resp)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKRRolUGxD5Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "outputId": "9a627c93-6d5f-43b6-fefe-02d3c7f85989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please select the file with UDM data (in JSON format)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c8b3ddba-fd4a-4d30-a6a2-101fa2b6271a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c8b3ddba-fd4a-4d30-a6a2-101fa2b6271a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving FinalCSIOC2.json to FinalCSIOC2.json\n",
            "Logs uploaded succesfully. Total logs sent: 1\n"
          ]
        }
      ],
      "source": [
        "#@title Unstructured Log Entries\n",
        "#@markdown Use this method to forward unstructured log entries to Chronicle one batch at a time.\n",
        "\n",
        "#@markdown Each batch of log data has a maximum size limit of 1 MB. Do not send multiple types of timestamps (use either ts_epoch_microseconds or ts_rfc3339 but not both). If you do not provide a separate timestamp, be sure to include one within the log_text field.\n",
        "\n",
        "#@markdown  **Note:** The 1 MB maximum size limit refers to an uncompressed payload. In case you send a compressed payload, the batch size should be limited to 1 MB after decompression.\n",
        "\n",
        "#@markdown <font color=red>**NO BATCHING IS DONE FOR THIS EXAMPLE CELL**</font>\n",
        "\n",
        "#@markdown Please only specify a file that will keep the batch under 1MB. One log entry per line is assumed.\n",
        "\n",
        "from time import sleep\n",
        "customer_id = \"d6cfdfe2-4a3c-4f73-8e92-d43c6ce1e554\" #@param {type: \"string\"}\n",
        "log_type = \"CROWDSTRIKE_IOC\" #@param {type: \"string\"}\n",
        "namespace = \"\" #@param {type: \"string\"}\n",
        "upload_log_file = True #@param {type: \"boolean\"}\n",
        "log_file = \"data.log\" #@param {type: \"string\"}\n",
        "#@markdown Optional:\n",
        "add_current_time_as_log_timestamp = False #@param {type:\"boolean\"}\n",
        "#@markdown Labels (also optional). Please enter as a comma seperated list of key=value pairs\n",
        "\n",
        "#@markdown Example: **key1=value1, key2=value2, key3=value3, etc...**\n",
        "labels = \"\" #@param {type: \"string\"}\n",
        "\n",
        "if upload_log_file:\n",
        "  print(\"Please select the file with UDM data (in JSON format)\")\n",
        "  uploaded = files.upload()\n",
        "  log_file = list(uploaded.keys())[0]\n",
        "with open(log_file, \"r\") as log_data:\n",
        "  log_entries = []\n",
        "  # lines_read = 0\n",
        "  # log_data.seek(offset)\n",
        "  # print(\"Position: {}\\nOffset: {}\\n{}\".format(positon,offset, log_data.readline()))\n",
        "  log_entries = [x.strip() for x in log_data.readlines()]\n",
        "\n",
        "# delete logfile after upload to prevent naming issues as covered in the notes at the bottom\n",
        "if upload_log_file:\n",
        "  os.system(f\"rm {log_file}\")\n",
        "\n",
        "payload = {\n",
        "    \"customer_id\" : customer_id,\n",
        "    \"log_type\" : log_type,\n",
        "    \"entries\" : [],\n",
        "    # \"labels\" : [\n",
        "    #     {\n",
        "    #         \"key\": \"ingestion_test_label\",\n",
        "    #         \"value\": \"successfully_applied\"\n",
        "    #     },\n",
        "    #     {\n",
        "    #         \"key\": \"ingestion_test_label\",\n",
        "    #         \"value\": \"also_applied\"\n",
        "    #     }\n",
        "    # ]\n",
        "}\n",
        "\n",
        "if labels:\n",
        "  #create a labels key\n",
        "  if \"labels\" not in payload.keys():\n",
        "    payload[\"labels\"] = []\n",
        "\n",
        "  labels = labels.split(\",\")\n",
        "  for label in labels:\n",
        "    key, value = label.split(\"=\")\n",
        "    payload[\"labels\"].append({\"key\" : key.strip(), \"value\" : value.strip()})\n",
        "\n",
        "if namespace:\n",
        "  payload['namespace'] = namespace\n",
        "\n",
        "for log_entry in log_entries:\n",
        "  proto_log = {\"log_text\" : log_entry}\n",
        "  if add_current_time_as_log_timestamp:\n",
        "    now = datetime.now(timezone.utc)\n",
        "    proto_log[\"ts_rfc3339\"] = now.isoformat()\n",
        "  payload[\"entries\"].append(proto_log)\n",
        "\n",
        "payload = json.dumps(payload)\n",
        "\n",
        "ENDPOINT_BASE = 'https://{}malachiteingestion-pa.googleapis.com/v2'.format(region_prefix)\n",
        "LIST_CBN_PARSER_STATUS_URL = '{}/unstructuredlogentries:batchCreate'.format(ENDPOINT_BASE)\n",
        "# send the request and process the response\n",
        "resp = http_client.request(LIST_CBN_PARSER_STATUS_URL, \"POST\", body=payload)\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  print(\"Logs uploaded successfully. Total logs sent: {}\".format(len(log_entries)))\n",
        "  # pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FRrWklBoeYU",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title createentities\n",
        "#@markdown Creates entities. You are limited to 1MB of data per request.\n",
        "\n",
        "customer_id = \"9cd07b80-f66e-42c3-acd2-0ac803b63337\" #@param {type: \"string\"}\n",
        "#@markdown Choose whether to upload a file of UDM data or to specify a file already in the colab filesystem.\n",
        "upload_log_file = False #@param {type: \"boolean\"}\n",
        "log_file = \"udm.json\" #@param {type: \"string\"}\n",
        "log_type = \"QUALYS_ASSET_CONTEXT\" #@param {type : \"string\"}\n",
        "\n",
        "#@markdown **The logfile should be a JSON style array of UDM entities.**\n",
        "\n",
        "if upload_log_file:\n",
        "  print(\"Please select the file with UDM data (in JSON format)\")\n",
        "  uploaded = files.upload()\n",
        "  log_file = list(uploaded.keys())[0]\n",
        "with open(log_file, \"r\") as log_data:\n",
        "  log_entries = json.loads(log_data.read())\n",
        "\n",
        "# delete logfile after upload to prevent naming issues as covered in the notes at the bottom\n",
        "if upload_log_file:\n",
        "  os.system(f\"rm {log_file}\")\n",
        "\n",
        "\n",
        "payload = {\n",
        "    \"customer_id\" : customer_id,\n",
        "    \"log_type\": log_type,\n",
        "    \"entities\" : log_entries\n",
        "}\n",
        "\n",
        "uri = f\"https://{region_prefix}malachiteingestion-pa.googleapis.com/v2/entities:batchCreate\"\n",
        "\n",
        "resp = session.post(uri, json=payload)\n",
        "if resp.status_code > 299:\n",
        "  pprint(resp.json().get('error').get('message'))\n",
        "else:\n",
        "  print(f\"Logs uploaded succesfully. Returned body is:\\n{pprint(resp.json())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VjqGaR7xt990"
      },
      "outputs": [],
      "source": [
        "#@title Get Supported log types\n",
        "#@markdown Use this method to retrieve a list of supported log types.\n",
        "download_output = False #@param {\"type\": \"boolean\"}\n",
        "file_name = \"supported_log_types.json\" #@param {\"type\":\"string\"}\n",
        "ENDPOINT_BASE = 'https://{}malachiteingestion-pa.googleapis.com/v2'.format(region_prefix)\n",
        "LIST_CBN_PARSER_STATUS_URL = '{}/logtypes'.format(ENDPOINT_BASE)\n",
        "# send the request and process the response\n",
        "resp = http_client.request(LIST_CBN_PARSER_STATUS_URL, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  if download_output:\n",
        "    with open(file_name, \"w\") as output_file:\n",
        "      json.dump(json_resp, output_file, indent=2)\n",
        "    files.download(file_name)\n",
        "    file_size = os.path.getsize(file_name)\n",
        "    print(f\"Output written to {file_name}. File is {file_size}B\")\n",
        "  else:\n",
        "    pprint(json_resp)\n",
        "\n",
        "# valid_log_types = []\n",
        "# for log_type in json_resp['logTypes']:\n",
        "#   valid_log_types.append(log_type[\"logType\"])\n",
        "# with open(\"valid_logs.txt\", \"w\") as output_file:\n",
        "#   output_file.write(str(valid_log_types))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3wpTMoXG3Fh"
      },
      "source": [
        "#Feed Schema API\n",
        "Documentation [link](https://cloud.google.com/chronicle/docs/reference/feed-management-api#feed_schema_api_reference)\n",
        "\n",
        "[Jump to top](#scrollTo=v0jKbGj8ZZRB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kOwmSEcHxHV-"
      },
      "outputs": [],
      "source": [
        "#@title GetFeedSchema\n",
        "#@markdown This method returns a structure representing the entire feed schema.\n",
        "\n",
        "download_output = True #@param {\"type\": \"boolean\"}\n",
        "file_name = \"feedSchema.json\" #@param {\"type\":\"string\"}\n",
        "\n",
        "URL = 'https://{}backstory.googleapis.com/v1/feedSchema'.format(region_prefix)\n",
        "# send the request and process the response\n",
        "resp = session.get(URL)\n",
        "json_resp = resp.json()\n",
        "# show the parser history\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp['error'])\n",
        "else:\n",
        "  if download_output:\n",
        "    with open(file_name, \"w\") as output_file:\n",
        "      json.dump(json_resp, output_file, indent=4)\n",
        "    files.download(file_name)\n",
        "    file_size = os.path.getsize(file_name)\n",
        "    print(f\"Output written to {file_name}. File is {file_size}B\")\n",
        "  else:\n",
        "    pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zsU-Vujqz_FE"
      },
      "outputs": [],
      "source": [
        "#@title ListFeedSourceTypeSchemas\n",
        "#@markdown This method returns information about all feed source types.\n",
        "\n",
        "download_output = False #@param {\"type\": \"boolean\"}\n",
        "file_name = \"feedSourceTypes.json\" #@param {\"type\":\"string\"}\n",
        "\n",
        "URL = 'https://{}backstory.googleapis.com/v1/feedSourceTypeSchemas'.format(region_prefix)\n",
        "# send the request and process the response\n",
        "resp = session.get(URL)\n",
        "json_resp = resp.json()\n",
        "# show the parser history\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp['error'])\n",
        "else:\n",
        "  if download_output:\n",
        "    with open(file_name, \"w\") as output_file:\n",
        "      json.dump(json_resp, output_file, indent=4)\n",
        "    files.download(file_name)\n",
        "    file_size = os.path.getsize(file_name)\n",
        "    print(f\"Output written to {file_name}. File is {file_size}B\")\n",
        "  else:\n",
        "    pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6JOcw3Wf0bTU"
      },
      "outputs": [],
      "source": [
        "#@title ListLogTypeSchemas\n",
        "#@markdown This method returns information about all log types compatible with a particular feed source type.\n",
        "\n",
        "feed_source_type = \"API\" #@param {type:\"string\"}\n",
        "download_output = True #@param {\"type\": \"boolean\"}\n",
        "file_name = \"logTypeSchemasHTTP.json\" #@param {\"type\":\"string\"}\n",
        "\n",
        "URL = f'https://{region_prefix}backstory.googleapis.com/v1/feedSourceTypeSchemas/{feed_source_type}/logTypeSchemas'\n",
        "# send the request and process the response\n",
        "resp = session.get(URL)\n",
        "json_resp = resp.json()\n",
        "# show the parser history\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp['error'])\n",
        "else:\n",
        "  if download_output:\n",
        "    with open(file_name, \"w\") as output_file:\n",
        "      json.dump(json_resp, output_file, indent=4)\n",
        "    files.download(file_name)\n",
        "    file_size = os.path.getsize(file_name)\n",
        "    print(f\"Output written to {file_name}. File is {file_size}B\")\n",
        "  else:\n",
        "    pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "p6pLo52q1oay"
      },
      "outputs": [],
      "source": [
        "#@title GetLogTypeSchema\n",
        "#@markdown This method returns detailed information about all the fields necessary to configure a feed for a particular source type and log type.\n",
        "\n",
        "feed_source_type = \"SFTP\" #@param {type:\"string\"}\n",
        "log_type = \"ONEPASSWORD\" #@param {type: \"string\"}\n",
        "download_output = False #@param {\"type\": \"boolean\"}\n",
        "file_name = \"logTypeSchema.json\" #@param {\"type\":\"string\"}\n",
        "\n",
        "URL = f'https://{region_prefix}backstory.googleapis.com/v1/feedSourceTypeSchemas/{feed_source_type}/logTypeSchemas/{log_type}'\n",
        "# send the request and process the response\n",
        "resp = session.get(URL)\n",
        "json_resp = resp.json()\n",
        "# show the parser history\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp['error'])\n",
        "else:\n",
        "  if download_output:\n",
        "    with open(file_name, \"w\") as output_file:\n",
        "      json.dump(json_resp, output_file, indent=4)\n",
        "    files.download(file_name)\n",
        "    file_size = os.path.getsize(file_name)\n",
        "    print(f\"Output written to {file_name}. File is {file_size}B\")\n",
        "  else:\n",
        "    pprint(json_resp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feed Management API\n",
        "Documentation [link](https://cloud.google.com/chronicle/docs/reference/feed-management-api#feed_management_api_reference)\n",
        "\n",
        "[Jump to top](#scrollTo=v0jKbGj8ZZRB)"
      ],
      "metadata": {
        "id": "B1oCjyR52XG1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r8IwH1Jn4_MO"
      },
      "outputs": [],
      "source": [
        "#@title Enable Feed\n",
        "#@markdown Enables an `INACTIVE` feed, which allows it to be executed.\n",
        "feed_id = \"ab26c31e-b1dd-42b7-a40c-a244b6eccaa6\" #@param {type: \"string\"}\n",
        "\n",
        "download_output = False #@param {type: \"boolean\"}\n",
        "file_name = \"configured_feeds.json\" #@param {type: \"string\"}\n",
        "\n",
        "URL = f'https://{region_prefix}backstory.googleapis.com/v1/feeds/{feed_id}:enable'\n",
        "# send the request and process the response\n",
        "resp = session.post(URL)\n",
        "json_resp = resp.json()\n",
        "# show the parser history\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp['error'])\n",
        "else:\n",
        "  if download_output:\n",
        "    with open(file_name, \"w\") as output_file:\n",
        "      json.dump(json_resp, output_file, indent=4)\n",
        "    files.download(file_name)\n",
        "    file_size = os.path.getsize(file_name)\n",
        "    print(f\"Output written to {file_name}. File is {file_size}B\")\n",
        "  else:\n",
        "    pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ks8mMovp5T7r"
      },
      "outputs": [],
      "source": [
        "#@title Disable Feed\n",
        "#@markdown Disables a feed. A disabled feed has a status of `INACTIVE`. Disabled feeds will no longer fetch data.\n",
        "feed_id = \"ab26c31e-b1dd-42b7-a40c-a244b6eccaa6\" #@param {type: \"string\"}\n",
        "\n",
        "download_output = False #@param {type: \"boolean\"}\n",
        "file_name = \"configured_feeds.json\" #@param {type: \"string\"}\n",
        "\n",
        "URL = f'https://{region_prefix}backstory.googleapis.com/v1/feeds/{feed_id}:disable'\n",
        "# send the request and process the response\n",
        "resp = session.post(URL)\n",
        "json_resp = resp.json()\n",
        "# show the parser history\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp['error'])\n",
        "else:\n",
        "  if download_output:\n",
        "    with open(file_name, \"w\") as output_file:\n",
        "      json.dump(json_resp, output_file, indent=4)\n",
        "    files.download(file_name)\n",
        "    file_size = os.path.getsize(file_name)\n",
        "    print(f\"Output written to {file_name}. File is {file_size}B\")\n",
        "  else:\n",
        "    pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vbRqltjyrsKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc968917-9b9b-49b1-8360-b09902af7b29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'details': {'feedSourceType': 'API',\n",
            "             'logType': 'OKTA',\n",
            "             'oktaSettings': {'hostname': 'dev-32032166.okta.com'}},\n",
            " 'feedState': 'COMPLETED',\n",
            " 'lastFeedInitiationTime': '2025-04-24T15:17:40.114894002Z',\n",
            " 'name': 'feeds/730245ae-c114-4753-9989-34ba9788a60f'}\n"
          ]
        }
      ],
      "source": [
        "#@title GetFeed\n",
        "#@markdown Gets the details of the feed that was configured.\n",
        "feed_id = \"730245ae-c114-4753-9989-34ba9788a60f\" #@param {type: \"string\"}\n",
        "\n",
        "download_output = False #@param {type: \"boolean\"}\n",
        "file_name = \"configured_feeds.json\" #@param {type: \"string\"}\n",
        "\n",
        "URL = f'https://{region_prefix}backstory.googleapis.com/v1/feeds/{feed_id}'\n",
        "# send the request and process the response\n",
        "resp = session.get(URL)\n",
        "json_resp = resp.json()\n",
        "# show the parser history\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp['error'])\n",
        "else:\n",
        "  if download_output:\n",
        "    with open(file_name, \"w\") as output_file:\n",
        "      json.dump(json_resp, output_file, indent=4)\n",
        "    files.download(file_name)\n",
        "    file_size = os.path.getsize(file_name)\n",
        "    print(f\"Output written to {file_name}. File is {file_size}B\")\n",
        "  else:\n",
        "    pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nESXi3wbG5_d"
      },
      "outputs": [],
      "source": [
        "#@title ListFeeds\n",
        "#@markdown Retrieves all the feeds configured for a given Chronicle instance.\n",
        "\n",
        "download_output = False #@param {type: \"boolean\"}\n",
        "file_name = \"configured_feeds.json\" #@param {type: \"string\"}\n",
        "URL = f'https://{region_prefix}backstory.googleapis.com/v1/feeds'\n",
        "# send the request and process the response\n",
        "resp = session.get(URL)\n",
        "json_resp = resp.json()\n",
        "# show the parser history\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp['error'])\n",
        "else:\n",
        "  if download_output:\n",
        "    with open(file_name, \"w\") as output_file:\n",
        "      json.dump(json_resp, output_file, indent=4)\n",
        "    files.download(file_name)\n",
        "    file_size = os.path.getsize(file_name)\n",
        "    print(f\"Output written to {file_name}. File is {file_size}B\")\n",
        "  else:\n",
        "    pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ujA_vlXQsors"
      },
      "outputs": [],
      "source": [
        "#@title Delete a specific feed\n",
        "#@markdown Deletes a feed that was configured using the Chronicle Feed Management API.\n",
        "feed_id = \"f625fd1e-ff0f-4065-9f1e-7bb70f8e5e60\" #@param {type: \"string\"}\n",
        "ENDPOINT_BASE = 'https://{}backstory.googleapis.com/v1'.format(region_prefix)\n",
        "LIST_FEEDS_URL = '{}/feeds/{}'.format(ENDPOINT_BASE,feed_id)\n",
        "# send the request and process the response\n",
        "resp = http_client.request(LIST_FEEDS_URL, \"DELETE\")\n",
        "json_resp = json.loads(resp[1])\n",
        "# show the parser history\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp['error'])\n",
        "else:\n",
        "  print(\"Feed id {} has been succesfully deleted.\".format(feed_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tWuEIJjAoU_n"
      },
      "outputs": [],
      "source": [
        "#@title Fetch service account\n",
        "#@markdown Gets a unique service account that Chronicle uses to ingest data. Use this method only if you're setting up a [Cloud Storage feed](https://cloud.google.com/chronicle/docs/reference/feed-management-api#gc-storage).\n",
        "\n",
        "URL = f'https://{region_prefix}backstory.googleapis.com/v1/fetchFeedServiceAccount'\n",
        "# send the request and process the response\n",
        "resp = session.get(URL)\n",
        "json_resp = resp.json()\n",
        "# show the parser history\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp['error'])\n",
        "else:\n",
        "  pprint(json_resp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muQqm1nmtAI0"
      },
      "source": [
        "###Create and Update feed endpoints\n",
        "These are not currently being added because the payload body varies for each type of feed type. Putting all of them in a notebook is unrealistic and probably unnecessary.\n",
        "\n",
        "If you would like to try this functionality please use the [CLI tool](#scrollTo=Wx1pfTxOjv57). It will walk you through feed creation step by step.\n",
        "\n",
        "All details can be found at the official [Feed Management API docs](https://cloud.google.com/chronicle/docs/preview/feed-management-api/feed-management-api)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WxlVTLNhVMBM"
      },
      "outputs": [],
      "source": [
        "#@title CreateFeed\n",
        "#@markdown Gets the details of the feed that was configured.\n",
        "body = \"{   \\\"display_name\\\": \\\"OCSF Webhook\\\",   \\\"details\\\": {     \\\"feedSourceType\\\": \\\"HTTPS_PUSH_WEBHOOK\\\",     \\\"logType\\\": \\\"OCSF\\\"   } }\" #@param {type: \"string\"}\n",
        "body = json.loads(body)\n",
        "uri = f'https://{region_prefix}backstory.googleapis.com/v1/feeds'\n",
        "# send the request and process the response\n",
        "resp = session.post(uri, json = body)\n",
        "json_resp = resp.json()\n",
        "# show the parser history\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp['error'])\n",
        "else:\n",
        "  pprint(json_resp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzEhT4Gsy7jN"
      },
      "source": [
        "#Google Cloud Threat Intelligence API\n",
        "\n",
        "[Jump to top](#scrollTo=v0jKbGj8ZZRB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sZCDVi3BzRI6"
      },
      "outputs": [],
      "source": [
        "#@title List Alerts\n",
        "\n",
        "page_token = \"\" #@param {type: \"string\"}\n",
        "page_size =   1#@param {type: \"integer\"}\n",
        "\n",
        "ENDPOINT_BASE = 'https://{}backstory.googleapis.com/v1'.format(region_prefix)\n",
        "LIST_URL = '{}/uppercaseAlerts?page_size={}&page_token={}'.format(ENDPOINT_BASE, page_size, page_token)\n",
        "# send the request and process the response\n",
        "resp = http_client.request(LIST_URL, \"GET\" )\n",
        "json_resp = json.loads(resp[1])\n",
        "# show the parser history\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp['error'])\n",
        "else:\n",
        "  pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kHL4XwzpzK2z"
      },
      "outputs": [],
      "source": [
        "#@title Get Alert\n",
        "\n",
        "alert_id = \"\" #@param {type: \"string\"}\n",
        "\n",
        "ENDPOINT_BASE = 'https://{}backstory.googleapis.com/v1'.format(region_prefix)\n",
        "LIST_URL = '{}/uppercaseAlerts/{}'.format(ENDPOINT_BASE, alert_id)\n",
        "# send the request and process the response\n",
        "resp = http_client.request(LIST_URL, \"GET\" )\n",
        "json_resp = json.loads(resp[1])\n",
        "# show the parser history\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp['error'])\n",
        "else:\n",
        "  pprint(json_resp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACbfcv9MdcYk"
      },
      "source": [
        "#CBN Tool\n",
        "<font color='red' size=+4>Please Note, DEPRECATED</font>:  \n",
        " The cbn-tool CLI was deprecated on 29 December, 2023. Developers are requested to use the new [Chronicle CLI](https://github.com/chronicle/cli).\n",
        "\n",
        "[Jump to top](#scrollTo=v0jKbGj8ZZRB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1RvCgNxo6Z5i"
      },
      "outputs": [],
      "source": [
        "#@title List all Parsers\n",
        "command_to_run = f\"python /content/cbn-tool/cbn_cli.py --region={cbn_region} --credentials_file=/content/{key_filename} list\"\n",
        "\n",
        "result = os.popen(command_to_run)\n",
        "result = result.read()\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fnkaG6-XOb7a"
      },
      "outputs": [],
      "source": [
        "#@title Validate a CBN\n",
        "conf_file = \"ede98ebd-2422-4194-acdd-6fac803a7695.conf\" #@param {type: \"string\"}\n",
        "log_file = \"fidelis.log\" #@param {type: \"string\"}\n",
        "output_file = \"validation.txt\"  #@param {type: \"string\"}\n",
        "save_output = True #@param {type: \"boolean\"}\n",
        "print_output = False #@param {type: \"boolean\"}\n",
        "command_to_run = f\"python /content/cbn-tool/cbn_cli.py --region={cbn_region} --credentials_file=/content/{key_filename} run --conf_file={conf_file} --log_file={log_file}\"\n",
        "\n",
        "result = os.popen(command_to_run)\n",
        "result = result.read()\n",
        "\n",
        "if print_output:\n",
        "  print(result)\n",
        "if save_output:\n",
        "  if output_file in os.listdir():\n",
        "    os.remove(output_file)\n",
        "  with open(output_file, \"w\") as file_to_write:\n",
        "    file_to_write.write(result)\n",
        "print(\"Validation complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-RWtmzQqQMPg"
      },
      "outputs": [],
      "source": [
        "#@title Get Sample Logs\n",
        "log_type = \"DNS_SINKHOLE\" #@param {type: \"string\"}\n",
        "start_date = \"2023-01-30\" #@param {type: \"date\"}\n",
        "end_date = \"2023-02-01\" #@param {type: \"date\"}\n",
        "command_to_run = f\"python /content/cbn-tool/cbn_cli.py --region={cbn_region} --credentials_file=/content/{key_filename} gen --log_type={log_type} --start_date={start_date}T00:00:00Z --end_date={end_date}T23:59:59Z\"\n",
        "\n",
        "result = os.popen(command_to_run)\n",
        "result = result.read()\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SV7DzwCS90Qe"
      },
      "outputs": [],
      "source": [
        "#@title List errors of a log type between specific days\n",
        "start_date = \"2022-05-23\" #@param {type:\"date\"}\n",
        "end_date = \"2022-06-02\" #@param {type:\"date\"}\n",
        "log_type = \"OKTA\" #@param {type:\"string\"}\n",
        "output_file = \"something.txt\" #@param {type:\"string\"}\n",
        "write_to_file = False #@param {type: \"boolean\"}\n",
        "print_output = True #@param {type: \"boolean\"}\n",
        "\n",
        "command_to_run = f\"python /content/cbn-tool/cbn_cli.py --region={cbn_region} --credentials_file=/content/{key_filename}  error --start_date={start_date}T00:00:00Z --end_date={end_date}T23:59:59Z --log_type={log_type}\"\n",
        "\n",
        "result = os.popen(command_to_run)\n",
        "result = result.read()\n",
        "if print_output:\n",
        "  print(\"Result:\")\n",
        "  print(result)\n",
        "\n",
        "if write_to_file:\n",
        "  with open(output_file, \"w\") as file:\n",
        "    file.write(result)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qZANcLwKdesd"
      },
      "outputs": [],
      "source": [
        "#@title Upload Custom CBN\n",
        "\n",
        "#@markdown Select whether to upload the CBN conf file or specify a local filename. If uploading the cbn_filename variable doesn't matter\n",
        "upload_conf_file = True #@param {type:\"boolean\"}\n",
        "cbn_filename = \"blah.blah\" #@param {type: \"string\"}\n",
        "if upload_conf_file:\n",
        "  uploaded = files.upload()\n",
        "  cbn_filename = list(uploaded.keys())[0]\n",
        "#@markdown Enter the author to be displayed\n",
        "author = \"google.com\" #@param {type: \"string\"}\n",
        "#@markdown Enter the logtype this CBN will parse\n",
        "log_type = \"ARCSIGHT_CEF\" #@param {type: \"string\"}\n",
        "status_check_interval = 15\n",
        "\n",
        "command_to_run = f'python /content/cbn-tool/cbn_cli.py --region={cbn_region} --credentials_file=/content/{key_filename} submit --conf_file={cbn_filename} --log_type={log_type} --author={author}'\n",
        "print(\"running command: {}\".format(command_to_run))\n",
        "result = os.popen(command_to_run)\n",
        "result = result.read()\n",
        "print(\"Result:\")\n",
        "print(result)\n",
        "\n",
        "config_id_regex_result = re.search(r\"status --config_id=([\\-\\w]+)\", result)\n",
        "if config_id_regex_result:\n",
        "  config_id = config_id_regex_result.groups()[0]\n",
        "  command_to_run = f\"python /content/cbn-tool/cbn_cli.py --region={cbn_region} --credentials_file=/content/{key_filename} status --config_id={config_id}\"\n",
        "  status_check_result = os.popen(command_to_run)\n",
        "  status_check_result = status_check_result.read()\n",
        "  status_check_result_json_regex_capture = re.search(r\"({.*})\",status_check_result, re.DOTALL)\n",
        "  if status_check_result_json_regex_capture:\n",
        "    status_check_json = json.loads(status_check_result_json_regex_capture.groups()[0])\n",
        "    while status_check_json[\"state\"] == \"NEW\" or status_check_json[\"state\"] == \"VALIDATING\":\n",
        "      print(\"Parser validation in progress. Current state is: {}\\nWaiting {} seconds and trying again\".format(status_check_json[\"state\"], status_check_interval))\n",
        "      # pprint(status_check_json)\n",
        "      sleep(status_check_interval)\n",
        "      status_check_result = os.popen(command_to_run)\n",
        "      status_check_result = status_check_result.read()\n",
        "      status_check_result_json_regex_capture = re.search(r\"({.*})\",status_check_result, re.DOTALL)\n",
        "      status_check_json = json.loads(status_check_result_json_regex_capture.groups()[0])\n",
        "    pprint(status_check_json)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca5dXllqgGwQ"
      },
      "source": [
        "#Customer Management API\n",
        "[Documentation](https://cloud.google.com/chronicle/docs/preview/customer-management-api/customer-management-api)\n",
        "\n",
        "[Jump to top](#scrollTo=v0jKbGj8ZZRB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSpZv5UWO77f",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6565943-8e54-4c81-8f79-94d32dcb87f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to create customer. This may take several minutes and there will be no output during this time.\n",
            "{'customer_code': 'dmrsknogcp',\n",
            " 'customer_name': 'nogcp',\n",
            " 'customer_subdomains': 'dmrsknogcp',\n",
            " 'retention_duration': 'ONE_YEAR'}\n",
            "'generic::unknown: customer creation failed: INVALID_ARGUMENT'\n"
          ]
        }
      ],
      "source": [
        "#@title Create Customer\n",
        "#@markdown Creates a customer and associates this customer with the partner. This API fully provisions a customer in Chronicle. The response includes the customer ID.\n",
        "customer_name = \"nogcp\" #@param {type: \"string\"}\n",
        "customer_code =  \"dmrsknogcp\" #@param {type: \"string\"}\n",
        "customer_subdomains = \"dmrsknogcp\"  #@param {type: \"string\"}\n",
        "#@markdown If specifying the provider_id it should be in the format `locations/global/workforcePools/<pool name>/providers/<provider name>`\n",
        "provider_id = \"\"  #@param {type: \"string\"}\n",
        "#@markdown If specifying project it should be in the format `projects/<project number>` <br><font color=red>The text based project ID will NOT work. You must use the project number!\n",
        "gcp_project = \"\" #@param {type: \"string\"}\n",
        "retention_duration = \"ONE_YEAR\" #@param [\"ONE_YEAR\", \"SIX_MONTHS\"]\n",
        "#@markdown Select whether to upload the SSO file or specify a local filename. If uploading the sso_config_file variable doesn't matter\n",
        "upload_sso_config = False #@param {type: \"boolean\"}\n",
        "# sso_config_filename = \"sso_conf.txt\"  #@param {type: \"string\"}\n",
        "sso_config_filename = \"\" #@param {type: \"string\"}\n",
        "\n",
        "req_body = {\n",
        "    \"customer_name\" : customer_name,\n",
        "    \"customer_code\" : customer_code,\n",
        "    \"customer_subdomains\" : customer_subdomains,\n",
        "    \"retention_duration\" : retention_duration\n",
        "    }\n",
        "\n",
        "if provider_id:\n",
        "  req_body[\"provider_id\"] = provider_id\n",
        "\n",
        "if gcp_project:\n",
        "  req_body[\"gcp_project\"] = gcp_project\n",
        "\n",
        "if upload_sso_config:\n",
        "  print(\"Please select and upload your SSO config file.\")\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  sso_config_filename = list(uploaded.keys())[0]\n",
        "\n",
        "if upload_sso_config and sso_config_filename:\n",
        "  with open(sso_config_filename, \"rb\") as file_to_read:\n",
        "    sso_config_file = base64.b64encode(file_to_read.read()).decode('ascii')\n",
        "\n",
        "  req_body[\"sso_config\"] = sso_config_file\n",
        "\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v1/partner/customer/createcustomer\"\n",
        "# send the request and process the response\n",
        "print(\"Attempting to create customer. This may take several minutes and there will be no output during this time.\")\n",
        "# extend http timeout to 20 minutes since this is a long call\n",
        "http_client.timeout = 1200\n",
        "# pprint(req_body)\n",
        "resp = http_client.request(uri_to_post, \"POST\", body=json.dumps(req_body))\n",
        "# return timeout back to default 1 minute\n",
        "http_client.timeout = 60\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "P1dxhOKKBvGK"
      },
      "outputs": [],
      "source": [
        "#@title Generate IdP Metadata\n",
        "#@markdown Generates new IdP metadata for a given subdomain. Customers can access Chronicle using <subdomain>.backstory.chronicle.security.\n",
        "customer_subdomain = \"dimarsky-old\" #@param {type: \"string\"}\n",
        "customer_subdomains = customer_subdomain.lower()\n",
        "download_output = False #@param {type: \"boolean\"}\n",
        "# decode_base64 = True #@param {type: \"boolean\"}\n",
        "\n",
        "uri_to_get = \"https://{}backstory.googleapis.com/v1/partner/customer/generateidpmetadata\".format(region_prefix)\n",
        "\n",
        "req_body = {\n",
        "    \"customer_subdomain\" : customer_subdomain\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "# send the request and process the response\n",
        "resp = session.post(uri_to_get, json=req_body)\n",
        "json_resp = resp.json()\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  metadata = json_resp['metadata']\n",
        "  if download_output:\n",
        "    with open(\"{}.xml\".format(customer_subdomain), \"w\") as customer_file:\n",
        "      customer_file.write(metadata)\n",
        "      # pprint(customer_data, stream=customer_file)\n",
        "    files.download(\"{}.xml\".format(customer_subdomain))\n",
        "    print(\"IdP Metadata has been downloaded to the local system.\")\n",
        "  else:\n",
        "    print(metadata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UoJZ5uANTbdN"
      },
      "outputs": [],
      "source": [
        "#@title Get Customer\n",
        "#@markdown Retrieves the customer details, including the customer name, forwarder IDs, stored credentials, and subdomains for a given customer being managed by the calling partner.\n",
        "customer_code = \"DMRSKnfr\" #@param {type: \"string\"}\n",
        "customer_code = customer_code.lower()\n",
        "download_output = False #@param {type: \"boolean\"}\n",
        "decode_base64 = True #@param {type: \"boolean\"}\n",
        "\n",
        "uri_to_get = \"https://{}backstory.googleapis.com/v1/partner/customer/getcustomer?customer_code={}\".format(region_prefix ,customer_code)\n",
        "# send the request and process the response\n",
        "resp = http_client.request(uri_to_get, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  customer_data = json_resp\n",
        "  if decode_base64:\n",
        "    for credential_index in range(len(customer_data['credentials'])):\n",
        "      customer_data['credentials'][credential_index]['credential'] = base64.b64decode(customer_data['credentials'][credential_index]['credential']).decode()\n",
        "    if \"config\" in customer_data[\"ssoConfig\"]:\n",
        "      customer_data[\"ssoConfig\"][\"config\"] = base64.b64decode(customer_data[\"ssoConfig\"][\"config\"]).decode()\n",
        "      sso_config = customer_data['ssoConfig']\n",
        "    customer_credentials = customer_data['credentials']\n",
        "    printable_customer_data = customer_data.copy()\n",
        "    if 'ssoConfig' in printable_customer_data:\n",
        "      del printable_customer_data['ssoConfig']\n",
        "    del printable_customer_data['credentials']\n",
        "    pprint(printable_customer_data)\n",
        "    if \"config\" in customer_data[\"ssoConfig\"]:\n",
        "      print(\"\\n\\nSSO Config:\\n{}\".format(sso_config['config']))\n",
        "    for credential in customer_credentials:\n",
        "      print(\"\\n\\n{} :\\n{}\".format(credential[\"credentialType\"], credential[\"credential\"]))\n",
        "\n",
        "  else:\n",
        "    pprint(customer_data)\n",
        "  if download_output:\n",
        "    with open(\"{}.json\".format(customer_code), \"w\") as customer_file:\n",
        "      customer_file.write(json.dumps(customer_data))\n",
        "      # pprint(customer_data, stream=customer_file)\n",
        "    files.download(\"{}.json\".format(customer_code))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZW1_RySfYrFA"
      },
      "outputs": [],
      "source": [
        "#@title Get Customer Forwarder Configs\n",
        "#@markdown Retrieves the customer's Linux or Windows Forwarder configuration. It first ensures that the partner identified by the service account has authorization to access the customer's forwarder. If there is more than one Chronicle Forwarder for a specific customer, the first active Forwarder is selected and its configuration is returned.\n",
        "customer_code = \"dmrsktst\" #@param {type: \"string\"}\n",
        "download_output = True #@param {type: \"boolean\"}\n",
        "decode_base64 = True #@param {type: \"boolean\"}\n",
        "\n",
        "uri_to_get = \"https://{}backstory.googleapis.com/v1/partner/customer/forwarder/getconfigs?customer_code={}\".format(region_prefix ,customer_code)\n",
        "# send the request and process the response\n",
        "resp = http_client.request(uri_to_get, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  forwarder_data = json_resp\n",
        "  if decode_base64:\n",
        "    for forwarder_index in range(len(forwarder_data['forwarderConfigs'])):\n",
        "      forwarder_data[\"forwarderConfigs\"][forwarder_index]['config'] = base64.b64decode(forwarder_data[\"forwarderConfigs\"][forwarder_index]['config']).decode()\n",
        "      print(\"{}\\n{}\".format(forwarder_data[\"forwarderConfigs\"][forwarder_index]['platform'], forwarder_data[\"forwarderConfigs\"][forwarder_index]['config']))\n",
        "  else:\n",
        "    pprint(forwarder_data)\n",
        "  if download_output:\n",
        "    with open(\"{}_forwarders.json\".format(customer_code), \"w\") as customer_file:\n",
        "      customer_file.write(json.dumps(forwarder_data))\n",
        "      # pprint(forwarder_data, stream=customer_file)\n",
        "    files.download(\"{}_forwarders.json\".format(customer_code))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QjRp9vv_cs4v"
      },
      "outputs": [],
      "source": [
        "#@title List Customers\n",
        "#@markdown Retrieves a list of the customers associated with the partner. The partner is identified when they authenticate using their service account credentials.\n",
        "download_output = False #@param {type: \"boolean\"}\n",
        "# decode_base64 = False #@param {type: \"boolean\"}\n",
        "\n",
        "uri_to_get = f\"https://{region_prefix}backstory.googleapis.com/v1/partner/customer/listcustomers\"\n",
        "# send the request and process the response\n",
        "resp = session.get(uri_to_get)\n",
        "# json_resp = json.loads(resp[1])\n",
        "if resp.status_code > 299:\n",
        "  pprint(resp.json().get('error').get('message'))\n",
        "else:\n",
        "  customers = resp.json()\n",
        "  pprint(customers)\n",
        "  # if decode_base64:\n",
        "  #   for forwarder_index in range(len(forwarder_data['forwarderConfigs'])):\n",
        "  #     forwarder_data[\"forwarderConfigs\"][forwarder_index]['config'] = base64.b64decode(forwarder_data[\"forwarderConfigs\"][forwarder_index]['config']).decode()\n",
        "  # pprint(forwarder_data)\n",
        "  if download_output:\n",
        "    with open(\"customer_list.json\", \"w\") as customer_file:\n",
        "      pprint(customers, stream=customer_file)\n",
        "    files.download(\"customer_list.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nVvlBDide1Tr"
      },
      "outputs": [],
      "source": [
        "#@title Set Auth Version\n",
        "#@markdown Enables you to update the authentication version for the specified customer. Complete this step only after confirming that the end-to-end authentication for the tenant they are migrating is working correctly.\n",
        "\n",
        "# Note: SetAuthVersion uses the POST method and auth_version can only be set to AUTH_VERSION_1 or AUTH_VERSION_2.\n",
        "customer_code = \"dmrsk\" #@param {type: \"string\"}\n",
        "auth_version = \"AUTH_VERSION_3\" #@param [\"AUTH_VERSION_1\",\"AUTH_VERSION_2\", \"AUTH_VERSION_3\", \"AUTH_VERSION_4\"]\n",
        "\n",
        "req_payload = {\n",
        "    \"customer_code\" : customer_code,\n",
        "    \"auth_version\" : auth_version\n",
        "}\n",
        "\n",
        "uri_to_post = \"https://{}backstory.googleapis.com/v1/partner/customer/setauthversion\".format(region_prefix)\n",
        "# send the request and process the response\n",
        "resp = http_client.request(uri_to_post, \"POST\", body=json.dumps(req_payload))\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eRR439B5iWqU"
      },
      "outputs": [],
      "source": [
        "#@title Set Compliance Requirements\n",
        "#@markdown Given a customer code and a list of compliance certifications, SetComplianceRequirements sets compliance requirements for the customer.\n",
        "customer_code = \"dmrsknfr\" #@param {type: \"string\"}\n",
        "#@markdown Please enter a comma separated list of complaince certifications. Valid values as of 10/18/23 are:\n",
        "##@markdown * COMPLIANCE_CERTIFICATION_UNSPECIFIED\n",
        "#@markdown * COMPLIANCE_CERTIFICATION_FEDRAMP_MODERATE\n",
        "#@markdown * COMPLIANCE_CERTIFICATION_HIPAA\n",
        "#@markdown * COMPLIANCE_CERTIFICATION_PCI_DSS\n",
        "#@markdown * COMPLIANCE_CERTIFICATION_FEDRAMP_HIGH\n",
        "compliance_certifiaction = \"\" #@param {type : \"string\"}\n",
        "compliance_certifiaction = [x.strip() for x in compliance_certifiaction.split(\",\")]\n",
        "\n",
        "req_payload = {\n",
        "    \"customer_code\" : customer_code,\n",
        "    \"compliance_certifications\" : compliance_certifiaction\n",
        "}\n",
        "\n",
        "uri_to_post = \"https://{}backstory.googleapis.com/v1/partner/customer/setcompliancerequirements\".format(region_prefix)\n",
        "# send the request and process the response\n",
        "resp = http_client.request(uri_to_post, \"POST\", body=json.dumps(req_payload))\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2oG0deN-jCCp"
      },
      "outputs": [],
      "source": [
        "#@title Set UI State\n",
        "#@markdown Enables or disables the web application of a tenant managed by a partner by updating the customer's feature flag.\n",
        "\n",
        "\n",
        "customer_code = \"dmrskbyop\" #@param {type: \"string\"}\n",
        "UI_state = True #@param {type: \"boolean\"}\n",
        "\n",
        "req_payload = {\n",
        "    \"customer_code\" : customer_code,\n",
        "    \"state\" : UI_state\n",
        "}\n",
        "\n",
        "uri_to_post = \"https://{}backstory.googleapis.com/v1/partner/customer/setuistate:state\".format(region_prefix)\n",
        "# send the request and process the response\n",
        "resp = http_client.request(uri_to_post, \"POST\", body=json.dumps(req_payload))\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsM7Pe7UaOzc",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Set Workforce Pool Provider\n",
        "#@markdown Given a customer code and its subdomain, SetWorkforcePoolProvider sets the workforce pool provider ID for the customer and its specified subdomain. Refer to the guide on how to create a workforce pool provider ID.\n",
        "\n",
        "\n",
        "customer_code = \"dmrsknfr\" #@param {type: \"string\"}\n",
        "customer_code = customer_code.lower()\n",
        "customer_subdomain = \"dimarskynet\" #@param {type: \"string\"}\n",
        "provider_id = \"locations/global/workforcePools/workspace-pool/providers/personal-domain-workspace\" #@param {type: \"string\"}\n",
        "\n",
        "req_payload = {\n",
        "    \"customer_code\" : customer_code,\n",
        "    \"customer_subdomain\" : customer_subdomain,\n",
        "    \"provider_id\" : provider_id\n",
        "}\n",
        "\n",
        "uri_to_post = \"https://{}backstory.googleapis.com/v1/partner/customer/setworkforcepoolprovider\".format(region_prefix)\n",
        "# send the request and process the response\n",
        "resp = http_client.request(uri_to_post, \"POST\", body=json.dumps(req_payload))\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhrNVGrGzR7Q",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Update SSO Config\n",
        "#@markdown Enables you to update the SSO Configuration for the specified customer. You can optionally add a subdomain if there are multiple subdomains for a given customer. If you call this API as part of the migration from AUTH_VERSION_1 to AUTH_VERSION_2, Google recommends setting the update_v2_only field to true.\n",
        "\n",
        "\n",
        "customer_code = \"epamdemo\" #@param {type: \"string\"}\n",
        "customer_code = customer_code.lower()\n",
        "customer_subdomain = \"epamdemo\" #@param {type: \"string\"}\n",
        "update_v2_only = True #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown Select whether to upload the SSO file or specify a local filename. If uploading the sso_config_file variable doesn't matter\n",
        "upload_sso_config = False #@param {type: \"boolean\"}\n",
        "sso_config_filename = \"/content/okta_metadata.xml\"  #@param {type: \"string\"}\n",
        "\n",
        "if upload_sso_config:\n",
        "  print(\"Please select and upload your SSO config file.\")\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  sso_config_filename = list(uploaded.keys())[0]\n",
        "\n",
        "with open(sso_config_filename, \"rb\") as file_to_read:\n",
        "  sso_config_file = base64.b64encode(file_to_read.read()).decode('ascii')\n",
        "\n",
        "\n",
        "req_payload = {\n",
        "    \"customer_code\" : customer_code,\n",
        "    \"sso_config\" : sso_config_file,\n",
        "    \"customer_subdomain\" : customer_subdomain,\n",
        "    \"update_v2_only\" : update_v2_only\n",
        "}\n",
        "\n",
        "uri_to_post = \"https://{}backstory.googleapis.com/v1/partner/customer/updatessoconfig\".format(region_prefix)\n",
        "# send the request and process the response\n",
        "http_client.timeout = 600\n",
        "resp = http_client.request(uri_to_post, \"PATCH\", body=json.dumps(req_payload))\n",
        "http_client.timeout = 60\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3ActwdOEGuf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Set GCP Project Link\n",
        "#@markdown Sets the Google Cloud project for the Chronicle instance. You may provide either the project ID or the project number in the gcp_project field.\n",
        "\n",
        "\n",
        "customer_code = \"dmrsknfr\" #@param {type: \"string\"}\n",
        "#@markdown The GCP project can either be the Project Number or the Project ID\n",
        "gcp_project = \"chronicle-byop\" #@param {type: \"string\"}\n",
        "\n",
        "req_payload = {\n",
        "    \"customer_code\" : customer_code,\n",
        "    \"gcp_project\" : f\"projects/{gcp_project}\"\n",
        "}\n",
        "\n",
        "uri_to_post = \"https://{}backstory.googleapis.com/v1/partner/customer/setgcpprojectlink\".format(region_prefix)\n",
        "# send the request and process the response\n",
        "resp = http_client.request(uri_to_post, \"POST\", body=json.dumps(req_payload))\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8SqrFNTUiD7n"
      },
      "outputs": [],
      "source": [
        "#@title GenerateIamMigrationCommands\n",
        "#@markdown Provides auto-generated commands that create new IAM policies equivalent to your existing Google SecOps RBAC access control, which is configured in Google SecOps, under the SIEM Settings > Users and Groups page.\n",
        "\n",
        "customer_code = \"dmrskbyop\" #@param {type: \"string\"}\n",
        "\n",
        "req_payload = {\n",
        "    \"customer_code\" : customer_code\n",
        "}\n",
        "\n",
        "uri_to_post = \"https://{}backstory.googleapis.com/v1/partner/customer/iammigration:generateIamMigrationCommands\".format(region_prefix)\n",
        "# send the request and process the response\n",
        "resp = http_client.request(uri_to_post, \"POST\", body=json.dumps(req_payload))\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SD0-bnqOrvrR"
      },
      "outputs": [],
      "source": [
        "#@title EnableIAM\n",
        "#@markdown Enables Feature RBAC controlled using IAM on the Google Security Operations instance of the customer organization specified in the request body.\n",
        "\n",
        "customer_code = \"dmrskbyop\" #@param {type: \"string\"}\n",
        "\n",
        "req_payload = {\n",
        "    \"customer_code\" : customer_code\n",
        "}\n",
        "\n",
        "uri_to_post = \"https://{}backstory.googleapis.com/v1/partner/customer/iammigration:enableIam\".format(region_prefix)\n",
        "# send the request and process the response\n",
        "resp = http_client.request(uri_to_post, \"POST\", body=json.dumps(req_payload))\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOLIlkpBCpNM"
      },
      "source": [
        "#Detection Engine\n",
        "Documentation [link](https://cloud.google.com/chronicle/docs/reference/detection-engine-api#archiverule)\n",
        "\n",
        "[Jump to top](#scrollTo=v0jKbGj8ZZRB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7WGvku-dC-d3"
      },
      "outputs": [],
      "source": [
        "#@title ArchiveRule\n",
        "#@markdown Archive the specified rule.\n",
        "\n",
        "ruleId = \"ru_4aa9de46-704c-4a96-8aa8-5ee1992302f7\" #@param {type: \"string\"}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/{ruleId}:archive\"\n",
        "resp = http_client.request(uri_to_post, \"POST\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "R8P3akYkDoOw"
      },
      "outputs": [],
      "source": [
        "#@title CancelRetrohunt\n",
        "#@markdown Cancel a retrohunt for the specified rule.\n",
        "\n",
        "#@markdown Please specify a rule ID to cancel a retrohunt for the latest version of a rule.\n",
        "\n",
        "#@markdown **OR**\n",
        "\n",
        "#@markdown  Please specify a version ID to cancel a retrohunt for a specific version of a rule.\n",
        "cancel_latest_version = True #@param {type: \"boolean\"}\n",
        "ruleId = \"\" #@param {type: \"string\"}\n",
        "versionId = \"\" #@param {type: \"string\"}\n",
        "retrohuntId = \"\" #@param {type: \"string\"}\n",
        "\n",
        "rule_identifier = ruleId if cancel_latest_version else versionId\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/{rule_identifier}/retrohunts/{retrohuntId}:cancelRetrohunt\"\n",
        "resp = http_client.request(uri_to_post, \"POST\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oJIyICJDFMmC"
      },
      "outputs": [],
      "source": [
        "#@title CreateRule\n",
        "#@markdown Create a new rule without setting the rule to live.\n",
        "\n",
        "#@markdown Choose whether to upload a text file with the rule or use one already in the filesystem of the colab instance.\n",
        "\n",
        "upload_rule = False #@param {type: \"boolean\"}\n",
        "rule_filename = \"rule.txt\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown <font color=\"red\">Optional</font>: [add labels for data export API](https://cloud.google.com/chronicle/docs/preview/datatap-config/use-rules-in-datatap)\n",
        "\n",
        "#@markdown Please enter as a comma seperated list of label=state\n",
        "\n",
        "#@markdown Example: **label1=ENABLED, label2=DISABLED, label3=ENABLED, etc...**\n",
        "\n",
        "labels = \"label1=ENABLED, label2=DISABLED, label3=ENABLED\" #@param {type: \"string\"}\n",
        "\n",
        "if upload_rule:\n",
        "  print(\"Please select and upload your rule\")\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  rule_filename = list(uploaded.keys())[0]\n",
        "\n",
        "with open(rule_filename, \"r\") as rule:\n",
        "  rule_text = rule.read()\n",
        "\n",
        "request_body = {\n",
        "    \"ruleText\" : rule_text\n",
        "}\n",
        "\n",
        "if labels:\n",
        "  #create a labels key\n",
        "  if \"labels\" not in request_body.keys():\n",
        "    request_body[\"labels\"] = {\"label\":[]}\n",
        "\n",
        "  labels = labels.split(\",\")\n",
        "  for label in labels:\n",
        "    label, state = label.split(\"=\")\n",
        "    if state.strip().upper() not in [\"ENABLED\", \"DISABLED\"]:\n",
        "      print(f\"State must be either \\\"ENABLED\\\" or \\\"DISABLED\\\". {state.trim().upper()} was found instead. Aborting this execution. Please correct this data.\")\n",
        "      sys.exit(f\"Invalid value supplied for state: {state.trim().upper()}\")\n",
        "    request_body[\"labels\"][\"label\"].append({\n",
        "        \"state\": state.strip().upper(),\n",
        "        \"data_tap_label\": {\n",
        "          \"sink_name\": label.strip(),\n",
        "        }\n",
        "      })\n",
        "# print(json.dumps(request_body, indent=2))\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules\"\n",
        "resp = http_client.request(uri_to_post, \"POST\", body=json.dumps(request_body))\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Iv9aw4DXHnd5"
      },
      "outputs": [],
      "source": [
        "#@title CreateRuleVersion\n",
        "#@markdown Creates a new version of an existing rule. The new version of the rule does not have to be based on the latest version.\n",
        "\n",
        "ruleId = \"ru_4aa9de46-704c-4a96-8aa8-5ee1992302f7\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Choose whether to upload a text file with the rule or use one already in the filesystem of the colab instance.\n",
        "\n",
        "upload_rule = False #@param {type: \"boolean\"}\n",
        "rule_filename = \"new_rule.yaral\" #@param {type: \"string\"}\n",
        "\n",
        "if upload_rule:\n",
        "  print(\"Please select and upload your keyfile\")\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  rule_filename = list(uploaded.keys())[0]\n",
        "\n",
        "with open(rule_filename, \"r\") as rule:\n",
        "  rule_text = rule.read()\n",
        "\n",
        "request_body = {\n",
        "    \"ruleText\" : rule_text\n",
        "}\n",
        "\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/{ruleId}:createVersion\"\n",
        "resp = http_client.request(uri_to_post, \"POST\", body=json.dumps(request_body))\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CeHbpEA8ILQB"
      },
      "outputs": [],
      "source": [
        "#@title DeleteRule\n",
        "#@markdown Delete the specified rule.\n",
        "\n",
        "ruleId = \"ru_f42f44db-4702-483e-9dcd-769023a35119\" #@param {type: \"string\"}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/{ruleId}\"\n",
        "resp = http_client.request(uri_to_post, \"DELETE\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Zbfa246DJTt0"
      },
      "outputs": [],
      "source": [
        "#@title DisableAlerting\n",
        "#@markdown Disables alerts for the specified rule.\n",
        "\n",
        "ruleId = \"\" #@param {type: \"string\"}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/{ruleId}:disableAlerting\"\n",
        "resp = http_client.request(uri_to_post, \"POST\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8Glx8Vv6Jg-M"
      },
      "outputs": [],
      "source": [
        "#@title DisableLiveRule\n",
        "#@markdown Disable the latest version of the rule.\n",
        "\n",
        "ruleId = \"\" #@param {type: \"string\"}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/{ruleId}:disableLiveRule\"\n",
        "resp = http_client.request(uri_to_post, \"POST\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "e5gUjRpPJuxU"
      },
      "outputs": [],
      "source": [
        "#@title EnableAlerting\n",
        "#@markdown Enables alerts for the specified rule.\n",
        "\n",
        "ruleId = \"\" #@param {type: \"string\"}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/{ruleId}:enableAlerting\"\n",
        "resp = http_client.request(uri_to_post, \"POST\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UqbMwnGnKLP0"
      },
      "outputs": [],
      "source": [
        "#@title EnableLiveRule\n",
        "#@markdown Set the latest version of a rule to live.\n",
        "\n",
        "ruleId = \"ru_e9b2c796-de5a-4261-8606-88f2c18f78b7\" #@param {type: \"string\"}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/{ruleId}:enableLiveRule\"\n",
        "resp = http_client.request(uri_to_post, \"POST\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r4JL4ZWRKb4C"
      },
      "outputs": [],
      "source": [
        "#@title GetDetection\n",
        "#@markdown Return the specified detection for the specified version of a rule.\n",
        "\n",
        "#@markdown Please specify a rule ID to get the detection for the latest version of a rule.\n",
        "\n",
        "#@markdown <font color=\"red\">**OR**</font>\n",
        "\n",
        "#@markdown  Please specify a version ID to get the detection for a specific version of a rule.\n",
        "latest_version = True #@param {type: \"boolean\"}\n",
        "ruleId = \"ru_4160ef00-534f-4f35-880c-367dfc1e30b4\" #@param {type: \"string\"}\n",
        "versionId = \"\" #@param {type: \"string\"}\n",
        "detectionId = \"de_a2e3d7a0-8363-d69e-1079-bdc8a4c5155a\" #@param {type: \"string\"}\n",
        "\n",
        "rule_identifier = ruleId if latest_version else versionId\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/{rule_identifier}/detections/{detectionId}\"\n",
        "resp = http_client.request(uri_to_post, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "K2MGDtvdLGBe"
      },
      "outputs": [],
      "source": [
        "#@title GetError\n",
        "#@markdown Return the specified error.\n",
        "\n",
        "errorID = \"\" #@param {type: \"string\"}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/errors/{errorId}\"\n",
        "resp = http_client.request(uri_to_post, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "c05E2umILcHy"
      },
      "outputs": [],
      "source": [
        "#@title GetRetrohunt\n",
        "#@markdown Getting the retrohunt for the specified version of a rule.\n",
        "\n",
        "#@markdown Please specify a rule ID to get the retrohunt for the latest version of a rule.\n",
        "\n",
        "#@markdown **OR**\n",
        "\n",
        "#@markdown  Please specify a version ID to get the retrohunt for a specific version of a rule.\n",
        "latest_version = True #@param {type: \"boolean\"}\n",
        "ruleId = \"\" #@param {type: \"string\"}\n",
        "versionId = \"\" #@param {type: \"string\"}\n",
        "retrohuntId = \"\" #@param {type: \"string\"}\n",
        "\n",
        "rule_identifier = ruleId if latest_version else versionId\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/{rule_identifier}/retrohunts/{retrohuntId}\"\n",
        "resp = http_client.request(uri_to_post, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EUQnBcHKL09E"
      },
      "outputs": [],
      "source": [
        "#@title GetRule\n",
        "#@markdown Return the specified rule.\n",
        "\n",
        "#@markdown Please specify a rule ID to get the latest version of a rule.\n",
        "\n",
        "#@markdown **OR**\n",
        "\n",
        "#@markdown  Please specify a version ID to get a specific version of a rule.\n",
        "latest_version = True #@param {type: \"boolean\"}\n",
        "ruleId = \"ru_cfbdd40f-1223-4812-8dd4-c6a0dc0e46df\" #@param {type: \"string\"}\n",
        "versionId = \"\" #@param {type: \"string\"}\n",
        "\n",
        "rule_identifier = ruleId if latest_version else versionId\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/{rule_identifier}\"\n",
        "resp = http_client.request(uri_to_post, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pq6JtaxoNiO5"
      },
      "outputs": [],
      "source": [
        "#@title ListCuratedRules\n",
        "#@markdown List Chronicle rules with detections.\n",
        "\n",
        "#@markdown Page size can range from 1 to 1,000\n",
        "page_size = 100 #@param {type:\"integer\"}\n",
        "page_token = \"\" #@param {type: \"string\"}\n",
        "\n",
        "url_params = {'page_size': page_size}\n",
        "if page_token:\n",
        "  url_params[\"page_token\"] = page_token\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/curatedRules\"\n",
        "resp = session.get(uri_to_post, params=url_params)\n",
        "json_resp = resp.json()\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2n6XE1GnPHKh"
      },
      "outputs": [],
      "source": [
        "#@title ListCuratedRuleDetections\n",
        "#@markdown Return the detections for the specified Chronicle rule.\n",
        "\n",
        "#@markdown REQUIRED:\n",
        "ruleId = \"-\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown OPTIONAL:\n",
        "alert_state = \"\" #@param [\"\", \"ALERTING\", \"NOT_ALERTING\"]\n",
        "#@markdown Start and End times are optional. If you check the box(es) below the corresponding field will be ignore (unbound start or end time).\n",
        "no_starting_time = True #@param {type: \"boolean\"}\n",
        "no_ending_time = True #@param {type: \"boolean\"}\n",
        "startDate = \"2025-01-04\" #@param {type: \"date\"}\n",
        "endDate = \"2025-02-04\" #@param {type: \"date\"}\n",
        "#@markdown Time should be in the format HH:MM:SS including leading zeros\n",
        "startTime = \"12:12:00\" #@param {type: \"string\"}\n",
        "endTime = \"12:12:00\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Sort detections by **DETECTION_TIME** or by **CREATED_TIME**. Defaults to DETECTION_TIME. Detections are returned in descending order of the timestamp.\n",
        "list_basis = \"DETECTION_TIME\" #@param [\"DETECTION_TIME\", \"CREATED_TIME\"]\n",
        "\n",
        "startTime = f\"{startDate}T{startTime}Z\"\n",
        "endTime = f\"{endDate}T{endTime}Z\"\n",
        "\n",
        "#@markdown Page size can range from 1 to 1,000\n",
        "page_size = 100 #@param {type:\"integer\"}\n",
        "page_token = \"\" #@param {type: \"string\"}\n",
        "\n",
        "\n",
        "url_params = {\n",
        "    'page_size': page_size,\n",
        "    \"list_basis\" : list_basis\n",
        "    }\n",
        "if page_token:\n",
        "  url_params[\"page_token\"] = page_token\n",
        "if not no_starting_time:\n",
        "  url_params[\"start_time\"] = startTime\n",
        "if not no_ending_time:\n",
        "  url_params[\"end_time\"] = endTime\n",
        "if alert_state:\n",
        "  url_params[\"alert_state\"] = alert_state\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/curatedRules/{ruleId}/detections\"\n",
        "resp = session.get(uri_to_post, params=url_params)\n",
        "json_resp = resp.json()\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vQRQMfgNMsCJ"
      },
      "outputs": [],
      "source": [
        "#@title ListDetections\n",
        "#@markdown Return the detections for the specified version of a rule, the latest version of a rule, all versions of a rule, or all versions of all rules.\n",
        "\n",
        "#@markdown Please specify a rule ID to get detections for the latest version of a rule.\n",
        "\n",
        "#@markdown **OR**\n",
        "\n",
        "#@markdown  Please specify a version ID to get detections for a specific version of a rule.\n",
        "\n",
        "latest_version = False #@param {type: \"boolean\"}\n",
        "ruleId = \"-\" #@param {type: \"string\"}\n",
        "#@markdown To get detections for all versions of a specified rule check the below box and make sure the **latest_version** checkbox above is also checked..\n",
        "all_versions = False #@param {type: \"boolean\"}\n",
        "versionId = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown If you would like to ignore the rule ID and get detections for all versions of all rules then check the below box.\n",
        "all_detections_for_all_version = True #@param {type: \"boolean\"}\n",
        "\n",
        "page_size = 12 #@param {type:\"slider\", min:1, max:1000, step:1}\n",
        "page_token = \"\" #@param {type: \"string\"}\n",
        "\n",
        "\n",
        "startTime = \"2023-09-01\" #@param {type: \"date\"}\n",
        "endTime = \"2023-09-12\" #@param {type: \"date\"}\n",
        "startTime = f\"{startTime}T00:00:00Z\"\n",
        "endTime = f\"{endTime}T23:59:59Z\"\n",
        "\n",
        "write_to_file = True #@param {type: \"boolean\"}\n",
        "#@markdown If writing to file should data also be displayed on screen?\n",
        "also_output_to_screen = False #@param {type: \"boolean\"}\n",
        "#@markdown If the write to file option is selected specify the filename to write data to.\n",
        "filename = \"detections.json\" #@param {type: \"string\"}\n",
        "\n",
        "url_params = {}\n",
        "url_params[\"start_time\"] = startTime\n",
        "url_params[\"end_time\"] = endTime\n",
        "\n",
        "url_params['page_size'] =  page_size\n",
        "if page_token:\n",
        "  url_params[\"page_token\"] = page_token\n",
        "encoded_url_params = urlencode(url_params)\n",
        "\n",
        "rule_identifier = ruleId if latest_version else versionId\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/{rule_identifier}/detections\"\n",
        "if all_versions:\n",
        "  uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/{rule_identifier}@-/detections\"\n",
        "if all_detections_for_all_version:\n",
        "  uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/-/detections\"\n",
        "\n",
        "uri_to_post += f\"?{encoded_url_params}\"\n",
        "\n",
        "resp = http_client.request(uri_to_post, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  if write_to_file:\n",
        "    with open(filename, \"w\") as output_file:\n",
        "      if \"detections\" in json_resp.keys():\n",
        "        output_file.write(json.dumps(json_resp))\n",
        "        print(f\"Wrote {len(json_resp['detections'])} detection to {filename}\")\n",
        "        if also_output_to_screen:\n",
        "          pprint(json_resp)\n",
        "      else:\n",
        "        print(\"No detections were returned for this query.\")\n",
        "  else:\n",
        "    pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "32T4mi7eRBhN"
      },
      "outputs": [],
      "source": [
        "#@title ListErrors\n",
        "#@markdown List the latest rule errors.\n",
        "\n",
        "#@markdown Page size can range from 1 to 1,000\n",
        "page_size = 101 #@param {type:\"integer\"}\n",
        "page_token = \"\" #@param {type: \"string\"}\n",
        "\n",
        "url_params = {'page_size': page_size}\n",
        "if page_token:\n",
        "  url_params[\"page_token\"] = page_token\n",
        "\n",
        "startDate = \"2022-11-01\" #@param {type: \"date\"}\n",
        "endDate = \"2022-11-03\" #@param {type: \"date\"}\n",
        "\n",
        "#@markdown Time should be in the format HH:MM:SS including leading zeros\n",
        "startTime = \"00:00:01\" #@param {type: \"string\"}\n",
        "endTime = \"23:59:59\" #@param {type: \"string\"}\n",
        "\n",
        "startTime = f\"{startDate}T{startTime}Z\"\n",
        "endTime = f\"{endDate}T{endTime}Z\"\n",
        "\n",
        "url_params[\"start_time\"] = startTime\n",
        "url_params[\"end_time\"] = endTime\n",
        "\n",
        "encoded_url_params = urlencode(url_params)\n",
        "\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/health/errors?{encoded_url_params}\"\n",
        "resp = http_client.request(uri_to_post, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OOKRkW7ZR7Sw"
      },
      "outputs": [],
      "source": [
        "#@title ListRetrohunts\n",
        "#@markdown Listing the retrohunts for a rule.\n",
        "\n",
        "#@markdown Please specify a rule ID to get retrohunts for the latest version of a rule.\n",
        "\n",
        "#@markdown **OR**\n",
        "\n",
        "#@markdown  Please specify a version ID to get retrohunts for a specific version of a rule.\n",
        "\n",
        "latest_version = True #@param {type: \"boolean\"}\n",
        "ruleId = \"\" #@param {type: \"string\"}\n",
        "#@markdown To get retrohunts for all versions of a specified rule check the below box and make sure the **latest_version** checkbox above is also checked..\n",
        "all_versions = True #@param {type: \"boolean\"}\n",
        "versionId = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown If you would like to ignore the rule ID and get retrohunts for all versions of all rules then check the below box.\n",
        "all_retrohunts_for_all_version = True #@param {type: \"boolean\"}\n",
        "\n",
        "page_size = 4 #@param {type:\"slider\", min:1, max:1000, step:1}\n",
        "page_token = \"\" #@param {type: \"string\"}\n",
        "\n",
        "url_params = {}\n",
        "url_params['page_size'] = page_size\n",
        "if page_token:\n",
        "  url_params[\"page_token\"] = page_token\n",
        "encoded_url_params = urlencode(url_params)\n",
        "\n",
        "\n",
        "rule_identifier = ruleId if latest_version else versionId\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/{rule_identifier}/retrohunts\"\n",
        "if all_versions:\n",
        "  uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/{rule_identifier}@-/retrohunts\"\n",
        "if all_retrohunts_for_all_version:\n",
        "  uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/-/retrohunts\"\n",
        "\n",
        "uri_to_post += f\"?{encoded_url_params}\"\n",
        "\n",
        "resp = http_client.request(uri_to_post, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RiSRcB-uItgx"
      },
      "outputs": [],
      "source": [
        "#@title ListRules\n",
        "#@markdown List the latest versions of all rules.\n",
        "\n",
        "#@markdown Max page size is 10,000\n",
        "page_size = 2000 #@param {type:\"integer\"}\n",
        "page_token = \"\" #@param {type: \"string\"}\n",
        "download_output = False #@param {type: \"boolean\"}\n",
        "\n",
        "url_params = {'page_size': page_size}\n",
        "if page_token:\n",
        "  url_params[\"page_token\"] = page_token\n",
        "encoded_url_params = urlencode(url_params)\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules?{encoded_url_params}\"\n",
        "resp = http_client.request(uri_to_post, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  if download_output:\n",
        "    if \"listRules.json\" in os.listdir():\n",
        "      os.remove(\"listRules.json\")\n",
        "    with open(\"listRules.json\", \"w\") as output_file:\n",
        "      json.dump(json_resp, output_file, indent=2)\n",
        "    files.download(\"listRules.json\")\n",
        "    print(\"Complete and file downloaded\")\n",
        "  else:\n",
        "    print(json_resp)\n",
        "  # pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zVlYPRBaWDVp"
      },
      "outputs": [],
      "source": [
        "#@title ListRuleVersions\n",
        "#@markdown List all versions of a specific rule. The versions are listed in descending order by the rule version creation time.\n",
        "\n",
        "ruleId = \"ru_4aa9de46-704c-4a96-8aa8-5ee1992302f7\" #@param {type: \"string\"}\n",
        "#@markdown Max page size is 1,000\n",
        "page_size = 90 #@param {type:\"integer\"}\n",
        "page_token = \"\" #@param {type: \"string\"}\n",
        "\n",
        "url_params = {'page_size': page_size}\n",
        "if page_token:\n",
        "  url_params[\"page_token\"] = page_token\n",
        "encoded_url_params = urlencode(url_params)\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/{ruleId}:listVersions?{encoded_url_params}\"\n",
        "resp = http_client.request(uri_to_post, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9HCSoDnutRfO"
      },
      "outputs": [],
      "source": [
        "#@title StreamDetectionAlerts\n",
        "#@markdown Continuously receive Detection Engine results over an HTTP stream as the detections are discovered.\n",
        "\n",
        "#@markdown The StreamDetectionAlerts API only shows detections created by rules whose alerting status was enabled at the time of detection. Enable alerting using the Chronicle UI by setting the Alerting option to enabled from the Rules Dashboard. Each rule has an alerting status.\n",
        "\n",
        "specify_continuationTime = True #@param {type:\"boolean\"}\n",
        "#@markdown Dates/Times are in UTC\n",
        "\n",
        "\n",
        "#@markdown Timestamp in RFC 3339 format used to request all detections after the specified time. If omitted, all detections after the current time are transmitted.\n",
        "\n",
        "continuationDate = \"2022-11-01\" #@param {type: \"date\"}\n",
        "#@markdown Time should be in the format HH:MM:SS including leading zeros\n",
        "continuationTime = \"12:12:00\" #@param {type: \"string\"}\n",
        "\n",
        "if specify_continuationTime:\n",
        "  continuationTime = f\"{continuationDate}T{continuationTime}Z\"\n",
        "  body = {\n",
        "    \"continuationTime\": continuationTime\n",
        "  }\n",
        "else:\n",
        "  body = {}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules:streamDetectionAlerts\"\n",
        "resp = session.post(uri_to_post, json=body, stream=True)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  for line in resp.iter_lines():\n",
        "    print(line)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9rHkaG8SyJir"
      },
      "outputs": [],
      "source": [
        "#@title StreamTestRule\n",
        "#@markdown Test a rule over a specified time range. Return any errors and any detections up to the specified maximum without persistence (detections are not retained).\n",
        "\n",
        "#@markdown Dates/Times are in UTC\n",
        "\n",
        "startDate = \"2024-04-10\" #@param {type: \"date\"}\n",
        "endDate = \"2024-04-19\" #@param {type: \"date\"}\n",
        "#@markdown Time should be in the format HH:MM:SS including leading zeros\n",
        "startTime = \"12:12:00\" #@param {type: \"string\"}\n",
        "endTime = \"12:12:00\" #@param {type: \"string\"}\n",
        "\n",
        "startTime = f\"{startDate}T{startTime}Z\"\n",
        "endTime = f\"{endDate}T{endTime}Z\"\n",
        "\n",
        "#@markdown Maximum number of results to return. Specify a value between 1 and 10,000. The default is 1,000.\n",
        "maxResults = 1000 #@param {type: \"integer\"}\n",
        "\n",
        "#@markdown ##Note\n",
        "#@markdown You will be prompted to select a file to upload as the test yara rule.\n",
        "\n",
        "print(\"Please select and upload yara rule to be tested\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "os.system(f\"mv '{list(uploaded.keys())[0]}' yara_rule.yara\")\n",
        "with open(\"yara_rule.yara\", \"r\") as rule_file:\n",
        "  rule = rule_file.read()\n",
        "\n",
        "# clean up after ourselves\n",
        "os.system(f\"rm yara_rule.yara\")\n",
        "\n",
        "body = {\n",
        "  \"rule\": {\n",
        "    \"ruleText\": rule\n",
        "  },\n",
        "  \"startTime\": startTime,\n",
        "  \"endTime\": endTime,\n",
        "  \"maxResults\": maxResults,\n",
        "}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules:streamTestRule\"\n",
        "resp = session.post(uri_to_post, json=body, stream=True)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  print(\"Please wait for the results to be streamed in...\")\n",
        "  for line in resp.iter_lines():\n",
        "    print(line)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Yxi1GX9Ofyn5"
      },
      "outputs": [],
      "source": [
        "#@title RunRetrohunt\n",
        "#@markdown Initiate a retrohunt for the specified rule.\n",
        "\n",
        "ruleId = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Dates/Times are in UTC\n",
        "\n",
        "startDate = \"2022-11-01\" #@param {type: \"date\"}\n",
        "endDate = \"2022-11-03\" #@param {type: \"date\"}\n",
        "\n",
        "#@markdown Time should be in the format HH:MM:SS including leading zeros\n",
        "startTime = \"00:00:01\" #@param {type: \"string\"}\n",
        "endTime = \"23:59:59\" #@param {type: \"string\"}\n",
        "\n",
        "startTime = f\"{startDate}T{startTime}Z\"\n",
        "endTime = f\"{endDate}T{endTime}Z\"\n",
        "request_body = {\n",
        "    \"startTime\" : startTime,\n",
        "    \"endTime\": endTime\n",
        "}\n",
        "\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/{ruleId}:runRetrohunt\"\n",
        "resp = http_client.request(uri_to_post, \"POST\", body=json.dumps(request_body))\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-fj2t2lMQCoO"
      },
      "outputs": [],
      "source": [
        "#@title UnarchiveRule\n",
        "#@markdown Unarchive the specified rule.\n",
        "\n",
        "ruleId = \"ru_4aa9de46-704c-4a96-8aa8-5ee1992302f7\" #@param {type: \"string\"}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/{ruleId}:unarchive\"\n",
        "resp = http_client.request(uri_to_post, \"POST\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-mLz0eQKSfRB"
      },
      "outputs": [],
      "source": [
        "#@title VerifyRule\n",
        "#@markdown Verifies that a rule is a valid YARA-L 2.0 rule without creating a new rule or evaluating it over data.\n",
        "\n",
        "#@markdown Choose whether to upload a text file with the rule or use one already in the filesystem of the colab instance.\n",
        "\n",
        "upload_rule = True #@param {type: \"boolean\"}\n",
        "rule_filename = \"\" #@param {type: \"string\"}\n",
        "\n",
        "if upload_rule:\n",
        "  print(\"Please select and upload your keyfile\")\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  rule_filename = list(uploaded.keys())[0]\n",
        "\n",
        "with open(rule_filename, \"r\") as rule:\n",
        "  rule_text = rule.read()\n",
        "\n",
        "request_body = {\n",
        "    \"ruleText\" : rule_text\n",
        "}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules:verifyRule\"\n",
        "resp = http_client.request(uri_to_post, \"POST\", body=json.dumps(request_body))\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vrtAagLVWAWC"
      },
      "outputs": [],
      "source": [
        "#@title WaitRetrohunt\n",
        "#@markdown Enables you to determine whether or not a retrohunt currently in progress has completed within the time period specified. If the retrohunt completes within the time period, WaitRetrohunt returns the retrohunt data. Otherwise, it returns an error indicating that timeout has been reached without the retrohunt completing.\n",
        "\n",
        "#@markdown Please specify a rule ID to check a retrohunt wait for the latest version of a rule.\n",
        "\n",
        "#@markdown **OR**\n",
        "\n",
        "#@markdown  Please specify a version ID to check a retrohunt wait for a specific version of a rule.\n",
        "latest_version = True #@param {type: \"boolean\"}\n",
        "ruleId = \"\" #@param {type: \"string\"}\n",
        "versionId = \"\" #@param {type: \"string\"}\n",
        "retrohuntId = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Time in seconds to wait for the retrohunt specified to complete. If timeout is not specified, the default is 5 minutes (300 seconds). The minimum timeout is 3 seconds and the maximum timeout is 5 minutes.\n",
        "timeout = 300 #@param {type: \"slider\", min: 3, max: 300}\n",
        "\n",
        "rule_identifier = ruleId if latest_version else versionId\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/detect/rules/{rule_identifier}/retrohunts/{retrohuntId}:wait\"\n",
        "\n",
        "req_body = {\n",
        "    \"timeout\" : str(timeout)\n",
        "}\n",
        "\n",
        "# extend http timeout to may be a long call\n",
        "http_client.timeout = timeout + 60\n",
        "resp = http_client.request(uri_to_post, \"POST\", body=json.dumps(req_body))\n",
        "# return timeout back to default 1 minute\n",
        "http_client.timeout = 60\n",
        "\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q_rBGSYzWD8"
      },
      "source": [
        "#Search API\n",
        "Documentation [link](https://cloud.google.com/chronicle/docs/reference/search-api)\n",
        "\n",
        "[Jump to top](#scrollTo=v0jKbGj8ZZRB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yZSwrMc8nE0g"
      },
      "outputs": [],
      "source": [
        "#@title GetLog\n",
        "#@markdown Returns a single raw log given the UID for the event.\n",
        "\n",
        "logId = \"NDhiMzQ1OThmMDc3OTg4MWNjNGQxY2NiNDVmMmUzN2U=\" #@param {type: \"string\"}\n",
        "\n",
        "decode_base64 = True #@param {type: \"boolean\"}\n",
        "save_to_file = False #@param {type: \"boolean\"}\n",
        "#@markdown Save file option must be selected to download the file.\n",
        "download_file_to_computer = False #@param {type: \"boolean\"}\n",
        "#@markdown Specify a filename to write the output to. Can be blank if save_to_file is not checked.\n",
        "file_name = \"testfile.json\" #@param {type: \"string\"}\n",
        "\n",
        "url_params = {}\n",
        "url_params[\"name\"] = logId\n",
        "\n",
        "uri = f\"https://{region_prefix}backstory.googleapis.com/v1/events/log:get/\"\n",
        "resp = session.get(uri, params=url_params)\n",
        "json_resp = resp.json()\n",
        "\n",
        "if decode_base64 and \"log\" in json_resp.keys():\n",
        "  json_resp['log']['decodedLog'] = base64.b64decode(json_resp['log']['logBytes']).decode()\n",
        "\n",
        "\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  if save_to_file:\n",
        "    if file_name in os.listdir():\n",
        "      os.remove(file_name)\n",
        "      print(f\"File named {file_name} already exists. Deleting it before writing new data.\")\n",
        "    with open(file_name, \"w\") as file_to_write:\n",
        "      file_to_write.write(json.dumps(json_resp))\n",
        "      print(f\"Saved data to: {file_name}\")\n",
        "    if download_file_to_computer:\n",
        "      files.download(file_name)\n",
        "  else:\n",
        "    pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y2MM0hNB-58b"
      },
      "outputs": [],
      "source": [
        "#@title GetEvent\n",
        "#@markdown Returns a single event given the UID for the event.\n",
        "\n",
        "uuid = \"AAAAAD2pxUYCmstzWDKckUtDt9EAAAAADgAAAAEAAAA=\" #@param {type: \"string\"}\n",
        "\n",
        "save_to_file = False #@param {type: \"boolean\"}\n",
        "#@markdown Save file option must be selected to download the file.\n",
        "download_file_to_computer = False #@param {type: \"boolean\"}\n",
        "#@markdown Specify a filename to write the output to. Can be blank if save_to_file is not checked.\n",
        "file_name = \"testfile.json\" #@param {type: \"string\"}\n",
        "\n",
        "uri = f\"https://{region_prefix}backstory.googleapis.com/v1/event:get?name={uuid}\"\n",
        "resp = session.get(uri)\n",
        "json_resp = resp.json()\n",
        "\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  if save_to_file:\n",
        "    if file_name in os.listdir():\n",
        "      os.remove(file_name)\n",
        "      print(f\"File named {file_name} already exists. Deleting it before writing new data.\")\n",
        "    with open(file_name, \"w\") as file_to_write:\n",
        "      file_to_write.write(json.dumps(json_resp))\n",
        "      print(f\"Saved data to: {file_name}\")\n",
        "    if download_file_to_computer:\n",
        "      files.download(file_name)\n",
        "  else:\n",
        "    pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sYaIj5DczwCk"
      },
      "outputs": [],
      "source": [
        "#@title ListAlerts\n",
        "#@markdown Returns information about both asset-based and user-based alerts with event timestamps within the specified time range.\n",
        "\n",
        "#@markdown Specify the maximum number of alerts to return. You can specify between 1 and 100,000. The default is 10,000.\n",
        "page_size =  100#@param {type:\"integer\"}\n",
        "# page_token = \"\" #@param {type: \"string\"}\n",
        "startDate = \"2024-01-01\" #@param {type: \"date\"}\n",
        "endDate = \"2024-03-29\" #@param {type: \"date\"}\n",
        "\n",
        "#@markdown Time should be in the format HH:MM:SS including leading zeros\n",
        "startTime = \"00:00:01\" #@param {type: \"string\"}\n",
        "endTime = \"23:59:59\" #@param {type: \"string\"}\n",
        "\n",
        "startTime = f\"{startDate}T{startTime}Z\"\n",
        "endTime = f\"{endDate}T{endTime}Z\"\n",
        "\n",
        "write_to_file = False #@param {type: \"boolean\"}\n",
        "#@markdown If writing to file should data also be displayed on screen?\n",
        "also_output_to_screen = False #@param {type: \"boolean\"}\n",
        "#@markdown If the write to file option is selected specify the filename to write data to.\n",
        "filename = \"alerts.json\" #@param {type: \"string\"}\n",
        "\n",
        "url_params = {}\n",
        "url_params[\"start_time\"] = startTime\n",
        "url_params[\"end_time\"] = endTime\n",
        "\n",
        "url_params['page_size'] = page_size\n",
        "# encoded_url_params = urlencode(url_params)\n",
        "\n",
        "uri = f\"https://{region_prefix}backstory.googleapis.com/v1/alert/listalerts\"\n",
        "resp = session.get(uri, params=url_params)\n",
        "json_resp = resp.json()\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  # pprint(json_resp)\n",
        "  if write_to_file:\n",
        "    with open(filename, \"w\") as output_file:\n",
        "      if \"alerts\" in json_resp.keys() or \"userAlerts\" in json_resp.keys():\n",
        "        output_file.write(json.dumps(json_resp))\n",
        "        print(f\"Wrote {len(json_resp['alerts']  if 'alerts' in json_resp.keys() else  [])} alerts and {len(json_resp['userAlerts'] if 'userAlerts' in json_resp.keys() else [])} user alerts to {filename}\")\n",
        "        if also_output_to_screen:\n",
        "          pprint(json_resp)\n",
        "      else:\n",
        "        print(\"No alerts were returned for this query.\")\n",
        "  else:\n",
        "    pprint(json_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Vlb-tefP7K2I"
      },
      "outputs": [],
      "source": [
        "#@title ListAssets\n",
        "#@markdown For your enterprise, given the specified artifact, list all the assets that accessed it within the specified time period, including the first and last time those assets accessed the artifact. This call returns a maximum of 100 assets per request. You can specify a narrower time period to reduce the number of assets returned.\n",
        "\n",
        "#@markdown Specify the maximum number of assets to return. You can specify between 1 and 10,000. The default is 10,000.\n",
        "page_size =  100#@param {type:\"integer\"}\n",
        "# page_token = \"\" #@param {type: \"string\"}\n",
        "startDate = \"2024-10-28\" #@param {type: \"date\"}\n",
        "endDate = \"2024-10-28\" #@param {type: \"date\"}\n",
        "\n",
        "#@markdown Time should be in the format HH:MM:SS including leading zeros\n",
        "startTime = \"03:00:01\" #@param {type: \"string\"}\n",
        "endTime = \"05:00:00\" #@param {type: \"string\"}\n",
        "\n",
        "startTime = f\"{startDate}T{startTime}Z\"\n",
        "endTime = f\"{endDate}T{endTime}Z\"\n",
        "\n",
        "artifact_type = \"domain_name\" #@param [\"domain_name\", \"destination_ip_address\", \"hash_md5\", \"hash_sha1\", \"hash_sha256\"]\n",
        "artifact_value = 'teamazimut.com' #@param {type : \"string\"}\n",
        "\n",
        "write_to_file = False #@param {type: \"boolean\"}\n",
        "#@markdown If writing to file should data also be displayed on screen?\n",
        "also_output_to_screen = True #@param {type: \"boolean\"}\n",
        "#@markdown If the write to file option is selected specify the filename to write data to.\n",
        "filename = \"assets.json\" #@param {type: \"string\"}\n",
        "\n",
        "url_params = {}\n",
        "url_params[f\"artifact.{artifact_type}\"] = artifact_value\n",
        "url_params[\"start_time\"] = startTime\n",
        "url_params[\"end_time\"] = endTime\n",
        "\n",
        "url_params['page_size'] = page_size\n",
        "encoded_url_params = urlencode(url_params)\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v1/artifact/listassets?{encoded_url_params}\"\n",
        "resp = http_client.request(uri_to_post, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  # pprint(json_resp)\n",
        "  if write_to_file:\n",
        "    with open(filename, \"w\") as output_file:\n",
        "      if \"assets\" in json_resp.keys():\n",
        "        output_file.write(json.dumps(json_resp))\n",
        "        print(f\"Wrote {len(json_resp['assets'])} assets to {filename}\")\n",
        "        if also_output_to_screen:\n",
        "          pprint(json_resp)\n",
        "      else:\n",
        "        print(\"No assets were returned for this query.\")\n",
        "  else:\n",
        "    pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "umMkG-qNWpY5"
      },
      "outputs": [],
      "source": [
        "#@title ListAssetAliases\n",
        "#@markdown Lists all the aliases of an asset in an enterprise for the specified asset identifier and time period.\n",
        "\n",
        "\n",
        "\n",
        "#@markdown Specify the maximum number of assets to return. You can specify between 1 and 10,000. The default is 10,000.\n",
        "page_size =  100#@param {type:\"integer\"}\n",
        "# page_token = \"\" #@param {type: \"string\"}\n",
        "startDate = \"2022-11-01\" #@param {type: \"date\"}\n",
        "endDate = \"2022-11-03\" #@param {type: \"date\"}\n",
        "\n",
        "#@markdown Time should be in the format HH:MM:SS including leading zeros\n",
        "startTime = \"00:00:01\" #@param {type: \"string\"}\n",
        "endTime = \"23:59:59\" #@param {type: \"string\"}\n",
        "\n",
        "startTime = f\"{startDate}T{startTime}Z\"\n",
        "endTime = f\"{endDate}T{endTime}Z\"\n",
        "\n",
        "asset_type = \"hostname\" #@param [\"hostname\", \"asset_ip_address\", \"mac\", \"product_id\"]\n",
        "asset_value = 'google.com' #@param {type : \"string\"}\n",
        "\n",
        "write_to_file = False #@param {type: \"boolean\"}\n",
        "#@markdown If writing to file should data also be displayed on screen?\n",
        "also_output_to_screen = False #@param {type: \"boolean\"}\n",
        "#@markdown If the write to file option is selected specify the filename to write data to.\n",
        "filename = \"assets.json\" #@param {type: \"string\"}\n",
        "\n",
        "url_params = {}\n",
        "url_params[f\"asset.{asset_type}\"] = asset_value\n",
        "url_params[\"start_time\"] = startTime\n",
        "url_params[\"end_time\"] = endTime\n",
        "\n",
        "url_params['page_size'] = page_size\n",
        "encoded_url_params = urlencode(url_params)\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v1/alias/listassetaliases?{encoded_url_params}\"\n",
        "resp = http_client.request(uri_to_post, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  # pprint(json_resp)\n",
        "  if write_to_file:\n",
        "    with open(filename, \"w\") as output_file:\n",
        "      if \"assets\" in json_resp.keys():\n",
        "        output_file.write(json.dumps(json_resp))\n",
        "        print(f\"Wrote {len(json_resp['assets'])} assets to {filename}\")\n",
        "        if also_output_to_screen:\n",
        "          pprint(json_resp)\n",
        "      else:\n",
        "        print(\"No assets were returned for this query.\")\n",
        "  else:\n",
        "    pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "b8FG9MRt_Qn-"
      },
      "outputs": [],
      "source": [
        "#@title ListEvents\n",
        "#@markdown List all the events discovered within your enterprise on a particular device within the specified time range. If you receive the maximum number of events you specified using the page_size parameter (or 10,000, the default), there might still be more events within your Chronicle account. You can narrow the time range and issue the call again to ensure you have visibility into all possible events.\n",
        "\n",
        "#@markdown Specify the maximum number of events to return. You can specify between 1 and 10,000. The default is 10,000.\n",
        "page_size =  2#@param {type:\"integer\"}\n",
        "# page_token = \"\" #@param {type: \"string\"}\n",
        "\n",
        "startDate = \"2022-11-01\" #@param {type: \"date\"}\n",
        "endDate = \"2022-11-03\" #@param {type: \"date\"}\n",
        "referenceDate = \"2022-11-03\" #@param {type: \"date\"}\n",
        "\n",
        "#@markdown Time should be in the format HH:MM:SS including leading zeros\n",
        "startTime = \"00:00:01\" #@param {type: \"string\"}\n",
        "endTime = \"23:59:59\" #@param {type: \"string\"}\n",
        "referenceTime = \"00:00:12\" #@param {type: \"string\"}\n",
        "\n",
        "startTime = f\"{startDate}T{startTime}Z\"\n",
        "endTime = f\"{endDate}T{endTime}Z\"\n",
        "referenceTime = f\"{referenceTime}T{referenceTime}Z\"\n",
        "\n",
        "asset_type = \"mac_address\" #@param [\"hostname\", \"asset_ip_address\", \"mac_address\", \"product_id\"]\n",
        "asset_value = '1c:a0:b8:75:ce:f4' #@param {type : \"string\"}\n",
        "\n",
        "write_to_file = False #@param {type: \"boolean\"}\n",
        "#@markdown If writing to file should data also be displayed on screen?\n",
        "also_output_to_screen = False #@param {type: \"boolean\"}\n",
        "#@markdown If the write to file option is selected specify the filename to write data to.\n",
        "filename = \"events.json\" #@param {type: \"string\"}\n",
        "\n",
        "url_params = {}\n",
        "url_params[f\"asset.{asset_type}\"] = asset_value\n",
        "url_params[\"start_time\"] = startTime\n",
        "url_params[\"end_time\"] = endTime\n",
        "url_params[\"reference_time\"] = referenceTime\n",
        "\n",
        "url_params['page_size'] = page_size\n",
        "encoded_url_params = urlencode(url_params)\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v1/asset/listevents?{encoded_url_params}\"\n",
        "resp = http_client.request(uri_to_post, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  # pprint(json_resp)\n",
        "  if write_to_file:\n",
        "    with open(filename, \"w\") as output_file:\n",
        "      if \"events\" in json_resp.keys():\n",
        "        output_file.write(json.dumps(json_resp))\n",
        "        print(f\"Wrote {len(json_resp['events'])} events to {filename}\")\n",
        "        if also_output_to_screen:\n",
        "          pprint(json_resp)\n",
        "      else:\n",
        "        print(\"No events were returned for this query.\")\n",
        "  else:\n",
        "    pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rVLpkQIDC28g"
      },
      "outputs": [],
      "source": [
        "#@title ListIoCs\n",
        "#@markdown List all the IoCs discovered within your enterprise within the specified time range. If you receive the maximum number of IoCs you specified using the page_size parameter (or 10,000, the default), there might still be more IoCs discovered in your Chronicle account. You might want to narrow the time range and issue the call again to ensure you have visibility on all possible IoCs.\n",
        "\n",
        "#@markdown Specify the maximum number of IoCs to return. You can specify between 1 and 10,000. The default is 10,000.\n",
        "page_size =  10#@param {type:\"integer\"}\n",
        "# page_token = \"\" #@param {type: \"string\"}\n",
        "startDate = \"2024-10-28\" #@param {type: \"date\"}\n",
        "\n",
        "#@markdown Time should be in the format HH:MM:SS including leading zeros\n",
        "startTime = \"03:00:01\" #@param {type: \"string\"}\n",
        "\n",
        "startTime = f\"{startDate}T{startTime}Z\"\n",
        "\n",
        "write_to_file = False #@param {type: \"boolean\"}\n",
        "#@markdown If writing to file should data also be displayed on screen?\n",
        "also_output_to_screen = True #@param {type: \"boolean\"}\n",
        "#@markdown If the write to file option is selected specify the filename to write data to.\n",
        "filename = \"iocs.json\" #@param {type: \"string\"}\n",
        "\n",
        "url_params = {}\n",
        "url_params[\"start_time\"] = startTime\n",
        "url_params['page_size'] = page_size\n",
        "encoded_url_params = urlencode(url_params)\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v1/ioc/listiocs?{encoded_url_params}\"\n",
        "resp = http_client.request(uri_to_post, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  # pprint(json_resp)\n",
        "  if write_to_file:\n",
        "    with open(filename, \"w\") as output_file:\n",
        "      if \"response\" in json_resp.keys() and \"matches\" in json_resp[\"response\"].keys():\n",
        "        output_file.write(json.dumps(json_resp))\n",
        "        print(f\"Wrote {len(json_resp['response']['matches'])} IoCs to {filename}\")\n",
        "        if also_output_to_screen:\n",
        "          pprint(json_resp)\n",
        "      else:\n",
        "        print(\"No events were returned for this query.\")\n",
        "  else:\n",
        "    pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5XaLOEAvPqeh"
      },
      "outputs": [],
      "source": [
        "#@title ListIoCDetails\n",
        "#@markdown Use this method to submit an artifact indicator and return any threat intelligence associated with that artifact. The threat intelligence information is drawn from your enterprise security systems and from Google's IoC partners (for example, the DHS threat feed).\n",
        "\n",
        "artifact_type = \"destination_ip_address\" #@param [\"domain_name\", \"destination_ip_address\"]\n",
        "artifact_value = '71.6.199.23' #@param {type : \"string\"}\n",
        "\n",
        "write_to_file = False #@param {type: \"boolean\"}\n",
        "#@markdown If writing to file should data also be displayed on screen?\n",
        "also_output_to_screen = False #@param {type: \"boolean\"}\n",
        "#@markdown If the write to file option is selected specify the filename to write data to.\n",
        "filename = \"IoCdetails.json\" #@param {type: \"string\"}\n",
        "\n",
        "url_params = {}\n",
        "url_params[f\"artifact.{artifact_type}\"] = artifact_value\n",
        "\n",
        "encoded_url_params = urlencode(url_params)\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v1/artifact/listiocdetails?{encoded_url_params}\"\n",
        "resp = http_client.request(uri_to_post, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  # pprint(json_resp)\n",
        "  if write_to_file:\n",
        "    with open(filename, \"w\") as output_file:\n",
        "      if \"sources\" in json_resp.keys():\n",
        "        output_file.write(json.dumps(json_resp))\n",
        "        print(f\"Wrote {len(json_resp['sources'])} IoC detail(s) to {filename}\")\n",
        "        if also_output_to_screen:\n",
        "          pprint(json_resp)\n",
        "      else:\n",
        "        print(\"No IoC Details were returned for this query.\")\n",
        "  else:\n",
        "    pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "F2sZ_IwfZkIA"
      },
      "outputs": [],
      "source": [
        "#@title ListUserAliases\n",
        "#@markdown Lists all the aliases of a user in an enterprise for a specified user identifier and time period.\n",
        "\n",
        "user_type = \"username\" #@param [\"email\", \"username\", \"windows_sid\", \"employee_id\", \"product_object_id\"]\n",
        "user_value = 'bob' #@param {type : \"string\"}\n",
        "\n",
        "startDate = \"2022-11-01\" #@param {type: \"date\"}\n",
        "endDate = \"2022-11-03\" #@param {type: \"date\"}\n",
        "\n",
        "#@markdown Time should be in the format HH:MM:SS including leading zeros\n",
        "startTime = \"00:00:01\" #@param {type: \"string\"}\n",
        "endTime = \"23:59:59\" #@param {type: \"string\"}\n",
        "\n",
        "startTime = f\"{startDate}T{startTime}Z\"\n",
        "endTime = f\"{endDate}T{endTime}Z\"\n",
        "\n",
        "write_to_file = False #@param {type: \"boolean\"}\n",
        "#@markdown If writing to file should data also be displayed on screen?\n",
        "also_output_to_screen = False #@param {type: \"boolean\"}\n",
        "#@markdown If the write to file option is selected specify the filename to write data to.\n",
        "filename = \"IoCdetails.json\" #@param {type: \"string\"}\n",
        "\n",
        "url_params = {}\n",
        "url_params[f\"user.{user_type}\"] = user_value\n",
        "url_params[\"start_time\"] = startTime\n",
        "url_params[\"end_time\"] = endTime\n",
        "\n",
        "encoded_url_params = urlencode(url_params)\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v1/alias/listuseraliases?{encoded_url_params}\"\n",
        "resp = http_client.request(uri_to_post, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  # pprint(json_resp)\n",
        "  if write_to_file:\n",
        "    with open(filename, \"w\") as output_file:\n",
        "      if \"sources\" in json_resp.keys():\n",
        "        output_file.write(json.dumps(json_resp))\n",
        "        print(f\"Wrote {len(json_resp['sources'])} IoC detail(s) to {filename}\")\n",
        "        if also_output_to_screen:\n",
        "          pprint(json_resp)\n",
        "      else:\n",
        "        print(\"No IoC Details were returned for this query.\")\n",
        "  else:\n",
        "    pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KhSHUjub38K0"
      },
      "outputs": [],
      "source": [
        "#@title udmSearch\n",
        "#@markdown Preview UDM search API\n",
        "\n",
        "udm_query = \" target.ip != \\\"\\\"   match:     principal.ip   outcome:     $sent_bytes = sum(network.sent_bytes)\" #@param {type: \"string\"}\n",
        "limit =  100#@param {type:\"integer\"}\n",
        "# page_token = \"\" #@param {type: \"string\"}\n",
        "startDate = \"2024-09-01\" #@param {type: \"date\"}\n",
        "endDate = \"2024-09-04\" #@param {type: \"date\"}\n",
        "\n",
        "#@markdown Time should be in the format HH:MM:SS including leading zeros\n",
        "startTime = \"00:00:01\" #@param {type: \"string\"}\n",
        "endTime = \"23:59:59\" #@param {type: \"string\"}\n",
        "\n",
        "startTime = f\"{startDate}T{startTime}Z\"\n",
        "endTime = f\"{endDate}T{endTime}Z\"\n",
        "\n",
        "write_to_file = False #@param {type: \"boolean\"}\n",
        "#@markdown If writing to file should data also be displayed on screen?\n",
        "also_output_to_screen = False #@param {type: \"boolean\"}\n",
        "#@markdown If the write to file option is selected specify the filename to write data to.\n",
        "filename = \"udm_query.json\" #@param {type: \"string\"}\n",
        "\n",
        "url_params = {}\n",
        "url_params[\"time_range.start_time\"] = startTime\n",
        "url_params[\"time_range.end_time\"] = endTime\n",
        "url_params['query'] = udm_query\n",
        "\n",
        "\n",
        "url_params['limit'] = limit\n",
        "# encoded_url_params = urlencode(url_params)\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v1/events:udmSearch\"\n",
        "resp = session.get(uri_to_post,params=url_params, timeout=601)\n",
        "# json_resp = json.loads(resp[1])\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  # pprint(json_resp)\n",
        "  if write_to_file:\n",
        "    with open(filename, \"w\") as output_file:\n",
        "      output_file.write(resp.text)\n",
        "    if also_output_to_screen:\n",
        "      pprint(resp.json())\n",
        "  else:\n",
        "    pprint(resp.json())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMvpcTZ3b-Ij"
      },
      "source": [
        "#Reference List API\n",
        "Documentation can be found [here](https://cloud.google.com/chronicle/docs/preview/reference-lists/reference-lists-api)\n",
        "\n",
        "[Jump to top](#scrollTo=v0jKbGj8ZZRB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "05iFv2o0cMOz"
      },
      "outputs": [],
      "source": [
        "#@title CreateReferenceList\n",
        "#@markdown Creates a list.\n",
        "\n",
        "name = \"test123\" #@param {type : \"string\"}\n",
        "description = \"I am a\" #@param {type : \"string\"}\n",
        "\n",
        "#@markdown Please specify a comma separated list of lines to add to this list.\n",
        "lines = \"1,2,3,4,5, sdfdsbsdfds    , 6\" #@param {type : \"string\"}\n",
        "content_type = \"CONTENT_TYPE_DEFAULT_STRING\" #@param [\"CONTENT_TYPE_DEFAULT_STRING\", \"REGEX\", \"CIDR\"]\n",
        "\n",
        "#@markdown If checked the uploaded file will be used instead of the lines variable above. New lines will be used as separators\n",
        "upload_list = False #@param {type: \"boolean\"}\n",
        "\n",
        "if upload_list:\n",
        "  print(\"Please select your list to upload\")\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  list_filename = list(uploaded.keys())[0]\n",
        "\n",
        "  with open(list_filename, \"r\") as list_file:\n",
        "    ref_list = [x.strip() for x in list_file.read().split(\"\\n\")]\n",
        "else:\n",
        "  ref_list = [x.strip() for x in lines.split(\",\")]\n",
        "\n",
        "request_body = {\n",
        "  \"name\": name,\n",
        "  \"description\": description,\n",
        "  \"lines\": ref_list,\n",
        "  \"content_type\": content_type\n",
        "}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/lists\"\n",
        "resp = http_client.request(uri_to_post, \"POST\", body=json.dumps(request_body))\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xjlz4V5zdcvV"
      },
      "outputs": [],
      "source": [
        "#@title GetReferenceList\n",
        "#@markdown Returns the specified list.\n",
        "\n",
        "name = \"test123\" #@param {type : \"string\"}\n",
        "\n",
        "## @markdown How much of each reference list to view. BASIC returns the metadata for the list, but not the full contents. FULL returns everything. FULL is the default.\n",
        "\n",
        "# uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/lists/{name}\"\n",
        "# resp = http_client.request(uri_to_post, \"GET\")\n",
        "# json_resp = json.loads(resp[1])\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/lists/{name}\"\n",
        "resp = session.get(uri_to_post)\n",
        "json_resp = resp.json()\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "t6lSKUeZeBU5"
      },
      "outputs": [],
      "source": [
        "#@title ListReferenceLists\n",
        "#@markdown Enumerates lists.\n",
        "\n",
        "#@markdown How much of each reference list to view. BASIC returns the metadata for the list, but not the full contents. FULL returns everything. FULL is the default.\n",
        "view = \"BASIC\" #@param [\"FULL\", \"BASIC\"]\n",
        "#@markdown Maximum number of lists to return in this page of reference lists. The default is 100.\n",
        "page_size = 1000 #@param {type: \"integer\"}\n",
        "#@markdown Page token, copied from a previous response, enabling you paginate through lists, starting from where the previous page left off.\n",
        "page_token = \"\" #@param {type: \"string\"}\n",
        "\n",
        "url_params = {\n",
        "  \"page_size\": page_size,\n",
        "  \"view\": view,\n",
        "}\n",
        "\n",
        "if page_token:\n",
        "  url_params[\"page_token\"] = page_token\n",
        "\n",
        "encoded_url_params = urlencode(url_params)\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/lists?{encoded_url_params}\"\n",
        "# resp = http_client.request(uri_to_post, \"GET\", body=json.dumps(request_body))\n",
        "resp = http_client.request(uri_to_post, \"GET\")\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1PIPCxStDqSO"
      },
      "outputs": [],
      "source": [
        "#@title UpdateReferenceList\n",
        "#@markdown Updates an existing list.\n",
        "\n",
        "name = \"home_subnest\" #@param {type : \"string\"}\n",
        "description = \"\" #@param {type : \"string\"}\n",
        "content_type = \"CIDR\" #@param [\"CONTENT_TYPE_DEFAULT_STRING\", \"REGEX\", \"CIDR\"]\n",
        "\n",
        "#@markdown Please specify a comma separated list of lines to add to this list.\n",
        "lines = \"10.53.0.0/24,10.53.10.0/23,192.168.0.0/24\" #@param {type : \"string\"}\n",
        "\n",
        "#@markdown If checked the uploaded file will be used instead of the lines variable above. New lines will be used as separators\n",
        "upload_list = False #@param {type: \"boolean\"}\n",
        "\n",
        "if upload_list:\n",
        "  print(\"Please select your list to upload\")\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  list_filename = list(uploaded.keys())[0]\n",
        "\n",
        "  with open(list_filename, \"r\") as list_file:\n",
        "    ref_list = [x.strip() for x in list_file.read().split(\"\\n\")]\n",
        "else:\n",
        "  ref_list = [x.strip() for x in lines.split(\",\")]\n",
        "\n",
        "request_body = {\n",
        "  \"name\": name,\n",
        "  \"lines\": ref_list,\n",
        "  \"content_type\": content_type\n",
        "}\n",
        "\n",
        "update_fields = [\"list.lines\"]\n",
        "\n",
        "if description:\n",
        "  update_fields.append(\"list.description\")\n",
        "  request_body[\"description\"] = description\n",
        "\n",
        "url_params = {\n",
        "  \"update_mask\": \",\".join(update_fields)\n",
        "}\n",
        "\n",
        "encoded_url_params = urlencode(url_params)\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/lists?{encoded_url_params}\"\n",
        "resp = http_client.request(uri_to_post, \"PATCH\", body=json.dumps(request_body))\n",
        "json_resp = json.loads(resp[1])\n",
        "if resp[0].status != http.HTTPStatus.OK:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vY-hX3wGp6LH"
      },
      "outputs": [],
      "source": [
        "#@title VerifyReferenceList\n",
        "#@markdown Validates list content and returns line errors, if any.\n",
        "\n",
        "#@markdown Please specify a comma separated list of lines to verify.\n",
        "lines = \"1,2,3,4,5, sdfdsbsdfds   , 6\" #@param {type : \"string\"}\n",
        "content_type = \"REGEX\" #@param [\"CONTENT_TYPE_DEFAULT_STRING\", \"REGEX\", \"CIDR\"]\n",
        "\n",
        "#@markdown If checked the uploaded file will be used instead of the lines variable above. New lines will be used as separators\n",
        "upload_list = False #@param {type: \"boolean\"}\n",
        "\n",
        "if upload_list:\n",
        "  print(\"Please select your list to upload\")\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  list_filename = list(uploaded.keys())[0]\n",
        "\n",
        "  with open(list_filename, \"r\") as list_file:\n",
        "    ref_list = [x.strip() for x in list_file.read().split(\"\\n\")]\n",
        "else:\n",
        "  ref_list = [x.strip() for x in lines.split(\",\")]\n",
        "\n",
        "request_body = {\n",
        "  \"lines\": ref_list,\n",
        "  \"content_type\": content_type\n",
        "}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/lists:verifyReferenceList\"\n",
        "resp = session.post(uri_to_post, json=request_body)\n",
        "json_resp = resp.json()\n",
        "if resp.status_code > 299:\n",
        "  pprint(json_resp.get('error').get('message'))\n",
        "else:\n",
        "  pprint(json_resp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Export API\n",
        "Documentation [link](https://cloud.google.com/chronicle/docs/preview/data-export-api/data-export-api)\n",
        "\n",
        "[Jump to top](#scrollTo=v0jKbGj8ZZRB)"
      ],
      "metadata": {
        "id": "q5xxRkQL2OM-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DXT-YVi52vq8"
      },
      "outputs": [],
      "source": [
        "#@title CreateDataExport\n",
        "#@markdown Creates a new data export.\n",
        "\n",
        "#@markdown Dates/Times are in UTC\n",
        "\n",
        "startDate = \"2025-01-15\" #@param {type: \"date\"}\n",
        "endDate = \"2025-01-30\" #@param {type: \"date\"}\n",
        "#@markdown Time should be in the format HH:MM:SS including leading zeros\n",
        "startTime = \"00:00:01\" #@param {type: \"string\"}\n",
        "endTime = \"23:59:59\" #@param {type: \"string\"}\n",
        "\n",
        "startTime = f\"{startDate}T{startTime}Z\"\n",
        "endTime = f\"{endDate}T{endTime}Z\"\n",
        "\n",
        "#@markdown An individual log type or 'ALL_TYPES' for all log types\n",
        "logType = \"ALL_TYPES\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Path to the customer-provided Google Cloud Storage bucket in projects/\\<project-id\\>/buckets/\\<bucket-name\\>\" format\n",
        "gcsBucket = \"projects/learning-sql-363317/buckets/data_export_api_target\" #@param {type: \"string\"}\n",
        "\n",
        "\n",
        "\n",
        "body = {\n",
        "  \"startTime\": startTime,\n",
        "  \"endTime\": endTime,\n",
        "  \"logType\": logType,\n",
        "  \"gcsBucket\": gcsBucket,\n",
        "}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v1/tools/dataexport\"\n",
        "resp = session.post(uri_to_post, json=body)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GPUt0M5GkPID"
      },
      "outputs": [],
      "source": [
        "#@title GetDataExport\n",
        "#@markdown Returns an existing data export.\n",
        "\n",
        "dataExportId = \"73dccbe4-fae2-4208-80a8-dc62b9e1b7a8\" #@param {type: \"string\"}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v1/tools/dataexport/{dataExportId}\"\n",
        "resp = session.get(uri_to_post)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OaSvqiV2lJxY"
      },
      "outputs": [],
      "source": [
        "#@title CancelDataExport\n",
        "#@markdown Cancels an existing data export request.\n",
        "\n",
        "#@markdown Note: Only IN_QUEUE data exports can be canceled.\n",
        "\n",
        "dataExportId = \"47d6ff7f-503e-4c31-9a5a-73ddc17bf986\" #@param {type: \"string\"}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v1/tools/dataexport/{dataExportId}:cancel\"\n",
        "resp = session.post(uri_to_post)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWuwZXdRlduS",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ListAvailableLogTypes\n",
        "#@markdown List all available log types and their time range.\n",
        "\n",
        "#@markdown A time range is optional. If not specified, the value is UNIX epoch time starting on January 1st, 1970 at UTC.\n",
        "include_time_range = True #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown Dates/Times are in UTC\n",
        "\n",
        "startDate = \"2025-01-01\" #@param {type: \"date\"}\n",
        "endDate = \"2025-01-29\" #@param {type: \"date\"}\n",
        "#@markdown Time should be in the format HH:MM:SS including leading zeros\n",
        "startTime = \"01:00:00\" #@param {type: \"string\"}\n",
        "endTime = \"23:59:59\" #@param {type: \"string\"}\n",
        "\n",
        "startTime = f\"{startDate}T{startTime}Z\"\n",
        "endTime = f\"{endDate}T{endTime}Z\"\n",
        "\n",
        "\n",
        "parameters = {\n",
        "  \"startTime\": startTime,\n",
        "  \"endTime\": endTime\n",
        "}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v1/tools/dataexport/listavailablelogtypes\"\n",
        "if include_time_range:\n",
        "  resp = session.get(uri_to_post, params=parameters)\n",
        "else:\n",
        "  resp = session.get(uri_to_post)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DataTap Configuration API\n",
        "Documentation [link](https://cloud.google.com/chronicle/docs/preview/datatap-config/datatapconfig-api)\n",
        "\n",
        "[Jump to top](#scrollTo=v0jKbGj8ZZRB)"
      ],
      "metadata": {
        "id": "MoDoZbCq8P7M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0HlaOouA8ciz"
      },
      "outputs": [],
      "source": [
        "#@title Create\n",
        "#@markdown Creates a DataTap configuration.\n",
        "\n",
        "displayName = \"\" #@param {type: \"string\"}\n",
        "#@markdown Use the following format for the topic: **projects/\\<project_id\\>/topics/\\<topicId\\>**\n",
        "topic = \"\" #@param {type: \"string\"}\n",
        "filter = \"ALERT_UDM_EVENTS\" #@param [\"ALL_UDM_EVENTS\", \"ALERT_UDM_EVENTS\"]\n",
        "serializationFormat = \"JSON\" #@param [\"JSON\", \"MARSHALLED_PROTO\"]\n",
        "\n",
        "body = {\n",
        "  \"displayName\": displayName,\n",
        "  \"cloudPubsubSink\": {\n",
        "    \"topic\": topic,\n",
        "  },\n",
        "  \"filter\": filter,\n",
        "  \"serializationFormat\": serializationFormat\n",
        "}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v1/dataTaps\"\n",
        "resp = session.post(uri_to_post, json=body)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AP4GOSV9qgx",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Update\n",
        "#@markdown Updates a DataTap configuration.\n",
        "\n",
        "tapId =  \"\" #@param {type: \"string\"}\n",
        "displayName = \"\" #@param {type: \"string\"}\n",
        "#@markdown Use the following format for the topic: **projects/\\<project_id\\>/topics/\\<topicId\\>**\n",
        "topic = \"\" #@param {type: \"string\"}\n",
        "filter = \"ALERT_UDM_EVENTS\" #@param [\"ALL_UDM_EVENTS\", \"ALERT_UDM_EVENTS\"]\n",
        "serializationFormat = \"JSON\" #@param [\"JSON\", \"MARSHALLED_PROTO\"]\n",
        "\n",
        "body = {\n",
        "  \"name\" : f\"dataTaps/{tapId}\",\n",
        "  \"displayName\": displayName,\n",
        "  \"cloudPubsubSink\": {\n",
        "    \"topic\": topic,\n",
        "  },\n",
        "  \"filter\": filter,\n",
        "  \"serializationFormat\": serializationFormat\n",
        "}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v1/dataTaps/{tapId}\"\n",
        "resp = session.patch(uri_to_post, json=body)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JSnJVDog_2s7"
      },
      "outputs": [],
      "source": [
        "#@title Delete\n",
        "#@markdown Deletes a DataTap configuration.\n",
        "\n",
        "tapId =  \"\" #@param {type: \"string\"}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v1/dataTaps/{tapId}\"\n",
        "resp = session.delete(uri_to_post)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "c5SsAewZAEGK"
      },
      "outputs": [],
      "source": [
        "#@title Get\n",
        "#@markdown Get a specific DataTap configuration.\n",
        "\n",
        "tapId =  \"\" #@param {type: \"string\"}\n",
        "\n",
        "body = {\n",
        "  \"name\": f\"dataTaps/{tapId}\",\n",
        "}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v1/dataTaps/{tapId}\"\n",
        "resp = session.get(uri_to_post, json=body)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0a07Xa5FAWdK"
      },
      "outputs": [],
      "source": [
        "#@title List\n",
        "#@markdown List all the DataTap configurations of a customer.\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v1/dataTaps\"\n",
        "resp = session.get(uri_to_post)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Forwarder API\n",
        "Documentation [link](https://cloud.google.com/chronicle/docs/install/forwarder-management-api)\n",
        "\n",
        "[Jump to top](#scrollTo=v0jKbGj8ZZRB)"
      ],
      "metadata": {
        "id": "gY3dJhKQRmKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create Forwarder\n",
        "#@markdown Creates a new forwarder in the Chronicle instance. The new forwarder will include any forwarder configuration values provided in the request body. Configuration values for collectors must be specified using Create Collector after using Create Forwarder.\n",
        "\n",
        "#@markdown For certain settings, configuration values that are missing or zero-valued in the request body are set to default values. For details about forwarder fields and values, see [Forwarder configuration fields](https://cloud.google.com/chronicle/docs/preview/forwarder-management-api/forwarder-management-api#forwarder-config-fields).\n",
        "\n",
        "displayName = \"windows-test\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown **[OPTIONAL]** The configuration settings for this forwarder. Please paste a JSON object of the config.\n",
        "\n",
        "#@markdown A helper is included at the bottom of the forwarder API section to help generate this.\n",
        "\n",
        "config = \"\" #@param {type: \"string\"}\n",
        "\n",
        "body = {\n",
        "    \"displayName\" : displayName\n",
        "}\n",
        "\n",
        "if config:\n",
        "  config = json.loads(config)\n",
        "  body['config'] = config\n",
        "\n",
        "\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/forwarders\"\n",
        "\n",
        "# pprint(body)\n",
        "\n",
        "resp = session.post(uri_to_post, json=body)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TaF5K876gIqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get Forwarder\n",
        "#@markdown Returns a forwarder.\n",
        "\n",
        "forwarderID = \"67971dbf-2d52-4251-aefd-c329d1d9bf1a\" #@param {type : \"string\"}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/forwarders/{forwarderID}\"\n",
        "\n",
        "resp = session.get(uri_to_post)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "h8gcq4MgBu3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lQ38HA6iR9Jo"
      },
      "outputs": [],
      "source": [
        "#@title List Forwarders\n",
        "#@markdown Lists all of the forwarders for a Chronicle instance.\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/forwarders\"\n",
        "resp = session.get(uri_to_post)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Update Forwarder\n",
        "#@markdown You can update a forwarder by using the updateMask URL query parameter to specify the fields to update.\n",
        "\n",
        "forwarderID =  \"a2ece8f1-78d5-4d0b-81a0-47fc1a8b3b38\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown If desired specify an updaetd display name\n",
        "updated_display_name = \"I_like_cheese\" #@param {type: \"string\"}\n",
        "#@markdown The updated config should look just like the config for generating a forwarder, but only needs the keys/values that need to be updated and no others.\n",
        "updated_config = \"{\\\"uploadCompression\\\": true, \\\"regexFilters\\\": [{\\\"description\\\": \\\"Just a test of some stuff\\\", \\\"regexp\\\": \\\".*BLOCKME.*\\\", \\\"behavior\\\": \\\"BLOCK\\\"}, {\\\"description\\\": \\\"Just a test of some stuff\\\", \\\"regexp\\\": \\\".*BLOCKMETOO.*\\\", \\\"behavior\\\": \\\"BLOCK\\\"}], \\\"serverSettings\\\": {\\\"state\\\": \\\"ACTIVE\\\", \\\"httpSettings\\\": {\\\"port\\\": 8081}}}\" #@param {type: \"string\"}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/forwarders/{forwarderID}\"\n",
        "\n",
        "def mask_array_gen(path,my_dict,path_array = []):\n",
        "    for k,v in my_dict.items():\n",
        "        if isinstance(v,dict):\n",
        "          if path:\n",
        "            mask_array_gen(path+\".\"+k,v,path_array)\n",
        "          else:\n",
        "            mask_array_gen(k,v,path_array)\n",
        "        else:\n",
        "          if path:\n",
        "            # handle exceptions for repeated fields.\n",
        "            if path.startswith(\"config.regexFilters\"):\n",
        "              if \"config.regexFilters\" not in path_array:\n",
        "                path_array.append(\"config.regexFilters\")\n",
        "            elif path.startswith(\"metadata.labels\"):\n",
        "              if \"metadata.labels\" not in path_array:\n",
        "                path_array.append(\"metadata.labels\")\n",
        "            else:\n",
        "              path_array.append(path + \".\" + k)\n",
        "          else:\n",
        "            path_array.append(k)\n",
        "    return {\"updateMask\" : \",\".join(path_array)}\n",
        "\n",
        "if updated_config:\n",
        "  updated_config = json.loads(updated_config)\n",
        "  params = mask_array_gen(\"config\", updated_config)\n",
        "else:\n",
        "  params = {\n",
        "      \"updateMask\" : \"\"\n",
        "  }\n",
        "\n",
        "if updated_display_name and params[\"updateMask\"]:\n",
        "  params[\"updateMask\"] += \",displayName\"\n",
        "elif updated_display_name:\n",
        "  params[\"updateMask\"] = \"displayName\"\n",
        "\n",
        "payload_body = {}\n",
        "\n",
        "if updated_display_name:\n",
        "  payload_body[\"display_name\"] = updated_display_name\n",
        "\n",
        "if updated_config:\n",
        "  payload_body[\"config\"] = updated_config\n",
        "\n",
        "resp = session.patch(uri_to_post, json=payload_body, params=params)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())"
      ],
      "metadata": {
        "id": "3JWF95YVdc0p",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Delete Forwarder\n",
        "#@markdown Deletes a forwarder.\n",
        "\n",
        "forwarderID = \"e97a8870-24c9-4bac-aa70-2991ae4a3658\" #@param {type : \"string\"}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/forwarders/{forwarderID}\"\n",
        "\n",
        "resp = session.delete(uri_to_post)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9xauAnRPLw0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate Forwarder Files\n",
        "#@markdown Generates and returns the contents of the forwarder's configuration **(.conf)** and authentication **(_auth.conf)** files.\n",
        "\n",
        "forwarderID = \"5e4535c8-651a-49e0-914b-31494df84434\" #@param {type : \"string\"}\n",
        "download_files = True #@param {type: \"boolean\"}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/forwarders/{forwarderID}:generateForwarderFiles\"\n",
        "\n",
        "resp = session.get(uri_to_post)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  if download_files:\n",
        "    if forwarderID in os.listdir():\n",
        "      os.system(f\"rm -rf {forwarderID}\")\n",
        "    os.mkdir(forwarderID)\n",
        "    with open(f\"./{forwarderID}/config.auth\", \"w\") as auth_file:\n",
        "      auth_file.write(resp.json()[\"auth\"])\n",
        "    with open(f\"./{forwarderID}/config.conf\", \"w\") as auth_file:\n",
        "      auth_file.write(resp.json()[\"config\"])\n",
        "    if f\"{forwarderID}.zip\" in os.listdir():\n",
        "      os.remove(f\"{forwarderID}.zip\")\n",
        "    os.system(f\"zip -r {forwarderID}.zip {forwarderID}\")\n",
        "    files.download(f\"{forwarderID}.zip\")\n",
        "    print(f\"{forwarderID}.zip has been downloaded with conig data.\")\n",
        "  else:\n",
        "    pprint(resp.json())\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tPDQPNgNZW9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Forwarder config generation helper\n",
        "\n",
        "The block is folded under this header beacuse it is long and takes a long time to scroll past."
      ],
      "metadata": {
        "id": "t9UYfp3Wf38-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Regex Filter Builder\n",
        "#@markdown This will help build out regex filters for forwarders with multiple regular expressions.\n",
        "\n",
        "\n",
        "#@markdown If **start_clean** is set to true reset the list of regex rules and start from scratch with a clean list.\n",
        "start_clean = False #@param {type: \"boolean\"}\n",
        "if \"regex_array\" not in locals() or start_clean:\n",
        "  regex_array = []\n",
        "\n",
        "#@markdown Describes what is being filtered and why.\n",
        "\n",
        "regexFilters_description = \"Just a test of some stuff\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown The regular expression used to match against each incoming line.\n",
        "\n",
        "regexFilters_regexp = \".*BLOCKMETOO.*\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Specifies the state of the server functionality. Valid values are: **ALLOW**: This state allows the filtered line to be uploaded. **BLOCK**: This state prevents the filtered line from being uploaded.\n",
        "\n",
        "regexFilters_behavior = \"BLOCK\" #@param [\"\", \"ALLOW\", \"BLOCK\"]\n",
        "\n",
        "regex_array.append({\n",
        "    \"description\": regexFilters_description,\n",
        "    \"regexp\": regexFilters_regexp,\n",
        "    \"behavior\": regexFilters_behavior\n",
        "})\n",
        "\n",
        "print(json.dumps(regex_array))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qNIX_UGrW5oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate config\n",
        "#@markdown This is a helper to build out a config for the create forwarder endpoint (and others)\n",
        "\n",
        "#@markdown All fields are optional.\n",
        "\n",
        "#@markdown If true, batches of data are compressed before upload. The default is true.\n",
        "\n",
        "uploadCompression = True #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown The namespace for identifying logs from this forwarder. **Note:** This is a global setting that applies to the forwarder and the forwarder's collectors, unless it is overridden at the collector level.\n",
        "\n",
        "assetNamespace = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown A list of arbitrary key:value pairs that can be specified in the forwarder configuration. **Note:** This is a global setting that applies to the forwarder and the forwarder's collectors, unless it is overridden at the collector level.\n",
        "\n",
        "#@markdown Please enter them in the form **key1:value1,key2:value2...**\n",
        "\n",
        "labels =  \"windows-server\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Paste a regex filter from the Regex Filter Builder in the cell above\n",
        "\n",
        "regexFilters_object = \"\" #@param {type :\"string\"}\n",
        "\n",
        "#@markdown Specifies the state of the server functionality. Valid values are: **ACTIVE**: In this state, server settings are applied as specified. **SUSPENDED** In this state, server settings are not applied.\n",
        "\n",
        "serverSettings_state = \"ACTIVE\" #@param [\"\", \"ACTIVE\", \"SUSPENDED\"]\n",
        "\n",
        "#@markdown The number of seconds after which the forwarder returns a bad readiness/health check and still accepts new connections. This is also the time to wait between receiving a signal to stop and actually beginning the shutdown of the server itself. This allows the load balancer time to remove the forwarder from the pool. The default value is **15**.\n",
        "\n",
        "serverSettings_gracefulTimeout = 0 #@param {type : \"integer\"}\n",
        "\n",
        "#@markdown The number of seconds after which the forwarder waits for active connections to successfully close on their own before being closed by the server. The default value is **10**.\n",
        "\n",
        "serverSettings_drainTimeout =  0 #@param {type : \"integer\"}\n",
        "\n",
        "#@markdown The port number that the HTTP server listens on for health checks from the load balancer. Must be between 1024-65535. The default is **8080**.\n",
        "\n",
        "serverSettings_httpSettings_port = 8081 #@param {type : \"integer\"}\n",
        "\n",
        "#@markdown The IP address, or hostname that can be resolved to IP addresses, that the server should listen to. The default value is 0.0.0.0 (the local system).\n",
        "\n",
        "serverSettings_httpSettings_host = \"\" #@param {type : \"string\"}\n",
        "\n",
        "#@markdown The maximum number of seconds allowed to read entire requests, which includes the header and the body. The default value is **3**.\n",
        "\n",
        "serverSettings_httpSettings_readTimeout = 0 #@param {type: \"integer\"}\n",
        "\n",
        "#@markdown The maximum number of seconds allowed to read request headers. The default value is **3**.\n",
        "\n",
        "serverSettings_httpSettings_readHeaderTimeout = 0 #@param {type: \"integer\"}\n",
        "\n",
        "#@markdown The maximum number of seconds allowed to send a response. The default value is **3**.\n",
        "\n",
        "serverSettings_httpSettings_writeTimeout = 0 #@param {type: \"integer\"}\n",
        "\n",
        "#@markdown The maximum number of seconds to wait for the next request when idle connections are enabled. The default is **3**.\n",
        "\n",
        "serverSettings_httpSettings_idleTimeout = 0 #@param {type: \"integer\"}\n",
        "\n",
        "#@markdown The status code returned when a liveness check is received and the forwarder is available. The default is **204**.\n",
        "\n",
        "serverSettings_routeSettings_availableStatusCode = 0 #@param {type: \"integer\"}\n",
        "\n",
        "#@markdown The status code returned when the forwarder is ready to accept traffic. The default is **204**.\n",
        "\n",
        "serverSettings_routeSettings_readyStatusCode = 0 #@param {type: \"integer\"}\n",
        "\n",
        "#@markdown The status code returned when the forwarder is not ready to accept traffic. The default is **503**.\n",
        "\n",
        "serverSettings_httpSettings_routeSettings_unreadyStatusCode = 0 #@param {type: \"integer\"}\n",
        "\n",
        "config = {}\n",
        "\n",
        "config[\"uploadCompression\"] = uploadCompression\n",
        "\n",
        "if assetNamespace:\n",
        "  if \"metadata\" not in config.keys():\n",
        "    config[\"metadata\"] = {}\n",
        "  config[\"metadata\"][\"assetNamespace\"] = assetNamespace\n",
        "\n",
        "if labels:\n",
        "  if \"metadata\" not in config.keys():\n",
        "    config[\"metadata\"] = {}\n",
        "  config[\"metadata\"]['labels'] = []\n",
        "  labels = labels.split(\",\")\n",
        "\n",
        "  for label in labels:\n",
        "    label = label.strip()\n",
        "    label = label.split(\":\")\n",
        "    config[\"metadata\"]['labels'].append({\"key\" : label[0].strip(), \"value\" : label[1].strip()})\n",
        "\n",
        "if regexFilters_object:\n",
        "  config[\"regexFilters\"] = json.loads(regexFilters_object)\n",
        "\n",
        "# if regexFilters_regexp:\n",
        "#   config[\"regexFilters\"] = {}\n",
        "#   config[\"regexFilters\"][\"regexp\"] = regexFilters_regexp\n",
        "\n",
        "#   if regexFilters_behavior:\n",
        "#     config[\"regexFilters\"][\"behavior\"] = regexFilters_behavior\n",
        "\n",
        "#   if regexFilters_description:\n",
        "#     config[\"regexFilters\"][\"description\"] = regexFilters_description\n",
        "\n",
        "if serverSettings_state:\n",
        "  config[\"serverSettings\"] = {}\n",
        "  config[\"serverSettings\"][\"state\"] = serverSettings_state\n",
        "\n",
        "if serverSettings_gracefulTimeout:\n",
        "  if \"serverSettings\" not in config.keys():\n",
        "    config[\"serverSettings\"] = {}\n",
        "  config[\"serverSettings\"][\"gracefulTimeout\"] = serverSettings_gracefulTimeout\n",
        "\n",
        "if serverSettings_drainTimeout:\n",
        "  if \"serverSettings\" not in config.keys():\n",
        "    config[\"serverSettings\"] = {}\n",
        "  config[\"serverSettings\"][\"drainTimeout\"] = serverSettings_drainTimeout\n",
        "\n",
        "if serverSettings_httpSettings_port:\n",
        "  if \"serverSettings\" not in config.keys():\n",
        "    config[\"serverSettings\"] = {}\n",
        "  if \"httpSettings\" not in config[\"serverSettings\"].keys():\n",
        "    config[\"serverSettings\"][\"httpSettings\"] = {}\n",
        "  config[\"serverSettings\"][\"httpSettings\"][\"port\"] = serverSettings_httpSettings_port\n",
        "\n",
        "if serverSettings_httpSettings_host:\n",
        "  if \"serverSettings\" not in config.keys():\n",
        "    config[\"serverSettings\"] = {}\n",
        "  if \"httpSettings\" not in config[\"serverSettings\"].keys():\n",
        "    config[\"serverSettings\"][\"httpSettings\"] = {}\n",
        "  config[\"serverSettings\"][\"httpSettings\"][\"host\"] = serverSettings_httpSettings_host\n",
        "\n",
        "if serverSettings_httpSettings_readTimeout:\n",
        "  if \"serverSettings\" not in config.keys():\n",
        "    config[\"serverSettings\"] = {}\n",
        "  if \"httpSettings\" not in config[\"serverSettings\"].keys():\n",
        "    config[\"serverSettings\"][\"httpSettings\"] = {}\n",
        "  config[\"serverSettings\"][\"httpSettings\"][\"readTimeout\"] = serverSettings_httpSettings_readTimeout\n",
        "\n",
        "if serverSettings_httpSettings_readHeaderTimeout:\n",
        "  if \"serverSettings\" not in config.keys():\n",
        "    config[\"serverSettings\"] = {}\n",
        "  if \"httpSettings\" not in config[\"serverSettings\"].keys():\n",
        "    config[\"serverSettings\"][\"httpSettings\"] = {}\n",
        "  config[\"serverSettings\"][\"httpSettings\"][\"readHeaderTimeout\"] = serverSettings_httpSettings_readHeaderTimeout\n",
        "\n",
        "if serverSettings_routeSettings_availableStatusCode:\n",
        "  if \"serverSettings\" not in config.keys():\n",
        "    config[\"serverSettings\"] = {}\n",
        "  if \"httpSettings\" not in config[\"serverSettings\"].keys():\n",
        "    config[\"serverSettings\"][\"httpSettings\"] = {}\n",
        "  if \"routeSettings\" not in config[\"serverSettings\"][\"httpSettings\"].keys():\n",
        "    config[\"serverSettings\"][\"httpSettings\"][\"routeSettings\"] = {}\n",
        "  config[\"serverSettings\"][\"httpSettings\"][\"routeSettings\"][\"availableStatusCode\"] = serverSettings_routeSettings_availableStatusCode\n",
        "\n",
        "if serverSettings_routeSettings_readyStatusCode:\n",
        "  if \"serverSettings\" not in config.keys():\n",
        "    config[\"serverSettings\"] = {}\n",
        "  if \"httpSettings\" not in config[\"serverSettings\"].keys():\n",
        "    config[\"serverSettings\"][\"httpSettings\"] = {}\n",
        "  if \"routeSettings\" not in config[\"serverSettings\"][\"httpSettings\"].keys():\n",
        "    config[\"serverSettings\"][\"httpSettings\"][\"routeSettings\"] = {}\n",
        "  config[\"serverSettings\"][\"httpSettings\"][\"routeSettings\"][\"readyStatusCode\"] = serverSettings_routeSettings_readyStatusCode\n",
        "\n",
        "if serverSettings_httpSettings_routeSettings_unreadyStatusCode:\n",
        "  if \"serverSettings\" not in config.keys():\n",
        "    config[\"serverSettings\"] = {}\n",
        "  if \"httpSettings\" not in config[\"serverSettings\"].keys():\n",
        "    config[\"serverSettings\"][\"httpSettings\"] = {}\n",
        "  if \"routeSettings\" not in config[\"serverSettings\"][\"httpSettings\"].keys():\n",
        "    config[\"serverSettings\"][\"httpSettings\"][\"routeSettings\"] = {}\n",
        "  config[\"serverSettings\"][\"httpSettings\"][\"routeSettings\"][\"unreadyStatusCode\"] = serverSettings_httpSettings_routeSettings_unreadyStatusCode\n",
        "\n",
        "\n",
        "print(\"Please copy the output and paste it into the config cell in the appropriate call.\")\n",
        "print(json.dumps(config))"
      ],
      "metadata": {
        "id": "6UQ-atvnhCEm",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Collector API\n",
        "\n",
        "Same doc as the forwader API, but [doc link](https://cloud.google.com/chronicle/docs/preview/forwarder-management-api/forwarder-management-api#collector_api_reference) for completness.\n",
        "\n",
        "[Jump to top](#scrollTo=v0jKbGj8ZZRB)"
      ],
      "metadata": {
        "id": "bdE3Nw4Yd6Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create Collector\n",
        "#@markdown Creates a new collector in the Chronicle account. Configuration values for collectors must be specified using Create Collector after using Create Forwarder.\n",
        "\n",
        "#@markdown For certain settings, configuration values that are missing or zero-valued in the request body are set to default values. For details about collector configuration fields and values, see [Collector configuration fields](https://cloud.google.com/chronicle/docs/preview/forwarder-management-api/forwarder-management-api#collector-config-fields).\n",
        "\n",
        "#@markdown The forawrder ID on which to create the collector.\n",
        "forwarderID = \"5daf55a9-74ee-4c99-816d-1506e5e5f426\" #@param {type: \"string\"}\n",
        "\n",
        "displayName = \"windows_syslog_listener\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown **[OPTIONAL]** The configuration settings for this collector. Please paste a JSON object of the config.\n",
        "\n",
        "#@markdown A helper is included at the bottom of the collector API section to help generate this.\n",
        "\n",
        "config = \"{\\\"logType\\\": \\\"BOX\\\", \\\"syslogSettings\\\": {\\\"protocol\\\": \\\"UDP\\\", \\\"address\\\": \\\"0.0.0.0\\\", \\\"port\\\": 10514}}\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Specifies the current state of the collector. Valid values are:\n",
        "state = \"ACTIVE\" #@param [\"\", \"ACTIVE\", \"SUSPENDED\"]\n",
        "body = {\n",
        "    \"displayName\" : displayName\n",
        "}\n",
        "\n",
        "if config:\n",
        "  config = json.loads(config)\n",
        "  body['config'] = config\n",
        "\n",
        "\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/forwarders/{forwarderID}/collectors\"\n",
        "\n",
        "# pprint(body)\n",
        "\n",
        "resp = session.post(uri_to_post, json=body)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ay2EGHtyaDhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get Collector\n",
        "#@markdown Returns a collector.\n",
        "\n",
        "forwarderID = \"b34cab48-2a22-4897-8747-3580eff0dd36\" #@param {type : \"string\"}\n",
        "collectorID = \"\" #@param {type : \"string\"}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/forwarders/{forwarderID}/collectors/{collectorID}\"\n",
        "\n",
        "resp = session.get(uri_to_post)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LtaUU5F4a1Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title List Collectors\n",
        "#@markdown Lists the existing collectors for the specified forwarder.\n",
        "\n",
        "forwarderID = \"a2ece8f1-78d5-4d0b-81a0-47fc1a8b3b38\" #@param {type : \"string\"}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/forwarders/{forwarderID}/collectors\"\n",
        "\n",
        "resp = session.get(uri_to_post)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZrImvbqXbJ9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Update Collector\n",
        "\n",
        "forwarderID =  \"a2ece8f1-78d5-4d0b-81a0-47fc1a8b3b38\" #@param {type: \"string\"}\n",
        "collectorID = \"670a1475-fccb-4f30-88e7-9f0951a2b4d9\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown The updated config should look just like the config for generating a forwarder, but only needs the keys/values that need to be updated and no others.\n",
        "updated_display_name = \"swiss\" #@param {type:\"string\"}\n",
        "updated_config = \"{\\\"logType\\\": \\\"D3_BANKING\\\", \\\"regexFilters\\\": [{\\\"description\\\": \\\"Just a test of some stuff\\\", \\\"regexp\\\": \\\".*BLOCKME.*\\\", \\\"behavior\\\": \\\"BLOCK\\\"}, {\\\"description\\\": \\\"Just a test of some stuff\\\", \\\"regexp\\\": \\\".*BLOCKMETOO.*\\\", \\\"behavior\\\": \\\"BLOCK\\\"}]}\" #@param {type: \"string\"}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/forwarders/{forwarderID}/collectors/{collectorID}\"\n",
        "\n",
        "def mask_array_gen(path,my_dict,path_array = []):\n",
        "    for k,v in my_dict.items():\n",
        "        if isinstance(v,dict):\n",
        "          if path:\n",
        "            mask_array_gen(path+\".\"+k,v,path_array)\n",
        "          else:\n",
        "            mask_array_gen(k,v,path_array)\n",
        "        else:\n",
        "          if path:\n",
        "            # handle exceptions for repeated fields.\n",
        "            if path.startswith(\"config.regexFilters\"):\n",
        "              if \"config.regexFilters\" not in path_array:\n",
        "                path_array.append(\"config.regexFilters\")\n",
        "            elif path.startswith(\"metadata.labels\"):\n",
        "              if \"metadata.labels\" not in path_array:\n",
        "                path_array.append(\"metadata.labels\")\n",
        "            else:\n",
        "              path_array.append(path + \".\" + k)\n",
        "          else:\n",
        "            path_array.append(k)\n",
        "    return {\"updateMask\" : \",\".join(path_array)}\n",
        "\n",
        "if updated_config:\n",
        "  updated_config = json.loads(updated_config)\n",
        "  params = mask_array_gen(\"config\", updated_config)\n",
        "else:\n",
        "  params = {\n",
        "      \"updateMask\" : \"\"\n",
        "  }\n",
        "\n",
        "if updated_display_name and params[\"updateMask\"]:\n",
        "  params[\"updateMask\"] += \",displayName\"\n",
        "elif updated_display_name:\n",
        "  params[\"updateMask\"] = \"displayName\"\n",
        "\n",
        "payload_body = {}\n",
        "\n",
        "if updated_display_name:\n",
        "  payload_body[\"display_name\"] = updated_display_name\n",
        "\n",
        "if updated_config:\n",
        "  payload_body[\"config\"] = updated_config\n",
        "\n",
        "\n",
        "resp = session.patch(uri_to_post, json=payload_body, params=params)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "x20Kkk_rqzP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Delete Collector\n",
        "#@markdown Deletes a collector.\n",
        "\n",
        "forwarderID = \"a2ece8f1-78d5-4d0b-81a0-47fc1a8b3b38\" #@param {type : \"string\"}\n",
        "collectorID = \"5882a551-b8fd-47fc-9d6f-f1526b3f2082\" #@param {type : \"string\"}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v2/forwarders/{forwarderID}/collectors/{collectorID}\"\n",
        "\n",
        "resp = session.delete(uri_to_post)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eLKig_B5bgEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Collector config generation helper\n",
        "\n",
        "The block is folded under this header beacuse it is long and takes a long time to scroll past."
      ],
      "metadata": {
        "id": "80VTSSvBgtUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Regex Filter Builder\n",
        "#@markdown This will help build out regex filters for collectors with multiple regular expressions.\n",
        "\n",
        "\n",
        "#@markdown If **start_clean** is set to true reset the list of regex rules and start from scratch with a clean list.\n",
        "start_clean = False #@param {type: \"boolean\"}\n",
        "if \"regex_array\" not in locals() or start_clean:\n",
        "  regex_array = []\n",
        "\n",
        "#@markdown Describes what is being filtered and why.\n",
        "\n",
        "regexFilters_description = \"Just a test of some stuff\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown The regular expression used to match against each incoming line.\n",
        "\n",
        "regexFilters_regexp = \".*BLOCKMETOO.*\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Specifies the state of the server functionality. Valid values are: **ALLOW**: This state allows the filtered line to be uploaded. **BLOCK**: This state prevents the filtered line from being uploaded.\n",
        "\n",
        "regexFilters_behavior = \"BLOCK\" #@param [\"\", \"ALLOW\", \"BLOCK\"]\n",
        "\n",
        "regex_array.append({\n",
        "    \"description\": regexFilters_description,\n",
        "    \"regexp\": regexFilters_regexp,\n",
        "    \"behavior\": regexFilters_behavior\n",
        "})\n",
        "\n",
        "print(json.dumps(regex_array))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gxanNKXLeMl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate Collector config\n",
        "#@markdown logtype is a required field\n",
        "logType = \"BOX\" #@param [\"\",'ABNORMAL_SECURITY','ABSOLUTE','ACALVIO','ACCELLION','ACTIVE_SYNC','ADAUDIT_PLUS','ADFS','ADMANAGER_PLUS','ADSELFSERVICE_PLUS','AIRDEFENSE','AIRWATCH','AIX_SYSTEM','AI_HUNTER','AKAMAI_CLOUD_MONITOR','AKAMAI_DDOS','AKAMAI_DHCP','AKAMAI_DNS','AKAMAI_EAA','AKAMAI_ETP','AKAMAI_WAF','ALERTLOGIC_NOTIFICATIONS','ALGOSEC','ALLOT_NETENFORCER','ANOMALI_IOC','ANSIBLE_AWX','APACHE','APACHE_KAFKA_AUDIT','APACHE_SPAMASSASSIN','APC_SMART_UPS','APC_STRUXUREWARE','APPIAN_CLOUD','APPOMNI','APTOS_EOM','AQUA_SECURITY','ARBOR_EDGE_DEFENSE','ARCHER_IRM','ARCSIGHT_CEF','AREA1','ARISTA_SWITCH','ARKIME_PCAP','ARMIS','ARMOR_ANYWHERE','ARRAYNETWORKS_VPN','ARRAY_NETWORKS_WAF','ARUBA_AIRWAVE','ARUBA_IPS','ARUBA_WIRELESS','ARXAN_THREAT_ANALYTICS','ASOC_ALERT','ASSET_STATIC_IP','ATLASSIAN_CONFLUENCE','ATLASSIAN_JIRA','ATTIVO','ATT_NETBOND','AUDITD','AUTHENTIC8_SILO','AUTHX','AUTH_ZERO','AUTOMATION_ANYWHERE','AUTOMOX_EPM','AVANAN_EMAIL','AVATIER','AVAYA_IVR','AVAYA_WIRELESS','AWS_AURORA','AWS_CLOUDFRONT','AWS_CLOUDTRAIL','AWS_CLOUDWATCH','AWS_CONFIG','AWS_CONTROL_TOWER','AWS_ELB','AWS_KMS','AWS_MACIE','AWS_REDSHIFT','AWS_ROUTE_53','AWS_S3_SERVER_ACCESS','AWS_SECURITY_HUB','AWS_SESSION_MANAGER','AWS_VPC_FLOW','AWS_WAF','AXONIUS','AZURE','AZURE_ACTIVITY','AZURE_AD','AZURE_AD_AUDIT','AZURE_AD_CONTEXT','AZURE_ATP','AZURE_COSMOS_DB','AZURE_FIREWALL','AZURE_MDM_INTUNE','AZURE_NSG_FLOW','AZURE_RESOURCE_LOGS','AZURE_SECURITY_CENTER','AZURE_SQL','BALABIT','BARRACUDA_CLOUDGEN_ACCESS','BARRACUDA_EMAIL','BARRACUDA_FIREWALL','BARRACUDA_WAF','BEYONDTRUST_BEYONDINSIGHT','BEYONDTRUST_CPB','BEYONDTRUST_ENDPOINT','BEYONDTRUST_REMOTE_ACCESS','BIGSWITCH_BCF','BIND_DNS','BITDEFENDER','BLUECAT_DDI','BLUECAT_EDGE','BLUECOAT_WEBPROXY','BLUE_PRISM','BMC_AMI_DEFENDER','BMC_HELIX_DISCOVERY','BOMGAR','BOX','BRICATA_NDR','BRIVO','BROCADE_SERVERIRON','BROCADE_SWITCH','BRO_DHCP','BRO_HTTP','BRO_JSON','BRO_TSV','BT_IPCONTROL','CAMEYO_BYO_CLOUD','CASSANDRA','CATO_NETWORKS','CATO_SDWAN','CA_ACCESS_CONTROL','CA_ACF2','CA_LDAP','CA_SSO_WEB','CB_APP_CONTROL','CB_EDR','CENTRIFY_SSO','CENTRIPETAL_IOC','CEQUENCE_BOT_DEFENSE','CHECKPOINT_EDR','CHECKPOINT_EMAIL','CHECKPOINT_FIREWALL','CHECKPOINT_HARMONY','CISCO_ACE','CISCO_ACI','CISCO_ACS','CISCO_AMP','CISCO_APIC','CISCO_ASA_FIREWALL','CISCO_CLOUDLOCK_CASB','CISCO_CTS','CISCO_DHCP','CISCO_DNAC','CISCO_DNS','CISCO_EMAIL_SECURITY','CISCO_FIREPOWER_FIREWALL','CISCO_FIRESIGHT','CISCO_IOS','CISCO_ISE','CISCO_MERAKI','CISCO_NX_OS','CISCO_PRIME','CISCO_ROUTER','CISCO_SECURE_MALWARE_ANALYTICS','CISCO_SECURE_WORKLOAD','CISCO_SMA','CISCO_STEALTHWATCH','CISCO_SWITCH','CISCO_TACACS','CISCO_UCM','CISCO_UCS','CISCO_VPN','CISCO_WIPS','CISCO_WIRELESS','CISCO_WSA','CIS_ALBERT_ALERT','CITRIX_MONITOR','CITRIX_NETSCALER','CITRIX_NETSCALER_WEB_LOGS','CITRIX_SDWAN','CITRIX_STOREFRONT','CITRIX_WEB_GATEWAY','CITRIX_WORKSPACE','CLAM_AV','CLEARPASS','CLEARSENSE','CLOUDFLARE','CLOUDFLARE_BOT_MANAGEMENT','CLOUDFLARE_WAF','CLOUDGENIX_SDWAN','CLOUDIAN_HYPERSTORE','CLOUDM','CLOUDPASSAGE_CSM','CLOUDPASSAGE_FIM','CLOUDPASSAGE_LIDS','CLOUDPASSAGE_SVM','CLOUD_IDENTITY_CONTEXT','CLOUD_PASSAGE','CMD','CODE42','CODE42_INCYDR','CODE_WORLDWIDE','COFENSE_TRIAGE','COFENSE_VISION','COHESITY','COMMVAULT','COMODO_AV','CONFLUENT_AUDIT','CORELIGHT','CORTEX_XDR','COVID_CTC_IOC','CRADLEPOINT_NETCLOUD','CROWDSTRIKE_IOC','CSV_CUSTOM_CMDB','CSV_CUSTOM_IOC','CS_CEF_EDR','CS_EDR','CS_STREAM','CUSTOMER_ALERT','CUSTOM_APPLICATION_ACCESS','CUSTOM_DNS','CUSTOM_SECURITY_DATA_ANALYTICS','CYBERARK','CYBEREASON_EDR','CYCODE','CYLANCE','CYLANCE_PROTECT','CYOLO_ZTNA','D3_BANKING','D3_SECURITY','DARKTRACE','DATADOG','DATALOCKER_SAFECONSOLE','DATAWATCH','DB2_DB','DEEPFENCE','DEEP_INSTINCT_EDR','DELL_EMC_AVAMAR','DELL_EMC_CLOUDLINK','DELL_EMC_DATA_DOMAIN','DELL_EMC_NAS','DELL_OPENMANAGE','DELL_SWITCH','DESIGN_PROFIT_CENTRAL_SERVER','DHS_IOC','DIGITALGUARDIAN_EDR','DIGITAL_SHADOWS_IOC','DIGITAL_SHADOWS_SEARCHLIGHT','DMP_ENTRE','DOCKER','DREMIO_DATA_LAKEHOUSE','DROPBOX','DUO_ADMIN','DUO_AUTH','DUO_CASB','DUO_CONTEXT','DUO_NETWORK_GATEWAY','DUO_TELEPHONY','DUO_USER_CONTEXT','DYNATRACE','E2_SOLUTIONS','EATON_UPS','ECAR','ECAR_BRO','EFFICIENTIP_DDI','EIQ_EDR','ELASTIC_AUDITBEAT','ELASTIC_FILEBEAT','ELASTIC_METRICBEAT','ELASTIC_PACKETBEATS','ELASTIC_SEARCH','ELASTIC_WINLOGBEAT','ENDGAME_EDR','ENDPOINT_PROTECTOR_DLP','ENTRUST_NTP_SERVER','EPIC','ESET_AV','ESET_EDR','ESET_IOC','ESTAR','ETQ_RELIANCE','ET_PRO_IOC','EXABEAM_FUSION_XDR','EXCHANGE_MAIL','EXTRAHOP','EXTRAHOP_DHCP','EXTRAHOP_DNS','EXTREME_SWITCH','F5_ASM','F5_BIGIP_LTM','F5_BOT','F5_DNS','F5_SHAPE','F5_VPN','FALCO_IDS','FASTLY_WAF','FIDELIS_ENDPOINT','FIDELIS_NETWORK','FILEZILLA_FTP','FILE_SCANNING_FRAMEWORK','FIREEYE_ALERT','FIREEYE_EMPS','FIREEYE_ETP','FIREEYE_HX','FIREEYE_NX','FIREMON_FIREWALL','FLASHPOINT_IOC','FLUENTD','FORCEPOINT_CASB','FORCEPOINT_DLP','FORCEPOINT_FIREWALL','FORCEPOINT_WEBPROXY','FORESCOUT_NAC','FORSETI','FORTANIX_DSM','FORTINET_DHCP','FORTINET_FIREWALL','FORTINET_FORTIANALYZER','FORTINET_FORTIAUTHENTICATOR','FORTINET_FORTICLIENT','FORTINET_FORTIEDR','FORTINET_FORTINAC','FORTINET_SANDBOX','FORTINET_WEBPROXY','FOX_IT_STIX','FREEIPA','FREERADIUS','FRONTLINE_VM','FUTUREX_HSM','GCP_APIGEE','GCP_CLOUDIDENTITY_DEVICES','GCP_CLOUDIDENTITY_DEVICEUSERS','GCP_CLOUDIOT','GCP_CLOUDSQL','GCP_COMPUTE','GCP_IDS','GCP_LOADBALANCING','GCP_RUN','GCP_THREAT_DETECTION','GCP_VPC_FLOW','GIGAMON','GITHUB','GITLAB','GLOBALSCAPE_SFTP','GLUSTER_FS','GMAIL_LOGS','GMV_CHECKER','GMV_CHECKER_CONTEXT','GREATHORN','GTB_DLP','GUARDDUTY','GUARDICORE_CENTRA','GUARDIUM','HADOOP','HAPROXY','HAPROXY_LOADBALANCER','HASHICORP','HCL_BIGFIX','HCNET_ACCOUNT_ADAPTER','HITACHI_ID_PAM','HONEYD','HPE_ILO','HP_PRINTER','HP_PROCURVE','HYPR_MFA','IBM_AS400','IBM_CICS','IBM_DATAPOWER','IBM_MAAS360','IBM_MQ_FILE_TRANSFER','IBM_SECURITY_VERIFY','IBM_SPECTRUM_PROTECT','IBM_SWITCH','IBM_TIVOLI','IBM_WEBSEAL','IBM_WEBSPHERE_APP_SERVER','IBM_ZOS','IBM_ZSECURE_ALERT','IBOSS_WEBPROXY','IDRAC','IIS','ILLUMIO_CORE','IMANAGE_CLOUD','IMPERVA_DB','IMPERVA_SECURESPHERE','IMPERVA_SONAR','IMPERVA_WAF','IMPRIVATA_CONFIRM_ID','IMPRIVATA_IDG','IMPRIVATA_ONESIGN','INFOBLOX','INFOBLOX_DHCP','INFOBLOX_DNS','INFOBLOX_LOADBALANCER','INFOBLOX_NETMRI','INFOBLOX_RPZ','INFORMIX','IPSWITCH_MOVEIT_AUTOMATION','IPSWITCH_MOVEIT_TRANSFER','IPSWITCH_SFTP','ISC_DHCP','JAMF','JAMF_COMPLIANCE_REPORTER','JAMF_PROTECT','JDE','JENKINS','JUMPCLOUD_DAAS','JUNIPER_FIREWALL','JUNIPER_IPS','JUNIPER_JUNOS','JUNIPER_MX','KAMAILIO','KASEYA','KASPERSKY_AV','KEA_DHCP','KEEPER','KEMP_LOADBALANCER','KIBANA','KISI','KNOWBE4_PHISHER','KONG_GATEWAY','KUBERNETES_AUDIT','KUBERNETES_AUTH_PROXY','KUBERNETES_NODE','KYRIBA','LACEWORK','LASTPASS','LENEL_ONGUARD','LEXMARK_PRINTER','LIAISON_NUBRIDGES','LIMACHARLIE_EDR','LINUX_DHCP','LINUX_SYSMON','LOGICMONITOR','LOOKINGGLASS_IPS','LOOKING_GLASS_IOC','LSI_BMS','MACOS','MAILSCANNER','MALWAREBYTES_EDR','MANAGE_ENGINE_AD360','MANAGE_ENGINE_PASSWORD_MANAGER','MANAGE_ENGINE_REPORTER_PLUS','MANGOAPPS','MARIA_DB','MATERIAL_SECURITY','MATRIX_FRONTIER','MCAFEE_ATD','MCAFEE_DLP','MCAFEE_EDR','MCAFEE_EPO','MCAFEE_ESM','MCAFEE_IPS','MCAFEE_MVISION_CASB','MCAFEE_SKYHIGH_CASB','MCAFEE_UCE','MCAFEE_WEBPROXY','MCAFEE_WEB_PROTECTION','MEDIGATE_CMDB','MEDIGATE_IOT','MENANDMICE_DNS','MENLO_SECURITY','MICROSEMI_NTP','MICROSOFT_ATA','MICROSOFT_CASB','MICROSOFT_DEFENDER_ENDPOINT','MICROSOFT_DEFENDER_IDENTITY','MICROSOFT_GRAPH_ALERT','MICROSOFT_NETLOGON','MICROSOFT_SCEP','MICROSOFT_SENTINEL','MICROSOFT_SQL','MICROSOFT_SSTP','MIMECAST_MAIL','MIMECAST_WEBPROXY','MINERVA_AV','MISP_IOC','MOBILEIRON','MONGO_DB','MULESOFT','MYSQL','NAGIOS','NASUNI_FILE_SERVICES','NCC_SCOUTSUITE','NCR_DIGITAL_INSIGHT_FSG','NCR_DIGITAL_INSIGHT_GL','NETAPP_ONTAP','NETAPP_SAN','NETDISCO','NETFILTER_IPTABLES','NETMOTION','NETSKOPE_ALERT','NETSKOPE_WEBPROXY','NETSURION_PROTECTWISE','NGINX','NIMBLE_OS','NIST_NVD','NIX_SYSTEM','NUCLEUS_ASSET','NUCLEUS_VULNERABILITY','NUCLEUS_VULNERABILITY_DELTA','NUTANIX_FRAME','NUTANIX_PRISM','NXLOG_MANAGER','OBSERVEIT','OBSIDIAN','OFFICE_365','OKTA','OKTA_ACCESS_GATEWAY','OKTA_RADIUS','OKTA_USER_CONTEXT','ONBASE_CMS','ONEIDENTITY_ARS','ONEIDENTITY_CHANGE_AUDITOR','ONEIDENTITY_DEFENDER','ONEIDENTITY_TPAM','ONELOGIN_SSO','ONELOGIN_USER_CONTEXT','ONEPASSWORD','OPENAM','OPENDJ','OPENGEAR','OPENLDAP','OPENPATH','OPENSSH','OPENTEXT_FAX2MAIL','OPEN_VPN','ORACLE_CLOUD_AUDIT','ORACLE_DB','ORCA','ORDR_IOT','OSCAR_CLAIMS','OSINT_IOC','OSQUERY_EDR','OSSEC','PAN_CASB','PAN_EDR','PAN_FIREWALL','PAN_GLOBAL_PROTECT','PAN_IOC','PAN_PRISMA_CLOUD','PASSIVE_DNS','PCAP_SSL_CLIENT_HELLO','PEOPLESOFT','PEPLINK_LOADBALANCER','PEPLINK_ROUTER','PEPLINK_SWITCH','PERIMETERX_BOT_PROTECTION','PFSENSE','PHISHEYE_ALERT','PING','PIVOTAL','PLASO','PLIXER_SCRUTINIZER','POSTFIX_MAIL','POWERSHELL','POWER_DNS','PREEMPT','PREEMPT_AUTH','PREVEIL_ENTERPRISE','PROOFID','PROOFPOINT_CASB','PROOFPOINT_MAIL','PROOFPOINT_MAIL_FILTER','PROOFPOINT_ON_DEMAND','PROOFPOINT_TRAP','PROOFPOINT_WEB_BROWSER_ISOLATION','PROTEGRITY_DEFIANCE','PROWATCH','PULSE_SECURE_VPN','PUPPET','PURE_STORAGE','QUALYS_CONTINUOUS_MONITORING','QUALYS_VM','QUEST_AD','RADIUS','RADWARE_DDOS','RADWARE_FIREWALL','RAPID7_INSIGHT','RAPID7_NEXPOSE','RECORDED_FUTURE_IOC','REDCANARY_CLOUD_PROTECTION_RAW','REDCANARY_EDR','REDHAT_DIRECTORY_SERVER','REDHAT_IM','REDHAT_KEYCLOAK','REDHAT_OPENSHIFT','REDHAT_STACKROX','REMEDIANT_SECUREONE','RH_ISAC_IOC','RIBBON_ANALYTICS_PLATFORM','RIBBON_SBC','RING_CENTRAL','RISKIQ_DIGITAL_FOOTPRINT','RSA_AUTH_MANAGER','RSA_NETWITNESS','RUBRIK','RUBRIK_POLARIS','RUCKUS_WIRELESS','SAFECONNECT_NAC','SAILPOINT_IAM','SALESFORCE','SALESFORCE_CONTEXT','SAP_HANA','SAP_INSURANCE','SECBERUS','SECUREAUTH_SSO','SECURELINK','SEMPERIS_ADFR','SEMPERIS_DSP','SENDMAIL','SENTINEL_DV','SENTINEL_EDR','SEP','SERVICENOW_AUDIT','SERVICENOW_CMDB','SERVICENOW_ROLES','SERVICENOW_SECURITY','SEVCO_CMDB','SHAREPOINT','SHIBBOLETH_IDP','SHODAN_IO','SIEMENS_SIPASS','SIGNAL_SCIENCES_WAF','SILVERFORT','SILVERPEAK_FIREWALL','SITEMINDER_SSO','SLACK_AUDIT','SNARE_SOLUTIONS','SNIPE_IT','SNOOPY_LOGGER','SNORT_IDS','SNOWFLAKE','SOFTWARE_HOUSE_ACS','SOLARIS_SYSTEM','SOLARWINDS_SERV_U','SONARQUBE','SONIC_FIREWALL','SOPHOS_AV','SOPHOS_CAPSULE8','SOPHOS_CENTRAL','SOPHOS_DHCP','SOPHOS_EDR','SOPHOS_FIREWALL','SOPHOS_UTM','SOURCEFIRE_IDS','SPLUNK','SPLUNK_DNS','SPLUNK_PHANTOM','SPYCLOUD','SQUID_WEBPROXY','STEALTHBITS_AUDIT','STEALTHBITS_DEFEND','STEELHEAD','STREAMALERT','STRONGSWAN_VPN','SUPERNA_EYEGLASS','SURICATA_EVE','SURICATA_IDS','SWIFT_AMH','SWIMLANE','SYMANTEC_CASB','SYMANTEC_DLP','SYMANTEC_EDR','SYMANTEC_EVENT_EXPORT','SYMANTEC_MAIL','SYMANTEC_VIP','SYMANTEC_WEB_ISOLATION','SYMANTEC_WSS','SYSDIG','TANIUM_ASSET','TANIUM_AUDIT','TANIUM_COMPLY','TANIUM_DEPLOY','TANIUM_DISCOVER','TANIUM_INSIGHT','TANIUM_INTEGRITY_MONITOR','TANIUM_PATCH','TANIUM_QUESTION','TANIUM_REVEAL','TANIUM_TH','TANIUM_THREAT_RESPONSE','TEAMVIEWER','TENABLE_IO','TENABLE_SC','TGDETECT','THALES_DIS','THALES_LUNA_HSM','THALES_MFA','THINKST_CANARY','THREATCONNECT_IOC','THYCOTIC','THYCOTIC_DEVOPS_SECRETVAULT','TIPPING_POINT','TOMCAT','TRENDMICRO_AV','TRENDMICRO_CLOUDAPPSECURITY','TRENDMICRO_DEEP_SECURITY','TRENDMICRO_EDR','TRENDMICRO_WEBPROXY','TRIPWIRE_FIM','UBIQUITI_SWITCH','UDM','ULTRADNS','UMBRELLA_DNS','UMBRELLA_FIREWALL','UMBRELLA_IP','UMBRELLA_WEBPROXY','UNBOUND_DNS','UNIFI_AP','UNIFI_SWITCH','UPTYCS_EDR','VANDYKE_SFTP','VARONIS','VECTRA_DETECT','VECTRA_STREAM','VEEAM','VENAFI','VERIZON_NDR','VIRUSTOTAL_THREAT_HUNTER','VITALQIP','VMRAY_FLOG_XML','VMWARE_AVINETWORKS_IWAF','VMWARE_AVI_VANTAGE','VMWARE_ESX','VMWARE_HCX','VMWARE_HORIZON','VMWARE_NSX','VMWARE_TANZU','VMWARE_VCENTER','VMWARE_VREALIZE','VMWARE_VSHIELD','VMWARE_WORKSPACE_ONE','VOLTAGE','VORMETRIC','VSFTPD_AUDIT','WATCHGUARD','WAZUH','WHITECLOUD_EDR','WINDOWS_AD','WINDOWS_APPLOCKER','WINDOWS_DEFENDER_ATP','WINDOWS_DEFENDER_AV','WINDOWS_DHCP','WINDOWS_DNS','WINDOWS_FIREWALL','WINDOWS_NET_POLICY_SERVER','WINDOWS_SYSMON','WINEVTLOG','WINEVTLOG_XML','WIZ_IO','WORDPRESS_CMS','WORKDAY','WORKDAY_AUDIT','WORKSPACE_ACTIVITY','WORKSPACE_ALERTS','WORKSPACE_CHROMEOS','WORKSPACE_GROUPS','WORKSPACE_MOBILE','WORKSPACE_PRIVILEGES','WORKSPACE_USERS','WORKSPOT_CONTROL','WP_ENGINE','WTI_CONSOLE_SERVERS','YUBICO_OTP','ZEROFOX_PLATFORM','ZIMPERIUM','ZIX_EMAIL_ENCRYPTION','ZOOM_OPERATION_LOGS','ZSCALER_CASB','ZSCALER_DNS','ZSCALER_FIREWALL','ZSCALER_VPN','ZSCALER_WEBPROXY'] {type: \"string\"}\n",
        "\n",
        "#@markdown All subsequent fields are optional\n",
        "\n",
        "#@markdown The namespace for identifying logs from this collector.\n",
        "\n",
        "assetNamespace = \"\" #@param {type : \"string\"}\n",
        "\n",
        "#@markdown A list of arbitrary key:value pairs that can be specified in the forwarder configuration. **Note:** This is a global setting that applies to the forwarder and the forwarder's collectors, unless it is overridden at the collector level.\n",
        "\n",
        "#@markdown Please enter them in the form **key1:value1,key2:value2...**\n",
        "labels =  \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Paste a regex filter from the Regex Filter Builder in the cell above\n",
        "\n",
        "regexFilters_object = \"\" #@param {type :\"string\"}\n",
        "\n",
        "#@markdown Specifies the disk buffering state for the collector\n",
        "diskBuffer_state = \"\" #@param [\"\", \"ACTIVE\", \"SUSPENDED\"]\n",
        "\n",
        "#@markdown The directory path for files written.\n",
        "diskBuffer_directoryPath = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown The maximum buffered file size.\n",
        "diskBuffer_maxFileBufferBytes = 0 #@param {type: \"integer\"}\n",
        "\n",
        "#@markdown The number of seconds between batches. The default is 10.\n",
        "maxSecondsPerBatch = 0 #@param {type: \"integer\"}\n",
        "\n",
        "#@markdown The number of bytes queued before forwarder batch upload. The default is 1048576.\n",
        "maxBytesPerBatch = 0 #@param {type: \"integer\"}\n",
        "\n",
        "#@markdown The below section allows you to specify the type of ingestion settings to use for this collector. One type is allowed for a collector configuration.\n",
        "\n",
        "#@markdown ##File\n",
        "\n",
        "fileSettings_filePath = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown ##Kafka\n",
        "\n",
        "#@markdown The username of an identity used for authentication.\n",
        "kafkaSettings_authentication_username = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown The password of the account identified by the username.\n",
        "kafkaSettings_authentication_password = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown The Kafka topic from which to ingest data. For details, see [Collect data from Kafka topics](https://cloud.google.com/chronicle/docs/install/forwarder-linux#collect_data_from_kafka_topic).\n",
        "kafkaSettings_topic = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown A group ID.\n",
        "kafkaSettings_groupId = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown The maximum number of seconds a dial will wait for a connect to complete. The default is 60.\n",
        "kafkaSettings_timeout = 0 #@param {type : \"integer\"}\n",
        "\n",
        "#@markdown A repeated string listing Kafka brokers. For example: **\"broker-1:9092\", \"broker-2:9093\"**\n",
        "\n",
        "#@markdown **Note:** All values are replaced during an update operation. Therefore, to update a list of brokers to add a new broker, specify all existing brokers and the new broker.\n",
        "kafkaSettings_brokers = \"\" #@param {type : \"string\"}\n",
        "\n",
        "#@markdown The path and certificate filename. For example: **/<wbr>path/to/cert.pem**\n",
        "kafkaSettings_tlsSettings_certificate = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown The path and certificate key filename. For example: **/<wbr>path/to/cert.key**\n",
        "kafkaSettings_tlsSettings_certificateKey = \"\" #@param {type : \"string\"}\n",
        "\n",
        "#@markdown The minimum TLS version.\n",
        "kafkaSettings_minimumTlsVersion = \"\" #@param {type : \"string\"}\n",
        "\n",
        "#@markdown If true, enables SSL certification verification (for kafka connections). The default is **false**.\n",
        "kafkaSettings_tlsSettings_insecureSkipVerify = False #@param {type : \"boolean\"}\n",
        "\n",
        "#@markdown ##PCAP\n",
        "#@markdown The interface to listen to for PCAP data.\n",
        "pcapSettings_networkInterface = \"\" #@param {type : \"string\"}\n",
        "\n",
        "#@markdown The Berkeley Packet Filter (BPF) for pcap.\n",
        "pcapSettings_bpf = \"\" #@param {type : \"string\"}\n",
        "\n",
        "#@markdown ##Splunk\n",
        "#@markdown The username of an identity used for authentication.\n",
        "splunkSettings_authentication_username = \"\" #@param {type : \"string\"}\n",
        "\n",
        "#@markdown The password of the account identified by the username.\n",
        "splunkSettings_authentication_password = \"\" #@param {type : \"string\"}\n",
        "\n",
        "#@markdown The host or IP address for the Splunk REST API.\n",
        "splunkSettings_host = \"\" #@param {type : \"string\"}\n",
        "\n",
        "#@markdown The port for the Splunk REST API.\n",
        "splunkSettings_port = 0 #@param {type : \"integer\"}\n",
        "\n",
        "#@markdown \tThe minimum time range in seconds for a given Splunk search. For details, see Collect Splunk data. The default is **10**.\n",
        "splunkSettings_minimumWindowSize = 0 #@param {type : \"integer\"}\n",
        "\n",
        "#@markdown The maximum time range in seconds for a given Splunk search. For details, see Collect Splunk data. The default is **30**.\n",
        "splunkSettings_maximumWindowSize = 0 #@param {type : \"integer\"}\n",
        "\n",
        "#@markdown The query used to filter records within Splunk. For example: **search index=* sourcetype=dns**\n",
        "splunkSettings_queryString = \"\" #@param {type : \"string\"}\n",
        "\n",
        "#@markdown The query mode for Splunk. For example: **realtime**\n",
        "splunkSettings_queryMode = \"\" #@param {type : \"string\"}\n",
        "\n",
        "#@markdown If true, the certificate is ignored.\n",
        "splunkSettings_certIgnored = False #@param {type : \"boolean\"}\n",
        "\n",
        "#@markdown ##Syslog\n",
        "#@markdown Specifies the protocol the collector will use to listen for syslog data.\n",
        "syslogSettings_protocol = \"UDP\" #@param [\"\", \"UDP\", \"TCP\"]\n",
        "\n",
        "#@markdown The target IP address or hostname where the collector resides and listens for syslog data.\n",
        "syslogSettings_address = \"0.0.0.0\" #@param {type : \"string\"}\n",
        "\n",
        "#@markdown The target port where the collector resides and listens for syslog data.\n",
        "syslogSettings_port = 10514 #@param {type : \"integer\"}\n",
        "\n",
        "#@markdown The size in bytes of the TCP socket's buffer. The default for TCP is **65536**. The default for UDP is **8192**.\n",
        "syslogSettings_bufferSize = 0 #@param {type : \"integer\"}\n",
        "\n",
        "#@markdown The number of seconds of inactivity after which the TCP connection is dropped. The default is **60**.\n",
        "syslogSettings_connectonTimeout = 0 #@param {type : \"integer\"}\n",
        "\n",
        "collector_config = {}\n",
        "\n",
        "if logType:\n",
        "  collector_config[\"logType\"] = logType\n",
        "\n",
        "if assetNamespace:\n",
        "  if \"metadata\" not in collector_config.keys():\n",
        "    collector_config[\"metadata\"] = {}\n",
        "  collector_config[\"metadata\"][\"assetNamespace\"] = assetNamespace\n",
        "\n",
        "if labels:\n",
        "  if \"metadata\" not in collector_config.keys():\n",
        "    collector_config[\"metadata\"] = {}\n",
        "  collector_config[\"metadata\"]['labels'] = []\n",
        "  labels = labels.split(\",\")\n",
        "\n",
        "  for label in labels:\n",
        "    label = label.strip()\n",
        "    label = label.split(\":\")\n",
        "    collector_config[\"metadata\"]['labels'].append({\"key\" : label[0].strip(), \"value\" : label[1].strip()})\n",
        "\n",
        "if regexFilters_object:\n",
        "  collector_config[\"regexFilters\"] = json.loads(regexFilters_object)\n",
        "\n",
        "if diskBuffer_state:\n",
        "  if \"diskBuffer\" not in collector_config.keys():\n",
        "    collector_config[\"diskBuffer\"] = {}\n",
        "  collector_config[\"diskBuffer\"][\"state\"] = diskBuffer_state\n",
        "\n",
        "if diskBuffer_directoryPath:\n",
        "  if \"diskBuffer\" not in collector_config.keys():\n",
        "    collector_config[\"diskBuffer\"] = {}\n",
        "  collector_config[\"diskBuffer\"][\"directoryPath\"] = diskBuffer_directoryPath\n",
        "\n",
        "if diskBuffer_maxFileBufferBytes:\n",
        "  if \"diskBuffer\" not in collector_config.keys():\n",
        "    collector_config[\"diskBuffer\"] = {}\n",
        "  collector_config[\"diskBuffer\"][\"maxFileBufferBytes\"] = diskBuffer_maxFileBufferBytes\n",
        "\n",
        "if maxSecondsPerBatch:\n",
        "  collector_config[\"maxSecondsPerBatch\"] = maxSecondsPerBatch\n",
        "\n",
        "if maxBytesPerBatch:\n",
        "  collector_config[\"maxBytesPerBatch\"] = maxBytesPerBatch\n",
        "\n",
        "if fileSettings_filePath:\n",
        "  collector_config[\"fileSettings\"] = {}\n",
        "  collector_config[\"fileSettings\"][\"filePath\"] = fileSettings_filePath\n",
        "\n",
        "if kafkaSettings_authentication_username:\n",
        "  if \"kafkaSettings\" not in collector_config.keys():\n",
        "    collector_config[\"kafkaSettings\"] = {}\n",
        "  if \"authentication\" not in collector_config[\"kafkaSettings\"].keys():\n",
        "    collector_config[\"kafkaSettings\"][\"authentication\"] = {}\n",
        "  collector_config[\"kafkaSettings\"][\"authentication\"][\"username\"] = kafkaSettings_authentication_username\n",
        "\n",
        "if kafkaSettings_authentication_password:\n",
        "  if \"kafkaSettings\" not in collector_config.keys():\n",
        "    collector_config[\"kafkaSettings\"] = {}\n",
        "  if \"authentication\" not in collector_config[\"kafkaSettings\"].keys():\n",
        "    collector_config[\"kafkaSettings\"][\"authentication\"] = {}\n",
        "  collector_config[\"kafkaSettings\"][\"authentication\"][\"password\"] = kafkaSettings_authentication_password\n",
        "\n",
        "if kafkaSettings_topic:\n",
        "  if \"kafkaSettings\" not in collector_config.keys():\n",
        "    collector_config[\"kafkaSettings\"] = {}\n",
        "  collector_config[\"kafkaSettings\"][\"topic\"] = kafkaSettings_topic\n",
        "\n",
        "if kafkaSettings_groupId:\n",
        "  if \"kafkaSettings\" not in collector_config.keys():\n",
        "    collector_config[\"kafkaSettings\"] = {}\n",
        "  collector_config[\"kafkaSettings\"][\"groupId\"] = kafkaSettings_groupId\n",
        "\n",
        "if kafkaSettings_timeout:\n",
        "  if \"kafkaSettings\" not in collector_config.keys():\n",
        "    collector_config[\"kafkaSettings\"] = {}\n",
        "  collector_config[\"kafkaSettings\"][\"timeout\"] = kafkaSettings_timeout\n",
        "\n",
        "if kafkaSettings_brokers:\n",
        "  if \"kafkaSettings\" not in collector_config.keys():\n",
        "    collector_config[\"kafkaSettings\"] = {}\n",
        "  collector_config[\"kafkaSettings\"][\"brokers\"] = kafkaSettings_brokers\n",
        "\n",
        "if kafkaSettings_tlsSettings_certificate:\n",
        "  if \"kafkaSettings\" not in collector_config.keys():\n",
        "    collector_config[\"kafkaSettings\"] = {}\n",
        "  if \"tlsSettings\" not in collector_config[\"kafkaSettings\"].keys():\n",
        "    collector_config[\"kafkaSettings\"][\"tlsSettings\"] = {}\n",
        "  collector_config[\"kafkaSettings\"][\"tlsSettings\"][\"certificate\"] = kafkaSettings_tlsSettings_certificate\n",
        "\n",
        "if kafkaSettings_tlsSettings_certificateKey:\n",
        "  if \"kafkaSettings\" not in collector_config.keys():\n",
        "    collector_config[\"kafkaSettings\"] = {}\n",
        "  if \"tlsSettings\" not in collector_config[\"kafkaSettings\"].keys():\n",
        "    collector_config[\"kafkaSettings\"][\"tlsSettings\"] = {}\n",
        "  collector_config[\"kafkaSettings\"][\"tlsSettings\"][\"certificateKey\"] = kafkaSettings_tlsSettings_certificateKey\n",
        "\n",
        "if kafkaSettings_tlsSettings_insecureSkipVerify:\n",
        "  if \"kafkaSettings\" not in collector_config.keys():\n",
        "    collector_config[\"kafkaSettings\"] = {}\n",
        "  if \"tlsSettings\" not in collector_config[\"kafkaSettings\"].keys():\n",
        "    collector_config[\"kafkaSettings\"][\"tlsSettings\"] = {}\n",
        "    collector_config[\"kafkaSettings\"][\"tlsSettings\"][\"insecureSkipVerify\"] = kafkaSettings_tlsSettings_insecureSkipVerify\n",
        "\n",
        "if pcapSettings_networkInterface:\n",
        "  if \"pcapSettings\" not in collector_config.keys():\n",
        "    collector_config[\"pcapSettings\"] = {}\n",
        "  collector_config[\"pcapSettings\"][\"networkInterface\"] = pcapSettings_networkInterface\n",
        "\n",
        "if pcapSettings_bpf:\n",
        "  if \"pcapSettings\" not in collector_config.keys():\n",
        "    collector_config[\"pcapSettings\"] = {}\n",
        "  collector_config[\"pcapSettings\"][\"bpf\"] = pcapSettings_bpf\n",
        "\n",
        "if splunkSettings_authentication_username:\n",
        "  if \"splunkSettings\" not in collector_config.keys():\n",
        "    collector_config[\"splunkSettings\"] = {}\n",
        "  if \"authentication\" not in collector_config[\"splunkSettings\"].keys():\n",
        "    collector_config[\"splunkSettings\"][\"authentication\"] = {}\n",
        "  collector_config[\"splunkSettings\"][\"authentication\"][\"username\"] = splunkSettings_authentication_username\n",
        "\n",
        "if splunkSettings_authentication_password:\n",
        "  if \"splunkSettings\" not in collector_config.keys():\n",
        "    collector_config[\"splunkSettings\"] = {}\n",
        "  if \"authentication\" not in collector_config[\"splunkSettings\"].keys():\n",
        "    collector_config[\"splunkSettings\"][\"authentication\"] = {}\n",
        "  collector_config[\"splunkSettings\"][\"authentication\"][\"password\"] = splunkSettings_authentication_password\n",
        "\n",
        "if splunkSettings_host:\n",
        "  if \"splunkSettings\" not in collector_config.keys():\n",
        "    collector_config[\"splunkSettings\"] = {}\n",
        "  collector_config[\"splunkSettings\"][\"host\"] = splunkSettings_host\n",
        "\n",
        "if splunkSettings_port:\n",
        "  if \"splunkSettings\" not in collector_config.keys():\n",
        "    collector_config[\"splunkSettings\"] = {}\n",
        "  collector_config[\"splunkSettings\"][\"port\"] = splunkSettings_port\n",
        "\n",
        "if splunkSettings_minimumWindowSize:\n",
        "  if \"splunkSettings\" not in collector_config.keys():\n",
        "    collector_config[\"splunkSettings\"] = {}\n",
        "  collector_config[\"splunkSettings\"][\"minimumWindowSize\"] = splunkSettings_minimumWindowSize\n",
        "\n",
        "if splunkSettings_maximumWindowSize:\n",
        "  if \"splunkSettings\" not in collector_config.keys():\n",
        "    collector_config[\"splunkSettings\"] = {}\n",
        "  collector_config[\"splunkSettings\"][\"maximumWindowSize\"] = splunkSettings_maximumWindowSize\n",
        "\n",
        "if splunkSettings_queryString:\n",
        "  if \"splunkSettings\" not in collector_config.keys():\n",
        "    collector_config[\"splunkSettings\"] = {}\n",
        "  collector_config[\"splunkSettings\"][\"queryString\"] = splunkSettings_queryString\n",
        "\n",
        "if splunkSettings_queryMode:\n",
        "  if \"splunkSettings\" not in collector_config.keys():\n",
        "    collector_config[\"splunkSettings\"] = {}\n",
        "  collector_config[\"splunkSettings\"][\"queryMode\"] = splunkSettings_queryMode\n",
        "\n",
        "if splunkSettings_certIgnored:\n",
        "  if \"splunkSettings\" not in collector_config.keys():\n",
        "    collector_config[\"splunkSettings\"] = {}\n",
        "  collector_config[\"splunkSettings\"][\"certIgnored\"] = splunkSettings_certIgnored\n",
        "\n",
        "if syslogSettings_protocol:\n",
        "  if \"syslogSettings\" not in collector_config.keys():\n",
        "    collector_config[\"syslogSettings\"] = {}\n",
        "  collector_config[\"syslogSettings\"][\"protocol\"] = syslogSettings_protocol\n",
        "\n",
        "if syslogSettings_address:\n",
        "  if \"syslogSettings\" not in collector_config.keys():\n",
        "    collector_config[\"syslogSettings\"] = {}\n",
        "  collector_config[\"syslogSettings\"][\"address\"] = syslogSettings_address\n",
        "\n",
        "if syslogSettings_port:\n",
        "  if \"syslogSettings\" not in collector_config.keys():\n",
        "    collector_config[\"syslogSettings\"] = {}\n",
        "  collector_config[\"syslogSettings\"][\"port\"] = syslogSettings_port\n",
        "\n",
        "if syslogSettings_bufferSize:\n",
        "  if \"syslogSettings\" not in collector_config.keys():\n",
        "    collector_config[\"syslogSettings\"] = {}\n",
        "  collector_config[\"syslogSettings\"][\"bufferSize\"] = syslogSettings_bufferSize\n",
        "\n",
        "if syslogSettings_connectonTimeout:\n",
        "  if \"syslogSettings\" not in collector_config.keys():\n",
        "    collector_config[\"syslogSettings\"] = {}\n",
        "  collector_config[\"syslogSettings\"][\"connectonTimeout\"] = syslogSettings_connectonTimeout\n",
        "\n",
        "# There can only be one type of colletor per call\n",
        "valid_colletors = [\n",
        "    \"syslogSettings\",\n",
        "    \"splunkSettings\",\n",
        "    \"pcapSettings\",\n",
        "    \"kafkaSettings\",\n",
        "    \"fileSettings\"\n",
        "]\n",
        "\n",
        "collectors_present = list(set(valid_colletors) & set(collector_config.keys()))\n",
        "if len(collectors_present) > 1:\n",
        "  print(f\"At most one type of collector can be present. There are {len(collectors_present)}\\nThey are: {', '.join(collectors_present)}\")\n",
        "else:\n",
        "  print(\"Please copy the output and paste it into the config cell in the appropriate call.\")\n",
        "  print(json.dumps(collector_config))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "k8k_-d6Jg0uF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCl0S9f9wWeu"
      },
      "source": [
        "#BigQuery Access API\n",
        "Documentation for this API can be found [here](https://cloud.google.com/chronicle/docs/reference/bigquery-access-api).\n",
        "\n",
        "[Jump to top](#scrollTo=v0jKbGj8ZZRB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "v0lf51QQwruh"
      },
      "outputs": [],
      "source": [
        "#@title Update BigQuery Access\n",
        "#@markdown Chronicle supports self-service access to Chronicle data in BigQuery. You can use this endpoint to grant Identity and Access Management (IAM) roles that give the following permissions for a user email:\n",
        "\n",
        "#@markdown The email must be a Google Accounts and ID Administration (GAIA) user email address of a Chronicle Security customer.\n",
        "email = \"\" #@param {type: \"string\"}\n",
        "\n",
        "body = {\n",
        "    \"email\" : email\n",
        "}\n",
        "\n",
        "uri_to_post = f\"https://{region_prefix}backstory.googleapis.com/v1/tools/bigqueryAccess:update\"\n",
        "resp = session.patch(uri_to_post, json=body)\n",
        "if resp.status_code > 299:\n",
        "  print(resp.text)\n",
        "else:\n",
        "  pprint(resp.json())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx1pfTxOjv57"
      },
      "source": [
        "#Chronicle CLI Tool\n",
        "Documentation for this tool can be found [here](https://cloud.google.com/chronicle/docs/administration/cli-user-guide#data_access_workflows).\n",
        "\n",
        "The tool itself can be found [here](https://github.com/chronicle/cli).\n",
        "\n",
        "[Jump to top](#scrollTo=v0jKbGj8ZZRB)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Forwarders\n",
        "operation = \"create\" #@param [\"create\", \"delete\", \"generate_files\", \"get\", \"list\", \"update\"]\n",
        "!chronicle_cli forwarders $operation --region $cli_region"
      ],
      "metadata": {
        "cellView": "form",
        "id": "b7SUMdaUWjpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Collectors\n",
        "operation = \"create\" #@param [\"create\", \"delete\", \"get\", \"list\", \"update\"]\n",
        "!chronicle_cli forwarders collectors $operation --region $cli_region"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JOMhZ9ZzbXdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Feeds\n",
        "operation = \"create\" #@param [\"create\", \"delete\", \"disable\", \"enable\", \"get\", \"list\", \"update\"]\n",
        "!chronicle_cli feeds $operation --region $cli_region"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6w11d15Eb9xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Parsers\n",
        "operation = \"list\" #@param [\"archive\", \"download\", \"generate\", \"history\", \"list\", \"list_errors\", \"run\", \"status\", \"submit\"]\n",
        "!chronicle_cli parsers $operation --region $cli_region"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XUIXGIxfctOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Parsers V2\n",
        "#@markdown This functionality requires two things\n",
        "\n",
        "#@markdown 1) A Chronicle instance with BYOP setup<br>2) A service account key from the GCP project tied to the Chronicle instance with the appropriate IAM roles granted\n",
        "\n",
        "PROJECT_ID = \"chronicle-byop\" #@param {type: \"string\"}\n",
        "CUSTOMER_ID = \"34871035-2752-4075-aed6-2e7f261be67d\" #@param {type: \"string\"}\n",
        "\n",
        "operation = \"get_parser\" #@param [\"list_parsers\",\"list_extensions\",\"run_parser\",\"submit_parser\",\"submit_extension\",\"delete_parser\",\"delete_extension\",\"deactivate_parser\",\"activate_parser\",\"get_parser\",\"get_extension\",\"get_validation_report\"]\n",
        "\n",
        "#@markdown Optional parameters, please refer to [documentation](https://cloud.google.com/chronicle/docs/administration/cli-user-guide#parser_management_v2_user_workflows) for more information.\n",
        "AUTHOR  = \"\" #@param [\"\"] {allow-input: true}\n",
        "CONFIG_FILE = \"\" #@param [\"\"] {allow-input: true}\n",
        "LOG_FILE = \"\" #@param [\"\"] {allow-input: true}\n",
        "LOG_TYPE = \"ADFS\" #@param [\"\"] {allow-input: true}\n",
        "PARSER_ID = \"\" #@param [\"\"] {allow-input: true}\n",
        "PARSEREXTENSION_ID = \"\" #@param [\"\"] {allow-input: true}\n",
        "state = \"\" #@param  [\"ALL\",\"ACTIVE\",\"INACTIVE\",\"\"]\n",
        "export = \"\" #@param [\"\"] {allow-input: true}\n",
        "file_format = \"\" #@param [\"\", \"TXT\", \"JSON\"]\n",
        "env = \"\" #@param [\"\",\"prod\",\"test\"]\n",
        "verbose = False #@param {type:\"boolean\"}\n",
        "\n",
        "if state:\n",
        "  state = f\"--state {state}\"\n",
        "else:\n",
        "  state = \"\"\n",
        "\n",
        "if file_format:\n",
        "  file_format = f\"--file-format {file_format}\"\n",
        "else:\n",
        "  file_format = \"\"\n",
        "\n",
        "if export:\n",
        "  export = f\"--export {export}\"\n",
        "else:\n",
        "  export = \"\"\n",
        "\n",
        "if env:\n",
        "  env = f\"--env {env}\"\n",
        "else:\n",
        "  env = \"\"\n",
        "\n",
        "if verbose:\n",
        "  verbose = f\"--verbose\"\n",
        "else:\n",
        "  verbose = \"\"\n",
        "\n",
        "print(f\"Running:\\nchronicle_cli parsers {operation} --v2 {state} {file_format} {export} {env} {verbose} {PROJECT_ID} {CUSTOMER_ID} --region {cli_region} {LOG_TYPE} {CONFIG_FILE} {LOG_FILE} {PARSER_ID} {PARSEREXTENSION_ID}\\n\")\n",
        "!chronicle_cli parsers $operation --v2 $state $file_format $export $env $verbose $PROJECT_ID $CUSTOMER_ID --region $cli_region $LOG_TYPE $CONFIG_FILE $LOG_FILE $PARSER_ID $PARSEREXTENSION_ID"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uqYBp3njsxIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Provide Big Query email access\n",
        "!chronicle_cli bigquery provide_access --region $cli_region"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_pNY9Y6AZFq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2f6ttB3qkeQ"
      },
      "source": [
        "# Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5fsLQEerndW"
      },
      "source": [
        "## File uploads\n",
        "\n",
        "- It turns out that the colab `files.upload()` call ([docs](https://colab.sandbox.google.com/notebooks/io.ipynb#scrollTo=BaCkyg5CV5jF))returns the name of the file selected, not the resulting name saved to the filesystem. If the same file is uploaded multiple times it wil be saved as:\n",
        "  - `filename.ext`\n",
        "  - `filename (1).ext`\n",
        "  - `filename (2).ext`\n",
        "  - etc...\n",
        "- This means that the original file (`filename.ext`) will continue to get referenced and may cause confusion.\n",
        "- Please try to keep this in mind if re-uploading the same file mulitple times.\n",
        "- Files can be deleted from the files view on the left hand side (folder icon)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Jump to top](#scrollTo=v0jKbGj8ZZRB)\n"
      ],
      "metadata": {
        "id": "Z9zLoScMN2PK"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "muQqm1nmtAI0"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
